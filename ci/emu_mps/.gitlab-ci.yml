# Change pip's cache directory to be inside the project directory since we can
# only cache local items.
variables:
  PIP_CACHE_DIR: "$CI_PROJECT_DIR/.cache/pip"
  REPOSITORY_BASE_URL: 9ygszqk0.gra7.container-registry.ovh.net
  REPOSITORY_NAME: $REPOSITORY_BASE_URL/emulators/emu-mps
  PROTECT: "slurm"
  PIP_EXTRA_INDEX_URL: "https://gitlab.pasqal.com/api/v4/projects/597/packages/pypi/simple"

default:
  interruptible: true

# The rules are from Workflows/MergeRequest-Pipelines.gitlab-ci.yml
# but we can't extend the template so they are duplicated here.
workflow:
  rules:
    - if: $PARENT_COMMIT_BRANCH && $PARENT_OPEN_MR && $PARENT_PIPELINE_SOURCE == "push" && $PARENT_COMMIT_REF_PROTECTED != "true"
      when: never
    - if: $PARENT_PIPELINE_SOURCE == "merge_request_event"
    - if: $PARENT_COMMIT_TAG
      variables:
        PROTECT: "protected"
    - if: $PARENT_COMMIT_REF_PROTECTED == "true"
      variables:
        PROTECT: "protected"
    - if: $PARENT_PIPELINE_SOURCE == "web"

.id_token:
  id_tokens:
    CI_JOB_JWT:
      aud: https://gitlab.pasqal.com

.publish_rules:
  rules:
    - if: $PARENT_PIPELINE_SOURCE == "schedule"
      when: never
    - if: $PARENT_COMMIT_TAG

# Include templates for running jobs on the dgx cluster
include:
  - project: pasqal/dgx-cluster-support
    ref: main
    file: /gitlab-templates/dgx-runner.yml

cache:
  paths:
    - .cache/pip

stages:
  - dummy
  - publish
  - benchmarks
  - package

dummy:
  #this child pipeline will fail if no jobs run. Always run this X_X
  stage: dummy
  script:
    - echo "Hello World!"

.benchmark:
  artifacts:
    paths:
      - ci/emu_mps/benchmarks/${JOB_NAME}/${JOB_NAME}.out
      - ci/emu_mps/benchmarks/${JOB_NAME}/results/*
    when: on_success
    access: all
    # 7 days as package stage will compile everything and store it for longer time
    expire_in: "7 days"
  stage: benchmarks
  tags:
    - slurm
    - ${PROTECT}
  cache:
    paths:
      - .cache/pip
      - ci/emu_mps/benchmarks/framework/benchmarkutils/__pycache__/
  rules:
    # run on schedule
    - if: $PARENT_COMMIT_BRANCH==$CI_DEFAULT_BRANCH && $PARENT_PIPELINE_SOURCE == "schedule"
    # Run manually within an MR
    - if: '$PARENT_PIPELINE_SOURCE == "merge_request_event" || $PARENT_TRIGGER_SOURCE == "web"'
      when: manual
      allow_failure: true
  before_script:
    - module load devel/python/${PYTHON_VERSION}
    - python3 -m venv venv
    - . venv/bin/activate
    - cp /home/emuteam/.venv/pip.conf venv/pip.conf
    - cd ci/emu_mps/benchmarks/${JOB_NAME}/
    - pip install -e ../../../../
    - pip install -e ../framework
  # Maximum and default runtime on the cluster of a job
  timeout: 96h
  variables:
    PYTHON_VERSION: "3.10.4"
  id_tokens: !reference [.id_token, id_tokens]

benchmark_adiabatic_afm_state_cpu:
  extends: .benchmark
  before_script:
    - module purge
    - !reference [.template-jacamar-minimal, before_script]
    - !reference [.benchmark, before_script]
  script:
    - python3 benchmark.py | tee ${JOB_NAME}.out
  after_script:
    - !reference [.template-jacamar-minimal, after_script]
  variables:
    SCHEDULER_PARAMETERS: "-N1 -c 16"
    JOB_NAME: "adiabatic_afm_state_cpu"

benchmark_adiabatic_afm_state_gpu:
  extends: .benchmark
  before_script:
    - module purge
    - !reference [.template-jacamar-minimal, before_script]
    - !reference [.benchmark, before_script]
  script:
    - python3 benchmark.py | tee ${JOB_NAME}.out
  after_script:
    - !reference [.template-jacamar-minimal, after_script]
  variables:
    SCHEDULER_PARAMETERS: "-N1 -c 1 -G 1"
    JOB_NAME: "adiabatic_afm_state_gpu"

benchmark_afm_state_fidelity:
  extends: .benchmark
  before_script:
    - module purge
    - !reference [.template-jacamar-minimal, before_script]
    - !reference [.benchmark, before_script]
  script:
    - python3 benchmark.py | tee ${JOB_NAME}.out
  after_script:
    - !reference [.template-jacamar-minimal, after_script]
  variables:
    SCHEDULER_PARAMETERS: "-N1 -c 16"
    JOB_NAME: "afm_state_fidelity"

benchmark_afm_state_fidelity_with_noise:
  extends: .benchmark
  before_script:
    - module purge
    - !reference [.template-jacamar-minimal, before_script]
    - !reference [.benchmark, before_script]
  script:
    - python3 benchmark.py | tee ${JOB_NAME}.out
  after_script:
    - !reference [.template-jacamar-minimal, after_script]
  variables:
    SCHEDULER_PARAMETERS: "-N1 -c 16"
    JOB_NAME: "afm_state_fidelity_with_noise"

benchmark_qubit_shuffling_cpu:
  extends: .benchmark
  before_script:
    - module purge
    - !reference [.template-jacamar-minimal, before_script]
    - !reference [.benchmark, before_script]
  script:
    - python3 benchmark.py | tee ${JOB_NAME}.out
  after_script:
    - !reference [.template-jacamar-minimal, after_script]
  variables:
    SCHEDULER_PARAMETERS: "-N1 -c 16"
    JOB_NAME: "qubit_shuffling_cpu"

benchmark_quench_fidelity:
  extends: .benchmark
  before_script:
    - module purge
    - !reference [.template-jacamar-minimal, before_script]
    - !reference [.benchmark, before_script]
  script:
    - python3 benchmark.py | tee ${JOB_NAME}.out
  after_script:
    - !reference [.template-jacamar-minimal, after_script]
  variables:
    SCHEDULER_PARAMETERS: "-N1 -c 32"
    JOB_NAME: "quench_fidelity"
  timeout: 96h

benchmark_quench_performance_cpu:
  extends: .benchmark
  before_script:
    - module purge
    - !reference [.template-jacamar-minimal, before_script]
    - !reference [.benchmark, before_script]
  script:
    - python3 benchmark.py | tee ${JOB_NAME}.out
  after_script:
    - !reference [.template-jacamar-minimal, after_script]
  variables:
    SCHEDULER_PARAMETERS: "-N1 -c 32"
    JOB_NAME: "quench_performance_cpu"

benchmark_quench_performance_gpu:
  extends: .benchmark
  before_script:
    - module purge
    - !reference [.template-jacamar-minimal, before_script]
    - !reference [.benchmark, before_script]
  script:
    - python3 benchmark.py | tee ${JOB_NAME}.out
  after_script:
    - !reference [.template-jacamar-minimal, after_script]
  variables:
    SCHEDULER_PARAMETERS: "-N1 -c 4 -G 1"
    JOB_NAME: "quench_performance_gpu"

benchmark_quench_perf_obs_cpuVSgpu:
  extends: .benchmark
  before_script:
    - module purge
    - !reference [.template-jacamar-minimal, before_script]
    - !reference [.benchmark, before_script]
  script:
    - python3 benchmark.py | tee ${JOB_NAME}.out
  after_script:
    - !reference [.template-jacamar-minimal, after_script]
  variables:
    SCHEDULER_PARAMETERS: "-N1 -c 24 -G 2"
    JOB_NAME: "quench_perf_obs_cpuVSgpu"

package_benchmark_artifacts:
  stage: package
  id_tokens: !reference [.id_token, id_tokens]
  tags:
    - slurm
    - ${PROTECT}
  rules:
    # run on schedule
    - if: $PARENT_COMMIT_BRANCH=="main" && $PARENT_PIPELINE_SOURCE == "schedule"
    # Run after manual benchmarks runned within an MR
    - if: '$PARENT_PIPELINE_SOURCE == "merge_request_event" || $PARENT_TRIGGER_SOURCE == "web"'
      allow_failure: true
  script:
    - echo "packaging everything and backing up on the cluster"
  after_script:
    - timestamp=$(date +"%Y%m%dT%H%M")
    - archivedir=/home/emuteam/archive
    - mkdir -p ${archivedir}/${timestamp}
    - cp -rva ci/emu_mps/benchmarks/*/results ${archivedir}/${timestamp}
    - FILES=$(find $archivedir/$timestamp -type f -name *.png)
    - for file in $FILES ; do echo -n " -a $file" >> commands.txt ; done
    - FILES_CMD=$(cat commands.txt)
    - msg="Hello Emulation Team!\n\nSee attachments for the emu-ct benchmark. \n\nDo not reply to this automatic email."
    - SUBJECT='[no-reply] Emu-MPS weekly benchmark'
    - echo -e "$msg" | mailx -r emuteam@admin-pasqal -s "$SUBJECT" $FILES_CMD emulation@pasqal.com
    - rm commands.txt
  needs:
    - benchmark_adiabatic_afm_state_cpu
    - benchmark_adiabatic_afm_state_gpu
    - benchmark_afm_state_fidelity
    - benchmark_afm_state_fidelity_with_noise
    - benchmark_qubit_shuffling_cpu
    - benchmark_quench_fidelity
    - benchmark_quench_performance_cpu
    - benchmark_quench_performance_gpu
    - benchmark_quench_perf_obs_cpuVSgpu
  artifacts:
    name: all-benchmarks
    paths:
      - "ci/emu_mps/benchmarks/**/*.log"
      - "ci/emu_mps/benchmarks/**/*.out"
      - "ci/emu_mps/benchmarks/**/*.png"
      - "ci/emu_mps/benchmarks/**/*.json"
    expire_in: "30 days"

publish_cloud_image:
  stage: publish
  image: docker:20.10.18
  extends:
    - .publish_rules
  services:
    - docker:20.10.18-dind
  variables:
    DOCKER_TLS_CERTDIR: "/certs"
  script:
    - echo $HARBOR_TOKEN | docker login -u $HARBOR_USERNAME --password-stdin $REPOSITORY_BASE_URL
    - docker build --build-arg SSH_PRIVATE_KEY="${SSH_PRIVATE_KEY}" -t $REPOSITORY_NAME:latest -t $REPOSITORY_NAME:$PARENT_COMMIT_TAG .
    - docker push --all-tags $REPOSITORY_NAME

publish-package:
  stage: publish
  image: python:3.10
  extends:
    - .publish_rules
  script:
    - python -m pip install --upgrade pip
    - python -m pip install hatch
    - cd ci/emu_mps
    - python -m hatch build
    - python -m hatch publish
  variables:
    HATCH_INDEX_USER: $CI_DEPLOY_USER
    HATCH_INDEX_AUTH: $CI_DEPLOY_PASSWORD
    HATCH_INDEX_REPO: https://gitlab.pasqal.com/api/v4/projects/597/packages/pypi
