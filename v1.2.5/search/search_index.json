{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to emu-mps","text":"<p>Emu-mps is a backend for the Pulser low-level Quantum Programming toolkit that lets you run Quantum Algorithms on a simulated device, using GPU acceleration if available. More in depth, emu-mps is designed to emulate the dynamics of programmable arrays of neutral atoms, with matrix product states (mps). While benchmarking is incomplete as of this writing, early results suggest that this design makes emu-mps faster and more memory-efficient than previous generations of quantum emulators at running simulations with large numbers of qubits.</p> <p>As of this writing, Emu-MPS is provided for Linux and macOS but will not work under Windows.</p>"},{"location":"#installation","title":"Installation","text":"<p>Warning: installing emu-mps will update pulser-core</p>"},{"location":"#using-hatch-uv-or-any-pyproject-compatible-python-manager","title":"Using <code>hatch</code>, <code>uv</code> or any pyproject-compatible Python manager","text":"<p>To add <code>emu-mps</code> to your project, edit your <code>pyproject.toml</code> to add the line</p> <pre><code>  \"emu-mps\"\n</code></pre> <p>to the list of <code>dependencies</code>.</p>"},{"location":"#using-pip-or-pipx","title":"Using <code>pip</code> or <code>pipx</code>","text":"<p>To install the <code>pipy</code> package using <code>pip</code> or <code>pipx</code></p> <ol> <li>Create a <code>venv</code> if that's not done yet</li> </ol> <pre><code>$ python -m venv venv\n</code></pre> <ol> <li>Enter the venv</li> </ol> <p>If you're running Unix:</p> <pre><code>$ . venv/bin/activate\n</code></pre> <p>If you're running Windows:</p> <pre><code>C:\\&gt; /path/to/new/virtual/environment/Scripts/activate\n</code></pre> <ol> <li>Install the package</li> </ol> <pre><code>$ pip install emu-mps\n# or\n$ pipx install emu-mps\n</code></pre> <p>Join us on Slack or by e-mail to give us feedback about how you plan to use Emu-MPS or if you require specific feature-upgrades.</p>"},{"location":"#usage","title":"Usage","text":"<p>For the time being, the easiest way to learn how to use this package is to look at the examples and notebooks.</p> <p>See also the full documentation for the API, information about contributing, benchmarks, etc.</p>"},{"location":"#getting-in-touch","title":"Getting in touch","text":"<ul> <li>Pasqal Community Portal (forums, chat, tutorials, examples, code library).</li> <li>GitHub Repository (source code, issue tracker).</li> <li>Professional Support (if you need tech support, custom licenses, a variant of this library optimized for your workload, your own QPU, remote access to a QPU, ...)</li> </ul>"},{"location":"#running-a-pulser-sequence-and-getting-results","title":"Running a Pulser sequence and getting results","text":"<p>Several example notebooks are included in the online documentation. The index page for them can be found here.</p>"},{"location":"#supported-features","title":"Supported features","text":"<p>The following features are currently supported:</p> <ul> <li>All Pulser sequences that use only the rydberg channel</li> <li>MPS and MPO can be constructed using the abstract Pulser format.</li> <li>The following noise types:<ul> <li>SPAM</li> <li>Monte Carlo quantum jumps</li> <li>A Gaussian laser waist for the global pulse channels.</li> </ul> </li> <li>The following basis states in a sequence:<ul> <li>ground-rydberg</li> <li>XY</li> </ul> </li> <li>The following properties from a Pulser Sequence are also correctly applied:<ul> <li>hardware modulation</li> <li>SLM mask</li> <li>A complex phase for the omega parameter</li> </ul> </li> <li>Customizable output, with the folowing inbuilt options:<ul> <li>The quantum state in MPS format</li> <li>Bitstrings</li> <li>The fidelity with respect to a given state</li> <li>The expectation of a given operator</li> <li>The qubit density (magnetization)</li> <li>The correlation matrix</li> <li>The mean, second moment and variance of the energy</li> </ul> </li> <li>Specification of<ul> <li>initial state</li> <li>various precision parameters</li> <li>whether to run on cpu or gpu(s)</li> <li>the \\(U_{ij}\\) coefficients from here</li> <li>A cutoff below which \\(U_{ij}\\) are set to 0 (this makes the computation more memory efficient)</li> </ul> </li> </ul>"},{"location":"#planned-features","title":"Planned features","text":"<ul> <li>Parallel TDVP on multiple GPUs</li> <li>More noise:<ul> <li>the currently unsupported noises in the Pulser <code>NoiseModel</code></li> </ul> </li> <li>Differentiability</li> </ul>"},{"location":"#more-info","title":"More Info","text":"<p>Please see the API specification for a list of available config options (see here), and the Observables page for how to compute observables (see here). Those configuration options relating to the mathematical functioning of the backend are explained in more detail in the Config page (see here). For notebooks with examples for how to do various things, please see the notebooks page (see here).</p>"},{"location":"CODE_OF_CONDUCT/","title":"Code of Conduct","text":""},{"location":"CODE_OF_CONDUCT/#our-pledge","title":"Our Pledge","text":"<p>In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p>"},{"location":"CODE_OF_CONDUCT/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to creating a positive environment include:</p> <ul> <li>Using welcoming and inclusive language</li> <li>Being respectful of differing viewpoints and experiences</li> <li>Gracefully accepting constructive criticism</li> <li>Focusing on what is best for the community</li> <li>Showing empathy towards other community members</li> </ul> <p>Examples of unacceptable behavior by participants include:</p> <ul> <li>The use of sexualized language or imagery and unwelcome sexual attention or advances</li> <li>Trolling, insulting/derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or electronic address, without explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a professional setting</li> </ul>"},{"location":"CODE_OF_CONDUCT/#our-responsibilities","title":"Our Responsibilities","text":"<p>Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.</p> <p>Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.</p>"},{"location":"CODE_OF_CONDUCT/#scope","title":"Scope","text":"<p>This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.</p>"},{"location":"CONTRIBUTING/","title":"How to Contribute","text":"<p>We're grateful for your interest in participating in emu-mps! Please follow our guidelines to ensure a smooth contribution process.</p>"},{"location":"CONTRIBUTING/#reporting-an-issue-or-proposing-a-feature","title":"Reporting an Issue or Proposing a Feature","text":"<p>Your course of action will depend on your objective, but generally, you should start by creating an issue. If you've discovered a bug or have a feature you'd like to see added to emu-mps, feel free to create an issue on the issue tracker. Here are some steps to take:</p> <ol> <li>Quickly search the existing issues using relevant keywords to ensure your issue hasn't been addressed already.</li> <li> <p>If your issue is not listed, create a new one. Try to be as detailed and clear as possible in your description.</p> </li> <li> <p>If you're merely suggesting an improvement or reporting a bug, that's already excellent! We thank you for it. Your issue will be listed and, hopefully, addressed at some point.</p> </li> <li>However, if you're willing to be the one solving the issue, that would be even better! In such instances, you would proceed by preparing a Pull Request.</li> </ol>"},{"location":"CONTRIBUTING/#submitting-a-pull-request","title":"Submitting a Pull Request","text":"<p>We're excited that you're eager to contribute to emu-mps! To contribute, create a branch on the emu-mps repository and once you are satisfied with your feature and all the tests pass create a Merge Request.</p> <p>Here's the process for making a contribution:</p> <p>Make a new branch via</p> <pre><code>git branch &lt;your initials&gt;/&lt;branch name&gt;\n</code></pre> <p>Next, checkout your new branch, and associate a branch to it on the GitHub server:</p> <pre><code>git checkout &lt;your initials&gt;/&lt;branch name&gt;\ngit push --set-upstream origin &lt;your initials&gt;/&lt;branch name&gt;\n</code></pre>"},{"location":"CONTRIBUTING/#setting-up-your-development-environment","title":"Setting up your development environment","text":"<p>We recommend to use <code>hatch</code> for managing environments:</p> <p>To develop within emu-mps, use: <pre><code>pip install hatch\nhatch -v shell\n</code></pre></p> <p>To run the automated tests, use:</p> <pre><code>hatch -e tests run test\n</code></pre> <p>If you don't want to use <code>hatch</code>, you can use the environment manager of your choice and execute the following:</p> <pre><code>pip install pytest\n\npip install -e .\npytest\n</code></pre>"},{"location":"CONTRIBUTING/#useful-things-for-your-workflow-linting-and-testing","title":"Useful Things for your workflow: Linting and Testing","text":"<p>Use <code>pre-commit</code> hooks to make sure that the code is properly linted before pushing a new commit. Make sure that the unit tests and type checks are passing since the merge request will not be accepted if the automatic CI/CD pipeline do not pass.</p> <p>Without <code>hatch</code>:</p> <pre><code>pip install pytest\n\npip install -e .\npip install pre-commit\npre-commit install\npre-commit run --all-files\npytest\n</code></pre> <p>And with <code>hatch</code>:</p> <pre><code>hatch -e tests run pre-commit run --all-files\nhatch -e tests run test\n</code></pre> <p>Make sure your docs build too!</p> <p>With <code>hatch</code>:</p> <pre><code>hatch -e docs run mkdocs build --clean --strict\n</code></pre> <p>Without <code>hatch</code>, <code>pip</code> install those libraries first: <pre><code>pip install -r doc_requirements.txt\n</code></pre></p> <p>Then build the documentation:</p> <pre><code> mkdocs build --clean --strict\n</code></pre>"},{"location":"api/","title":"API specification","text":"<p>The emu-mps api is based on a series of abstract base classes, which are intended to generalize into a backend independent API. Currently these classes are defined in emu-mps, and they will be documented here until they are moved into a more general location, probably pulser-core. While they are in this project, see the specification here.</p>"},{"location":"api/#mpsbackend","title":"MPSBackend","text":"<p>               Bases: <code>Backend</code></p> <p>A backend for emulating Pulser sequences using Matrix Product States (MPS), aka tensor trains.</p>"},{"location":"api/#emu_mps.mps_backend.MPSBackend.resume","title":"<code>resume(autosave_file)</code>","text":"<p>Resume simulation from autosave file. Only resume simulations from data you trust! Unpickling of untrusted data is not safe.</p> Source code in <code>emu_mps/mps_backend.py</code> <pre><code>def resume(self, autosave_file: str | pathlib.Path) -&gt; Results:\n    \"\"\"\n    Resume simulation from autosave file.\n    Only resume simulations from data you trust!\n    Unpickling of untrusted data is not safe.\n    \"\"\"\n    if isinstance(autosave_file, str):\n        autosave_file = pathlib.Path(autosave_file)\n\n    if not autosave_file.is_file():\n        raise ValueError(f\"Not a file: {autosave_file}\")\n\n    with open(autosave_file, \"rb\") as f:\n        impl: MPSBackendImpl = pickle.load(f)\n\n    impl.autosave_file = autosave_file\n    impl.last_save_time = time.time()\n    impl.config.init_logging()  # FIXME: might be best to take logger object out of config.\n\n    logging.getLogger(\"global_logger\").warning(\n        f\"Resuming simulation from file {autosave_file}\\n\"\n        f\"Saving simulation state every {impl.config.autosave_dt} seconds\"\n    )\n\n    return self._run(impl)\n</code></pre>"},{"location":"api/#emu_mps.mps_backend.MPSBackend.run","title":"<code>run(sequence, mps_config)</code>","text":"<p>Emulates the given sequence.</p> PARAMETER DESCRIPTION <code>sequence</code> <p>a Pulser sequence to simulate</p> <p> TYPE: <code>Sequence</code> </p> <code>mps_config</code> <p>the backends config. Should be of type MPSConfig</p> <p> TYPE: <code>BackendConfig</code> </p> RETURNS DESCRIPTION <code>Results</code> <p>the simulation results</p> Source code in <code>emu_mps/mps_backend.py</code> <pre><code>def run(self, sequence: Sequence, mps_config: BackendConfig) -&gt; Results:\n    \"\"\"\n    Emulates the given sequence.\n\n    Args:\n        sequence: a Pulser sequence to simulate\n        mps_config: the backends config. Should be of type MPSConfig\n\n    Returns:\n        the simulation results\n    \"\"\"\n    assert isinstance(mps_config, MPSConfig)\n\n    self.validate_sequence(sequence)\n\n    impl = create_impl(sequence, mps_config)\n    impl.init()  # This is separate from the constructor for testing purposes.\n\n    return self._run(impl)\n</code></pre>"},{"location":"api/#mpsconfig","title":"MPSConfig","text":"<p>               Bases: <code>BackendConfig</code></p> <p>The configuration of the emu-ct MPSBackend. The kwargs passed to this class are passed on to the base class. See the API for that class for a list of available options.</p> PARAMETER DESCRIPTION <code>initial_state</code> <p>the initial state to use in the simulation</p> <p> TYPE: <code>State | None</code> DEFAULT: <code>None</code> </p> <code>dt</code> <p>the timestep size that the solver uses. Note that observables are only calculated if the evaluation_times are divisible by dt.</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> <code>precision</code> <p>up to what precision the state is truncated</p> <p> TYPE: <code>float</code> DEFAULT: <code>1e-05</code> </p> <code>max_bond_dim</code> <p>the maximum bond dimension that the state is allowed to have.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1024</code> </p> <code>max_krylov_dim</code> <p>the size of the krylov subspace that the Lanczos algorithm maximally builds</p> <p> TYPE: <code>int</code> DEFAULT: <code>100</code> </p> <code>extra_krylov_tolerance</code> <p>the Lanczos algorithm uses this*precision as the convergence tolerance</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.001</code> </p> <code>num_gpus_to_use</code> <p>during the simulation, distribute the state over this many GPUs 0=all factors to cpu. As shown in the benchmarks, using multiple GPUs might alleviate memory pressure per GPU, but the runtime should be similar.</p> <p> TYPE: <code>int</code> DEFAULT: <code>DEVICE_COUNT</code> </p> <code>autosave_prefix</code> <p>filename prefix for autosaving simulation state to file</p> <p> TYPE: <code>str</code> DEFAULT: <code>'emu_mps_save_'</code> </p> <code>autosave_dt</code> <p>minimum time interval in seconds between two autosaves Saving the simulation state is only possible at specific times, therefore this interval is only a lower bound.</p> <p> TYPE: <code>int</code> DEFAULT: <code>600</code> </p> <code>kwargs</code> <p>arguments that are passed to the base class</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; num_gpus_to_use = 2 #use 2 gpus if available, otherwise 1 or cpu\n&gt;&gt;&gt; dt = 1 #this will impact the runtime\n&gt;&gt;&gt; precision = 1e-6 #smaller dt requires better precision, generally\n&gt;&gt;&gt; MPSConfig(num_gpus_to_use=num_gpus_to_use, dt=dt, precision=precision,\n&gt;&gt;&gt;     with_modulation=True) #the last arg is taken from the base class\n</code></pre> Source code in <code>emu_mps/mps_config.py</code> <pre><code>def __init__(\n    self,\n    *,\n    initial_state: State | None = None,\n    dt: int = 10,\n    precision: float = 1e-5,\n    max_bond_dim: int = 1024,\n    max_krylov_dim: int = 100,\n    extra_krylov_tolerance: float = 1e-3,\n    num_gpus_to_use: int = DEVICE_COUNT,\n    autosave_prefix: str = \"emu_mps_save_\",\n    autosave_dt: int = 600,  # 10 minutes\n    **kwargs: Any,\n):\n    super().__init__(**kwargs)\n    self.initial_state = initial_state\n    self.dt = dt\n    self.precision = precision\n    self.max_bond_dim = max_bond_dim\n    self.max_krylov_dim = max_krylov_dim\n    self.num_gpus_to_use = num_gpus_to_use\n    self.extra_krylov_tolerance = extra_krylov_tolerance\n\n    if self.noise_model is not None:\n        if \"doppler\" in self.noise_model.noise_types:\n            raise NotImplementedError(\"Unsupported noise type: doppler\")\n        if (\n            \"amplitude\" in self.noise_model.noise_types\n            and self.noise_model.amp_sigma != 0.0\n        ):\n            raise NotImplementedError(\"Unsupported noise type: amp_sigma\")\n\n    self.autosave_prefix = autosave_prefix\n    self.autosave_dt = autosave_dt\n\n    MIN_AUTOSAVE_DT = 10\n    assert (\n        self.autosave_dt &gt; MIN_AUTOSAVE_DT\n    ), f\"autosave_dt must be larger than {MIN_AUTOSAVE_DT} seconds\"\n</code></pre>"},{"location":"api/#mps","title":"MPS","text":"<p>               Bases: <code>State</code></p> <p>Matrix Product State, aka tensor train.</p> <p>Each tensor has 3 dimensions ordered as such: (left bond, site, right bond).</p> <p>Only qubits are supported.</p> <p>This constructor creates a MPS directly from a list of tensors. It is for internal use only.</p> PARAMETER DESCRIPTION <code>factors</code> <p>the tensors for each site WARNING: for efficiency in a lot of use cases, this list of tensors IS NOT DEEP-COPIED. Therefore, the new MPS object is not necessarily the exclusive owner of the list and its tensors. As a consequence, beware of potential external modifications affecting the list or the tensors. You are responsible for deciding whether to pass its own exclusive copy of the data to this constructor, or some shared objects.</p> <p> TYPE: <code>List[Tensor]</code> </p> <code>orthogonality_center</code> <p>the orthogonality center of the MPS, or None (in which case it will be orthogonalized when needed)</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>config</code> <p>the emu-mps config object passed to the run method</p> <p> TYPE: <code>Optional[MPSConfig]</code> DEFAULT: <code>None</code> </p> <code>num_gpus_to_use</code> <p>distribute the factors over this many GPUs 0=all factors to cpu, None=keep the existing device assignment.</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>DEVICE_COUNT</code> </p> Source code in <code>emu_mps/mps.py</code> <pre><code>def __init__(\n    self,\n    factors: List[torch.Tensor],\n    /,\n    *,\n    orthogonality_center: Optional[int] = None,\n    config: Optional[MPSConfig] = None,\n    num_gpus_to_use: Optional[int] = DEVICE_COUNT,\n):\n    \"\"\"\n    This constructor creates a MPS directly from a list of tensors. It is for internal use only.\n\n    Args:\n        factors: the tensors for each site\n            WARNING: for efficiency in a lot of use cases, this list of tensors\n            IS NOT DEEP-COPIED. Therefore, the new MPS object is not necessarily\n            the exclusive owner of the list and its tensors. As a consequence,\n            beware of potential external modifications affecting the list or the tensors.\n            You are responsible for deciding whether to pass its own exclusive copy\n            of the data to this constructor, or some shared objects.\n        orthogonality_center: the orthogonality center of the MPS, or None (in which case\n            it will be orthogonalized when needed)\n        config: the emu-mps config object passed to the run method\n        num_gpus_to_use: distribute the factors over this many GPUs\n            0=all factors to cpu, None=keep the existing device assignment.\n    \"\"\"\n    self.config = config if config is not None else MPSConfig()\n    assert all(\n        factors[i - 1].shape[2] == factors[i].shape[0] for i in range(1, len(factors))\n    ), \"The dimensions of consecutive tensors should match\"\n    assert (\n        factors[0].shape[0] == 1 and factors[-1].shape[2] == 1\n    ), \"The dimension of the left (right) link of the first (last) tensor should be 1\"\n\n    self.factors = factors\n    self.num_sites = len(factors)\n    assert self.num_sites &gt; 1  # otherwise, do state vector\n\n    assert (orthogonality_center is None) or (\n        0 &lt;= orthogonality_center &lt; self.num_sites\n    ), \"Invalid orthogonality center provided\"\n    self.orthogonality_center = orthogonality_center\n\n    if num_gpus_to_use is not None:\n        assign_devices(self.factors, min(DEVICE_COUNT, num_gpus_to_use))\n</code></pre>"},{"location":"api/#emu_mps.mps.MPS.__add__","title":"<code>__add__(other)</code>","text":"<p>Returns the sum of two MPSs, computed with a direct algorithm. The resulting MPS is orthogonalized on the first site and truncated up to <code>self.config.precision</code>.</p> PARAMETER DESCRIPTION <code>other</code> <p>the other state</p> <p> TYPE: <code>State</code> </p> RETURNS DESCRIPTION <code>MPS</code> <p>the summed state</p> Source code in <code>emu_mps/mps.py</code> <pre><code>def __add__(self, other: State) -&gt; MPS:\n    \"\"\"\n    Returns the sum of two MPSs, computed with a direct algorithm.\n    The resulting MPS is orthogonalized on the first site and truncated\n    up to `self.config.precision`.\n\n    Args:\n        other: the other state\n\n    Returns:\n        the summed state\n    \"\"\"\n    assert isinstance(other, MPS), \"Other state also needs to be an MPS\"\n    new_tt = add_factors(self.factors, other.factors)\n    result = MPS(\n        new_tt,\n        config=self.config,\n        num_gpus_to_use=None,\n        orthogonality_center=None,  # Orthogonality is lost.\n    )\n    result.truncate()\n    return result\n</code></pre>"},{"location":"api/#emu_mps.mps.MPS.__rmul__","title":"<code>__rmul__(scalar)</code>","text":"<p>Multiply an MPS by a scalar.</p> PARAMETER DESCRIPTION <code>scalar</code> <p>the scale factor</p> <p> TYPE: <code>complex</code> </p> RETURNS DESCRIPTION <code>MPS</code> <p>the scaled MPS</p> Source code in <code>emu_mps/mps.py</code> <pre><code>def __rmul__(self, scalar: complex) -&gt; MPS:\n    \"\"\"\n    Multiply an MPS by a scalar.\n\n    Args:\n        scalar: the scale factor\n\n    Returns:\n        the scaled MPS\n    \"\"\"\n    which = (\n        self.orthogonality_center\n        if self.orthogonality_center is not None\n        else 0  # No need to orthogonalize for scaling.\n    )\n    factors = scale_factors(self.factors, scalar, which=which)\n    return MPS(\n        factors,\n        config=self.config,\n        num_gpus_to_use=None,\n        orthogonality_center=self.orthogonality_center,\n    )\n</code></pre>"},{"location":"api/#emu_mps.mps.MPS.apply","title":"<code>apply(qubit_index, single_qubit_operator)</code>","text":"<p>Apply given single qubit operator to qubit qubit_index, leaving the MPS orthogonalized on that qubit.</p> Source code in <code>emu_mps/mps.py</code> <pre><code>def apply(self, qubit_index: int, single_qubit_operator: torch.Tensor) -&gt; None:\n    \"\"\"\n    Apply given single qubit operator to qubit qubit_index, leaving the MPS\n    orthogonalized on that qubit.\n    \"\"\"\n    self.orthogonalize(qubit_index)\n\n    self.factors[qubit_index] = torch.tensordot(\n        self.factors[qubit_index],\n        single_qubit_operator.to(self.factors[qubit_index].device),\n        ([1], [1]),\n    ).transpose(1, 2)\n</code></pre>"},{"location":"api/#emu_mps.mps.MPS.expect_batch","title":"<code>expect_batch(single_qubit_operators)</code>","text":"<p>Computes expectation values for each qubit and each single qubit operator in the batched input tensor.</p> <p>Returns a tensor T such that T[q, i] is the expectation value for qubit #q and operator single_qubit_operators[i].</p> Source code in <code>emu_mps/mps.py</code> <pre><code>def expect_batch(self, single_qubit_operators: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Computes expectation values for each qubit and each single qubit operator in\n    the batched input tensor.\n\n    Returns a tensor T such that T[q, i] is the expectation value for qubit #q\n    and operator single_qubit_operators[i].\n    \"\"\"\n    orthogonality_center = (\n        self.orthogonality_center\n        if self.orthogonality_center is not None\n        else self.orthogonalize(0)\n    )\n\n    result = torch.zeros(\n        self.num_sites, single_qubit_operators.shape[0], dtype=torch.complex128\n    )\n\n    center_factor = self.factors[orthogonality_center]\n    for qubit_index in range(orthogonality_center, self.num_sites):\n        temp = torch.tensordot(center_factor.conj(), center_factor, ([0, 2], [0, 2]))\n\n        result[qubit_index] = torch.tensordot(\n            single_qubit_operators.to(temp.device), temp, dims=2\n        )\n\n        if qubit_index &lt; self.num_sites - 1:\n            _, r = torch.linalg.qr(center_factor.reshape(-1, center_factor.shape[2]))\n            center_factor = torch.tensordot(\n                r, self.factors[qubit_index + 1].to(r.device), dims=1\n            )\n\n    center_factor = self.factors[orthogonality_center]\n    for qubit_index in range(orthogonality_center - 1, -1, -1):\n        _, r = torch.linalg.qr(\n            center_factor.reshape(center_factor.shape[0], -1).mT,\n        )\n        center_factor = torch.tensordot(\n            self.factors[qubit_index],\n            r.to(self.factors[qubit_index].device),\n            ([2], [1]),\n        )\n\n        temp = torch.tensordot(center_factor.conj(), center_factor, ([0, 2], [0, 2]))\n\n        result[qubit_index] = torch.tensordot(\n            single_qubit_operators.to(temp.device), temp, dims=2\n        )\n\n    return result\n</code></pre>"},{"location":"api/#emu_mps.mps.MPS.from_state_string","title":"<code>from_state_string(*, basis, nqubits, strings, **kwargs)</code>  <code>staticmethod</code>","text":"<p>See the base class.</p> PARAMETER DESCRIPTION <code>basis</code> <p>A tuple containing the basis states (e.g., ('r', 'g')).</p> <p> TYPE: <code>Iterable[str]</code> </p> <code>nqubits</code> <p>the number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>strings</code> <p>A dictionary mapping state strings to complex or floats amplitudes.</p> <p> TYPE: <code>dict[str, complex]</code> </p> RETURNS DESCRIPTION <code>MPS</code> <p>The resulting MPS representation of the state.s</p> Source code in <code>emu_mps/mps.py</code> <pre><code>@staticmethod\ndef from_state_string(\n    *,\n    basis: Iterable[str],\n    nqubits: int,\n    strings: dict[str, complex],\n    **kwargs: Any,\n) -&gt; MPS:\n    \"\"\"\n    See the base class.\n\n    Args:\n        basis: A tuple containing the basis states (e.g., ('r', 'g')).\n        nqubits: the number of qubits.\n        strings: A dictionary mapping state strings to complex or floats amplitudes.\n\n    Returns:\n        The resulting MPS representation of the state.s\n    \"\"\"\n\n    basis = set(basis)\n    if basis == {\"r\", \"g\"}:\n        one = \"r\"\n    elif basis == {\"0\", \"1\"}:\n        one = \"1\"\n    else:\n        raise ValueError(\"Unsupported basis provided\")\n\n    basis_0 = torch.tensor([[[1.0], [0.0]]], dtype=torch.complex128)  # ground state\n    basis_1 = torch.tensor([[[0.0], [1.0]]], dtype=torch.complex128)  # excited state\n\n    accum_mps = MPS(\n        [torch.zeros((1, 2, 1), dtype=torch.complex128)] * nqubits,\n        orthogonality_center=0,\n        **kwargs,\n    )\n\n    for state, amplitude in strings.items():\n        factors = [basis_1 if ch == one else basis_0 for ch in state]\n        accum_mps += amplitude * MPS(factors, **kwargs)\n    norm = accum_mps.norm()\n    if not math.isclose(1.0, norm, rel_tol=1e-5, abs_tol=0.0):\n        print(\"\\nThe state is not normalized, normalizing it for you.\")\n        accum_mps *= 1 / norm\n\n    return accum_mps\n</code></pre>"},{"location":"api/#emu_mps.mps.MPS.get_correlation_matrix","title":"<code>get_correlation_matrix(*, operator=n_operator)</code>","text":"<p>Efficiently compute the symmetric correlation matrix     C_ij =  in basis (\"r\", \"g\"). PARAMETER DESCRIPTION <code>operator</code> <p>a 2x2 Torch tensor to use</p> <p> TYPE: <code>Tensor</code> DEFAULT: <code>n_operator</code> </p> RETURNS DESCRIPTION <code>list[list[float]]</code> <p>the corresponding correlation matrix</p> Source code in <code>emu_mps/mps.py</code> <pre><code>def get_correlation_matrix(\n    self, *, operator: torch.Tensor = n_operator\n) -&gt; list[list[float]]:\n    \"\"\"\n    Efficiently compute the symmetric correlation matrix\n        C_ij = &lt;self|operator_i operator_j|self&gt;\n    in basis (\"r\", \"g\").\n\n    Args:\n        operator: a 2x2 Torch tensor to use\n\n    Returns:\n        the corresponding correlation matrix\n    \"\"\"\n    assert operator.shape == (2, 2)\n\n    result = [[0.0 for _ in range(self.num_sites)] for _ in range(self.num_sites)]\n\n    for left in range(0, self.num_sites):\n        self.orthogonalize(left)\n        accumulator = torch.tensordot(\n            self.factors[left],\n            operator.to(self.factors[left].device),\n            dims=([1], [0]),\n        )\n        accumulator = torch.tensordot(\n            accumulator, self.factors[left].conj(), dims=([0, 2], [0, 1])\n        )\n        result[left][left] = accumulator.trace().item().real\n        for right in range(left + 1, self.num_sites):\n            partial = torch.tensordot(\n                accumulator.to(self.factors[right].device),\n                self.factors[right],\n                dims=([0], [0]),\n            )\n            partial = torch.tensordot(\n                partial, self.factors[right].conj(), dims=([0], [0])\n            )\n\n            result[left][right] = (\n                torch.tensordot(\n                    partial, operator.to(partial.device), dims=([0, 2], [0, 1])\n                )\n                .trace()\n                .item()\n                .real\n            )\n            result[right][left] = result[left][right]\n            accumulator = tensor_trace(partial, 0, 2)\n\n    return result\n</code></pre>"},{"location":"api/#emu_mps.mps.MPS.get_max_bond_dim","title":"<code>get_max_bond_dim()</code>","text":"<p>Return the max bond dimension of this MPS.</p> RETURNS DESCRIPTION <code>int</code> <p>the largest bond dimension in the state</p> Source code in <code>emu_mps/mps.py</code> <pre><code>def get_max_bond_dim(self) -&gt; int:\n    \"\"\"\n    Return the max bond dimension of this MPS.\n\n    Returns:\n        the largest bond dimension in the state\n    \"\"\"\n    return max((x.shape[2] for x in self.factors), default=0)\n</code></pre>"},{"location":"api/#emu_mps.mps.MPS.get_memory_footprint","title":"<code>get_memory_footprint()</code>","text":"<p>Returns the number of MBs of memory occupied to store the state</p> RETURNS DESCRIPTION <code>float</code> <p>the memory in MBs</p> Source code in <code>emu_mps/mps.py</code> <pre><code>def get_memory_footprint(self) -&gt; float:\n    \"\"\"\n    Returns the number of MBs of memory occupied to store the state\n\n    Returns:\n        the memory in MBs\n    \"\"\"\n    return (  # type: ignore[no-any-return]\n        sum(factor.element_size() * factor.numel() for factor in self.factors) * 1e-6\n    )\n</code></pre>"},{"location":"api/#emu_mps.mps.MPS.inner","title":"<code>inner(other)</code>","text":"<p>Compute the inner product between this state and other. Note that self is the left state in the inner product, so this function is linear in other, and anti-linear in self</p> PARAMETER DESCRIPTION <code>other</code> <p>the other state</p> <p> TYPE: <code>State</code> </p> RETURNS DESCRIPTION <code>float | complex</code> <p>inner product</p> Source code in <code>emu_mps/mps.py</code> <pre><code>def inner(self, other: State) -&gt; float | complex:\n    \"\"\"\n    Compute the inner product between this state and other.\n    Note that self is the left state in the inner product,\n    so this function is linear in other, and anti-linear in self\n\n    Args:\n        other: the other state\n\n    Returns:\n        inner product\n    \"\"\"\n    assert isinstance(other, MPS), \"Other state also needs to be an MPS\"\n    assert (\n        self.num_sites == other.num_sites\n    ), \"States do not have the same number of sites\"\n\n    acc = torch.ones(1, 1, dtype=self.factors[0].dtype, device=self.factors[0].device)\n\n    for i in range(self.num_sites):\n        acc = acc.to(self.factors[i].device)\n        acc = torch.tensordot(acc, other.factors[i].to(acc.device), dims=1)\n        acc = torch.tensordot(self.factors[i].conj(), acc, dims=([0, 1], [0, 1]))\n\n    return acc.item()  # type: ignore[no-any-return]\n</code></pre>"},{"location":"api/#emu_mps.mps.MPS.make","title":"<code>make(num_sites, config=None, num_gpus_to_use=DEVICE_COUNT)</code>  <code>classmethod</code>","text":"<p>Returns a MPS in ground state |000..0&gt;.</p> PARAMETER DESCRIPTION <code>num_sites</code> <p>the number of qubits</p> <p> TYPE: <code>int</code> </p> <code>config</code> <p>the MPSConfig</p> <p> TYPE: <code>Optional[MPSConfig]</code> DEFAULT: <code>None</code> </p> <code>num_gpus_to_use</code> <p>distribute the factors over this many GPUs 0=all factors to cpu</p> <p> TYPE: <code>int</code> DEFAULT: <code>DEVICE_COUNT</code> </p> Source code in <code>emu_mps/mps.py</code> <pre><code>@classmethod\ndef make(\n    cls,\n    num_sites: int,\n    config: Optional[MPSConfig] = None,\n    num_gpus_to_use: int = DEVICE_COUNT,\n) -&gt; MPS:\n    \"\"\"\n    Returns a MPS in ground state |000..0&gt;.\n\n    Args:\n        num_sites: the number of qubits\n        config: the MPSConfig\n        num_gpus_to_use: distribute the factors over this many GPUs\n            0=all factors to cpu\n    \"\"\"\n    config = config if config is not None else MPSConfig()\n\n    if num_sites &lt;= 1:\n        raise ValueError(\"For 1 qubit states, do state vector\")\n\n    return cls(\n        [\n            torch.tensor([[[1.0], [0.0]]], dtype=torch.complex128)\n            for _ in range(num_sites)\n        ],\n        config=config,\n        num_gpus_to_use=num_gpus_to_use,\n        orthogonality_center=0,  # Arbitrary: every qubit is an orthogonality center.\n    )\n</code></pre>"},{"location":"api/#emu_mps.mps.MPS.norm","title":"<code>norm()</code>","text":"<p>Computes the norm of the MPS.</p> Source code in <code>emu_mps/mps.py</code> <pre><code>def norm(self) -&gt; float:\n    \"\"\"Computes the norm of the MPS.\"\"\"\n    orthogonality_center = (\n        self.orthogonality_center\n        if self.orthogonality_center is not None\n        else self.orthogonalize(0)\n    )\n\n    return float(\n        torch.linalg.norm(self.factors[orthogonality_center].to(\"cpu\")).item()\n    )\n</code></pre>"},{"location":"api/#emu_mps.mps.MPS.orthogonalize","title":"<code>orthogonalize(desired_orthogonality_center=0)</code>","text":"<p>Orthogonalize the state on the given orthogonality center.</p> <p>Returns the new orthogonality center index as an integer, this is convenient for type-checking purposes.</p> Source code in <code>emu_mps/mps.py</code> <pre><code>def orthogonalize(self, desired_orthogonality_center: int = 0) -&gt; int:\n    \"\"\"\n    Orthogonalize the state on the given orthogonality center.\n\n    Returns the new orthogonality center index as an integer,\n    this is convenient for type-checking purposes.\n    \"\"\"\n    assert (\n        0 &lt;= desired_orthogonality_center &lt; self.num_sites\n    ), f\"Cannot move orthogonality center to nonexistent qubit #{desired_orthogonality_center}\"\n\n    lr_swipe_start = (\n        self.orthogonality_center if self.orthogonality_center is not None else 0\n    )\n\n    for i in range(lr_swipe_start, desired_orthogonality_center):\n        q, r = torch.linalg.qr(self.factors[i].reshape(-1, self.factors[i].shape[2]))\n        self.factors[i] = q.reshape(self.factors[i].shape[0], 2, -1)\n        self.factors[i + 1] = torch.tensordot(\n            r.to(self.factors[i + 1].device), self.factors[i + 1], dims=1\n        )\n\n    rl_swipe_start = (\n        self.orthogonality_center\n        if self.orthogonality_center is not None\n        else (self.num_sites - 1)\n    )\n\n    for i in range(rl_swipe_start, desired_orthogonality_center, -1):\n        q, r = torch.linalg.qr(\n            self.factors[i].reshape(self.factors[i].shape[0], -1).mT,\n        )\n        self.factors[i] = q.mT.reshape(-1, 2, self.factors[i].shape[2])\n        self.factors[i - 1] = torch.tensordot(\n            self.factors[i - 1], r.to(self.factors[i - 1].device), ([2], [1])\n        )\n\n    self.orthogonality_center = desired_orthogonality_center\n\n    return desired_orthogonality_center\n</code></pre>"},{"location":"api/#emu_mps.mps.MPS.sample","title":"<code>sample(num_shots, p_false_pos=0.0, p_false_neg=0.0)</code>","text":"<p>Samples bitstrings, taking into account the specified error rates.</p> PARAMETER DESCRIPTION <code>num_shots</code> <p>how many bitstrings to sample</p> <p> TYPE: <code>int</code> </p> <code>p_false_pos</code> <p>the rate at which a 0 is read as a 1</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> <code>p_false_neg</code> <p>teh rate at which a 1 is read as a 0</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> RETURNS DESCRIPTION <code>Counter[str]</code> <p>the measured bitstrings, by count</p> Source code in <code>emu_mps/mps.py</code> <pre><code>def sample(\n    self, num_shots: int, p_false_pos: float = 0.0, p_false_neg: float = 0.0\n) -&gt; Counter[str]:\n    \"\"\"\n    Samples bitstrings, taking into account the specified error rates.\n\n    Args:\n        num_shots: how many bitstrings to sample\n        p_false_pos: the rate at which a 0 is read as a 1\n        p_false_neg: teh rate at which a 1 is read as a 0\n\n    Returns:\n        the measured bitstrings, by count\n    \"\"\"\n    self.orthogonalize(0)\n\n    num_qubits = len(self.factors)\n    rnd_matrix = torch.rand(num_shots, num_qubits)\n    bitstrings = Counter(\n        self._sample_implementation(rnd_matrix[x, :]) for x in range(num_shots)\n    )\n    if p_false_neg &gt; 0 or p_false_pos &gt; 0:\n        bitstrings = apply_measurement_errors(\n            bitstrings,\n            p_false_pos=p_false_pos,\n            p_false_neg=p_false_neg,\n        )\n    return bitstrings\n</code></pre>"},{"location":"api/#emu_mps.mps.MPS.truncate","title":"<code>truncate()</code>","text":"<p>SVD based truncation of the state. Puts the orthogonality center at the first qubit. Calls orthogonalize on the last qubit, and then sweeps a series of SVDs right-left. Uses self.config for determining accuracy. An in-place operation.</p> Source code in <code>emu_mps/mps.py</code> <pre><code>def truncate(self) -&gt; None:\n    \"\"\"\n    SVD based truncation of the state. Puts the orthogonality center at the first qubit.\n    Calls orthogonalize on the last qubit, and then sweeps a series of SVDs right-left.\n    Uses self.config for determining accuracy.\n    An in-place operation.\n    \"\"\"\n    self.orthogonalize(self.num_sites - 1)\n    truncate_impl(self.factors, config=self.config)\n    self.orthogonality_center = 0\n</code></pre>"},{"location":"api/#inner","title":"inner","text":"<p>Wrapper around MPS.inner.</p> PARAMETER DESCRIPTION <code>left</code> <p>the anti-linear argument</p> <p> TYPE: <code>MPS</code> </p> <code>right</code> <p>the linear argument</p> <p> TYPE: <code>MPS</code> </p> RETURNS DESCRIPTION <code>float | complex</code> <p>the inner product</p> Source code in <code>emu_mps/mps.py</code> <pre><code>def inner(left: MPS, right: MPS) -&gt; float | complex:\n    \"\"\"\n    Wrapper around MPS.inner.\n\n    Args:\n        left: the anti-linear argument\n        right: the linear argument\n\n    Returns:\n        the inner product\n    \"\"\"\n    return left.inner(right)\n</code></pre>"},{"location":"api/#mpo","title":"MPO","text":"<p>               Bases: <code>Operator</code></p> <p>Matrix Product Operator.</p> <p>Each tensor has 4 dimensions ordered as such: (left bond, output, input, right bond).</p> PARAMETER DESCRIPTION <code>factors</code> <p>the tensors making up the MPO</p> <p> TYPE: <code>List[Tensor]</code> </p> Source code in <code>emu_mps/mpo.py</code> <pre><code>def __init__(\n    self, factors: List[torch.Tensor], /, num_gpus_to_use: Optional[int] = None\n):\n    self.factors = factors\n    self.num_sites = len(factors)\n    if not self.num_sites &gt; 1:\n        raise ValueError(\"For 1 qubit states, do state vector\")\n    if factors[0].shape[0] != 1 or factors[-1].shape[-1] != 1:\n        raise ValueError(\n            \"The dimension of the left (right) link of the first (last) tensor should be 1\"\n        )\n    assert all(\n        factors[i - 1].shape[-1] == factors[i].shape[0]\n        for i in range(1, self.num_sites)\n    )\n\n    if num_gpus_to_use is not None:\n        assign_devices(self.factors, min(DEVICE_COUNT, num_gpus_to_use))\n</code></pre>"},{"location":"api/#emu_mps.mpo.MPO.__add__","title":"<code>__add__(other)</code>","text":"<p>Returns the sum of two MPOs, computed with a direct algorithm. The result is currently not truncated</p> PARAMETER DESCRIPTION <code>other</code> <p>the other operator</p> <p> TYPE: <code>Operator</code> </p> RETURNS DESCRIPTION <code>MPO</code> <p>the summed operator</p> Source code in <code>emu_mps/mpo.py</code> <pre><code>def __add__(self, other: Operator) -&gt; MPO:\n    \"\"\"\n    Returns the sum of two MPOs, computed with a direct algorithm.\n    The result is currently not truncated\n\n    Args:\n        other: the other operator\n\n    Returns:\n        the summed operator\n    \"\"\"\n    assert isinstance(other, MPO), \"MPO can only be added to another MPO\"\n    sum_factors = add_factors(self.factors, other.factors)\n    return MPO(sum_factors)\n</code></pre>"},{"location":"api/#emu_mps.mpo.MPO.__matmul__","title":"<code>__matmul__(other)</code>","text":"<p>Compose two operators. The ordering is that self is applied after other.</p> PARAMETER DESCRIPTION <code>other</code> <p>the operator to compose with self</p> <p> TYPE: <code>Operator</code> </p> RETURNS DESCRIPTION <code>MPO</code> <p>the composed operator</p> Source code in <code>emu_mps/mpo.py</code> <pre><code>def __matmul__(self, other: Operator) -&gt; MPO:\n    \"\"\"\n    Compose two operators. The ordering is that\n    self is applied after other.\n\n    Args:\n        other: the operator to compose with self\n\n    Returns:\n        the composed operator\n    \"\"\"\n    assert isinstance(other, MPO), \"MPO can only be applied to another MPO\"\n    factors = zip_right(self.factors, other.factors)\n    return MPO(factors)\n</code></pre>"},{"location":"api/#emu_mps.mpo.MPO.__mul__","title":"<code>__mul__(other)</code>","text":"<p>Applies this MPO to the given MPS. The returned MPS is:</p> <pre><code>- othogonal on the first site\n- truncated up to `other.precision`\n- distributed on the same devices of `other`\n</code></pre> PARAMETER DESCRIPTION <code>other</code> <p>the state to apply this operator to</p> <p> TYPE: <code>State</code> </p> RETURNS DESCRIPTION <code>MPS</code> <p>the resulting state</p> Source code in <code>emu_mps/mpo.py</code> <pre><code>def __mul__(self, other: State) -&gt; MPS:\n    \"\"\"\n    Applies this MPO to the given MPS.\n    The returned MPS is:\n\n        - othogonal on the first site\n        - truncated up to `other.precision`\n        - distributed on the same devices of `other`\n\n    Args:\n        other: the state to apply this operator to\n\n    Returns:\n        the resulting state\n    \"\"\"\n    assert isinstance(other, MPS), \"MPO can only be multiplied with MPS\"\n    factors = zip_right(\n        self.factors,\n        other.factors,\n        config=other.config,\n    )\n    return MPS(factors, orthogonality_center=0)\n</code></pre>"},{"location":"api/#emu_mps.mpo.MPO.__rmul__","title":"<code>__rmul__(scalar)</code>","text":"<p>Multiply an MPO by scalar. Assumes the orthogonal centre is on the first factor.</p> PARAMETER DESCRIPTION <code>scalar</code> <p>the scale factor to multiply with</p> <p> TYPE: <code>complex</code> </p> RETURNS DESCRIPTION <code>MPO</code> <p>the scaled MPO</p> Source code in <code>emu_mps/mpo.py</code> <pre><code>def __rmul__(self, scalar: complex) -&gt; MPO:\n    \"\"\"\n    Multiply an MPO by scalar.\n    Assumes the orthogonal centre is on the first factor.\n\n    Args:\n        scalar: the scale factor to multiply with\n\n    Returns:\n        the scaled MPO\n    \"\"\"\n    factors = scale_factors(self.factors, scalar, which=0)\n    return MPO(factors)\n</code></pre>"},{"location":"api/#emu_mps.mpo.MPO.expect","title":"<code>expect(state)</code>","text":"<p>Compute the expectation value of self on the given state.</p> PARAMETER DESCRIPTION <code>state</code> <p>the state with which to compute</p> <p> TYPE: <code>State</code> </p> RETURNS DESCRIPTION <code>float | complex</code> <p>the expectation</p> Source code in <code>emu_mps/mpo.py</code> <pre><code>def expect(self, state: State) -&gt; float | complex:\n    \"\"\"\n    Compute the expectation value of self on the given state.\n\n    Args:\n        state: the state with which to compute\n\n    Returns:\n        the expectation\n    \"\"\"\n    assert isinstance(\n        state, MPS\n    ), \"currently, only expectation values of MPSs are \\\n    supported\"\n    acc = torch.ones(\n        1, 1, 1, dtype=state.factors[0].dtype, device=state.factors[0].device\n    )\n    n = len(self.factors) - 1\n    for i in range(n):\n        acc = new_left_bath(acc, state.factors[i], self.factors[i]).to(\n            state.factors[i + 1].device\n        )\n    acc = new_left_bath(acc, state.factors[n], self.factors[n])\n    return acc.item()  # type: ignore [no-any-return]\n</code></pre>"},{"location":"api/#emu_mps.mpo.MPO.from_operator_string","title":"<code>from_operator_string(basis, nqubits, operations, operators={}, /, **kwargs)</code>  <code>staticmethod</code>","text":"<p>See the base class</p> PARAMETER DESCRIPTION <code>basis</code> <p>the eigenstates in the basis to use e.g. ('r', 'g')</p> <p> TYPE: <code>Iterable[str]</code> </p> <code>nqubits</code> <p>how many qubits there are in the state</p> <p> TYPE: <code>int</code> </p> <code>operations</code> <p>which bitstrings make up the state with what weight</p> <p> TYPE: <code>FullOp</code> </p> <code>operators</code> <p>additional symbols to be used in operations</p> <p> TYPE: <code>dict[str, QuditOp]</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>MPO</code> <p>the operator in MPO form.</p> Source code in <code>emu_mps/mpo.py</code> <pre><code>@staticmethod\ndef from_operator_string(\n    basis: Iterable[str],\n    nqubits: int,\n    operations: FullOp,\n    operators: dict[str, QuditOp] = {},\n    /,\n    **kwargs: Any,\n) -&gt; MPO:\n    \"\"\"\n    See the base class\n\n    Args:\n        basis: the eigenstates in the basis to use e.g. ('r', 'g')\n        nqubits: how many qubits there are in the state\n        operations: which bitstrings make up the state with what weight\n        operators: additional symbols to be used in operations\n\n    Returns:\n        the operator in MPO form.\n    \"\"\"\n    operators_with_tensors: dict[str, torch.Tensor | QuditOp] = dict(operators)\n\n    _validate_operator_targets(operations, nqubits)\n\n    basis = set(basis)\n    if basis == {\"r\", \"g\"}:\n        # operators_with_tensors will now contain the basis for single qubit ops,\n        # and potentially user defined strings in terms of these\n        operators_with_tensors |= {\n            \"gg\": torch.tensor(\n                [[1.0, 0.0], [0.0, 0.0]], dtype=torch.complex128\n            ).reshape(1, 2, 2, 1),\n            \"gr\": torch.tensor(\n                [[0.0, 0.0], [1.0, 0.0]], dtype=torch.complex128\n            ).reshape(1, 2, 2, 1),\n            \"rg\": torch.tensor(\n                [[0.0, 1.0], [0.0, 0.0]], dtype=torch.complex128\n            ).reshape(1, 2, 2, 1),\n            \"rr\": torch.tensor(\n                [[0.0, 0.0], [0.0, 1.0]], dtype=torch.complex128\n            ).reshape(1, 2, 2, 1),\n        }\n    elif basis == {\"0\", \"1\"}:\n        # operators_with_tensors will now contain the basis for single qubit ops,\n        # and potentially user defined strings in terms of these\n        operators_with_tensors |= {\n            \"00\": torch.tensor(\n                [[1.0, 0.0], [0.0, 0.0]], dtype=torch.complex128\n            ).reshape(1, 2, 2, 1),\n            \"01\": torch.tensor(\n                [[0.0, 0.0], [1.0, 0.0]], dtype=torch.complex128\n            ).reshape(1, 2, 2, 1),\n            \"10\": torch.tensor(\n                [[0.0, 1.0], [0.0, 0.0]], dtype=torch.complex128\n            ).reshape(1, 2, 2, 1),\n            \"11\": torch.tensor(\n                [[0.0, 0.0], [0.0, 1.0]], dtype=torch.complex128\n            ).reshape(1, 2, 2, 1),\n        }\n    else:\n        raise ValueError(\"Unsupported basis provided\")\n\n    mpos = []\n    for coeff, tensorop in operations:\n        # this function will recurse through the operators_with_tensors,\n        # and replace any definitions\n        # in terms of strings by the computed tensor\n        def replace_operator_string(op: QuditOp | torch.Tensor) -&gt; torch.Tensor:\n            if isinstance(op, torch.Tensor):\n                return op\n\n            result = torch.zeros(1, 2, 2, 1, dtype=torch.complex128)\n            for opstr, coeff in op.items():\n                tensor = replace_operator_string(operators_with_tensors[opstr])\n                operators_with_tensors[opstr] = tensor\n                result += tensor * coeff\n            return result\n\n        factors = [\n            torch.eye(2, 2, dtype=torch.complex128).reshape(1, 2, 2, 1)\n        ] * nqubits\n\n        for op in tensorop:\n            factor = replace_operator_string(op[0])\n            for target_qubit in op[1]:\n                factors[target_qubit] = factor\n\n        mpos.append(coeff * MPO(factors, **kwargs))\n    return sum(mpos[1:], start=mpos[0])\n</code></pre>"},{"location":"base_classes/","title":"Base classes","text":""},{"location":"base_classes/#backend","title":"Backend","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for different emulation backends. Forces backends to implement a run method.</p>"},{"location":"base_classes/#emu_base.base_classes.backend.Backend.run","title":"<code>run(sequence, config)</code>  <code>abstractmethod</code>","text":"<p>Emulates the given sequence.</p> PARAMETER DESCRIPTION <code>sequence</code> <p>a Pulser sequence to simulate</p> <p> TYPE: <code>Sequence</code> </p> <code>config</code> <p>the config. Should be of the appropriate type for the backend</p> <p> TYPE: <code>BackendConfig</code> </p> RETURNS DESCRIPTION <code>Results</code> <p>the simulation results</p> Source code in <code>emu_base/base_classes/backend.py</code> <pre><code>@abstractmethod\ndef run(self, sequence: Sequence, config: BackendConfig) -&gt; Results:\n    \"\"\"\n    Emulates the given sequence.\n\n    Args:\n        sequence: a Pulser sequence to simulate\n        config: the config. Should be of the appropriate type for the backend\n\n    Returns:\n        the simulation results\n    \"\"\"\n    pass\n</code></pre>"},{"location":"base_classes/#backendconfig","title":"BackendConfig","text":"<p>The base backend configuration.</p> PARAMETER DESCRIPTION <code>observables</code> <p>a list of callbacks to compute observables</p> <p> TYPE: <code>list[Callback] | None</code> DEFAULT: <code>None</code> </p> <code>with_modulation</code> <p>if True, run the sequence with hardware modulation</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>noise_model</code> <p>The pulser.NoiseModel to use in the simulation.</p> <p> TYPE: <code>NoiseModel</code> DEFAULT: <code>None</code> </p> <code>interaction_matrix</code> <p>When specified, override the interaction terms in the Hamiltonian. This corresponds to the \\(U_{ij}\\) terms in the documentation. Must be symmetric.</p> <p> TYPE: <code>list[list[float]] | None</code> DEFAULT: <code>None</code> </p> <code>interaction_cutoff</code> <p>set interaction coefficients smaller than this to 0. This can improve the memory profile of the application for some backends.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> <code>log_level</code> <p>The output verbosity. Should be one of the constants from logging.</p> <p> TYPE: <code>int</code> DEFAULT: <code>INFO</code> </p> <code>log_file</code> <p>a path to a file where to store the log, instead of printing to stdout</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; observables = [BitStrings(400, 100)] #compute 100 bitstrings at 400ns\n&gt;&gt;&gt; noise_model = pulser.noise_model.NoiseModel()\n&gt;&gt;&gt; interaction_matrix = [[1 for _ in range(nqubits)] for _ in range(nqubits)]\n&gt;&gt;&gt; interaction_cutoff = 2.0 #this will turn off all the above interactions again\n&gt;&gt;&gt; log_level = logging.warn\n</code></pre> Source code in <code>emu_base/base_classes/config.py</code> <pre><code>def __init__(\n    self,\n    *,\n    observables: list[Callback] | None = None,\n    with_modulation: bool = False,\n    noise_model: NoiseModel = None,\n    interaction_matrix: list[list[float]] | None = None,\n    interaction_cutoff: float = 0.0,\n    log_level: int = logging.INFO,\n    log_file: pathlib.Path | None = None,\n):\n    if observables is None:\n        observables = []\n    self.callbacks = (\n        observables  # we can add other types of callbacks, and just stack them\n    )\n    self.with_modulation = with_modulation\n    self.noise_model = noise_model\n\n    if interaction_matrix is not None and not (\n        isinstance(interaction_matrix, list)\n        and isinstance(interaction_matrix[0], list)\n        and isinstance(interaction_matrix[0][0], float)\n    ):\n        raise ValueError(\n            \"Interaction matrix must be provided as a Python list of lists of floats\"\n        )\n\n    if interaction_matrix is not None:\n        int_mat = torch.tensor(interaction_matrix)\n        tol = 1e-10\n        if not (\n            int_mat.numel() != 0\n            and torch.all(torch.isreal(int_mat))\n            and int_mat.dim() == 2\n            and int_mat.shape[0] == int_mat.shape[1]\n            and torch.allclose(int_mat, int_mat.T, atol=tol)\n            and torch.norm(torch.diag(int_mat)) &lt; tol\n        ):\n            raise ValueError(\"Interaction matrix is not symmetric and zero diag\")\n\n    self.interaction_matrix = interaction_matrix\n    self.interaction_cutoff = interaction_cutoff\n    self.logger = logging.getLogger(\"global_logger\")\n    self.log_file = log_file\n    self.log_level = log_level\n\n    self.init_logging()\n\n    if noise_model is not None and (\n        noise_model.runs != 1\n        or noise_model.samples_per_run != 1\n        or noise_model.runs is not None\n        or noise_model.samples_per_run is not None\n    ):\n        self.logger.warning(\n            \"Warning: The runs and samples_per_run values of the NoiseModel are ignored!\"\n        )\n</code></pre>"},{"location":"base_classes/#results","title":"Results","text":"<p>This class contains emulation results. Since the results written by an emulator are defined through callbacks, the contents of this class are not known a-priori.</p>"},{"location":"base_classes/#emu_base.base_classes.results.Results.get_result","title":"<code>get_result(name, time)</code>","text":"<p>get the given result at the given time</p> PARAMETER DESCRIPTION <code>name</code> <p>name of the result to get</p> <p> TYPE: <code>str</code> </p> <code>time</code> <p>time in ns at which to get the result</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>the result</p> Source code in <code>emu_base/base_classes/results.py</code> <pre><code>def get_result(self, name: str, time: int) -&gt; Any:\n    \"\"\"\n    get the given result at the given time\n\n    Args:\n        name: name of the result to get\n        time: time in ns at which to get the result\n\n    Returns:\n        the result\n\n    \"\"\"\n    return self._results[name][time]\n</code></pre>"},{"location":"base_classes/#emu_base.base_classes.results.Results.get_result_names","title":"<code>get_result_names()</code>","text":"<p>get a list of results present in this object</p> <p>Args:</p> RETURNS DESCRIPTION <code>list[str]</code> <p>list of results by name</p> Source code in <code>emu_base/base_classes/results.py</code> <pre><code>def get_result_names(self) -&gt; list[str]:\n    \"\"\"\n    get a list of results present in this object\n\n    Args:\n\n    Returns:\n        list of results by name\n\n    \"\"\"\n    return list(self._results.keys())\n</code></pre>"},{"location":"base_classes/#emu_base.base_classes.results.Results.get_result_times","title":"<code>get_result_times(name)</code>","text":"<p>get a list of times for which the given result has been stored</p> PARAMETER DESCRIPTION <code>name</code> <p>name of the result to get times of</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>list[int]</code> <p>list of times in ns</p> Source code in <code>emu_base/base_classes/results.py</code> <pre><code>def get_result_times(self, name: str) -&gt; list[int]:\n    \"\"\"\n    get a list of times for which the given result has been stored\n\n    Args:\n        name: name of the result to get times of\n\n    Returns:\n        list of times in ns\n\n    \"\"\"\n    return list(self._results[name].keys())\n</code></pre>"},{"location":"base_classes/#state","title":"State","text":"<p>               Bases: <code>ABC</code></p> <p>Base class enforcing an API for quantum states. Each backend will implement its own type of state, and the below methods.</p>"},{"location":"base_classes/#emu_base.base_classes.state.State.__add__","title":"<code>__add__(other)</code>  <code>abstractmethod</code>","text":"<p>Computes the sum of two states.</p> PARAMETER DESCRIPTION <code>other</code> <p>the other state</p> <p> TYPE: <code>State</code> </p> RETURNS DESCRIPTION <code>State</code> <p>the summed state</p> Source code in <code>emu_base/base_classes/state.py</code> <pre><code>@abstractmethod\ndef __add__(self, other: State) -&gt; State:\n    \"\"\"\n    Computes the sum of two states.\n\n    Args:\n        other: the other state\n\n    Returns:\n        the summed state\n    \"\"\"\n    pass\n</code></pre>"},{"location":"base_classes/#emu_base.base_classes.state.State.__rmul__","title":"<code>__rmul__(scalar)</code>  <code>abstractmethod</code>","text":"<p>Scale the state by a scale factor.</p> PARAMETER DESCRIPTION <code>scalar</code> <p>the scale factor</p> <p> TYPE: <code>complex</code> </p> RETURNS DESCRIPTION <code>State</code> <p>the scaled state</p> Source code in <code>emu_base/base_classes/state.py</code> <pre><code>@abstractmethod\ndef __rmul__(self, scalar: complex) -&gt; State:\n    \"\"\"\n    Scale the state by a scale factor.\n\n    Args:\n        scalar: the scale factor\n\n    Returns:\n        the scaled state\n    \"\"\"\n    pass\n</code></pre>"},{"location":"base_classes/#emu_base.base_classes.state.State.from_state_string","title":"<code>from_state_string(*, basis, nqubits, strings, **kwargs)</code>  <code>abstractmethod</code> <code>staticmethod</code>","text":"<p>Construct a state from the pulser abstract representation https://www.notion.so/pasqal/Abstract-State-and-Operator-Definition For a list of existing bases, see https://pulser.readthedocs.io/en/stable/conventions.html</p> PARAMETER DESCRIPTION <code>basis</code> <p>A tuple containing the basis states.</p> <p> TYPE: <code>Iterable[str]</code> </p> <code>nqubits</code> <p>the number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>strings</code> <p>A dictionary mapping state strings to complex or floats amplitudes</p> <p> TYPE: <code>dict[str, complex]</code> </p> RETURNS DESCRIPTION <code>State</code> <p>the state in whatever format the backend provides.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; afm_string_state = {\"rrr\": 1.0 / math.sqrt(2), \"ggg\": 1.0 / math.sqrt(2)}\n&gt;&gt;&gt; afm_state = State.from_state_string(\n&gt;&gt;&gt;     basis=(\"r\", \"g\"), nqubits=3, strings=afm_string_state\n&gt;&gt;&gt; )\n</code></pre> Source code in <code>emu_base/base_classes/state.py</code> <pre><code>@staticmethod\n@abstractmethod\ndef from_state_string(\n    *, basis: Iterable[str], nqubits: int, strings: dict[str, complex], **kwargs: Any\n) -&gt; State:\n    \"\"\"\n    Construct a state from the pulser abstract representation\n    &lt;https://www.notion.so/pasqal/Abstract-State-and-Operator-Definition&gt;\n    For a list of existing bases, see\n    &lt;https://pulser.readthedocs.io/en/stable/conventions.html&gt;\n\n    Args:\n        basis: A tuple containing the basis states.\n        nqubits: the number of qubits.\n        strings: A dictionary mapping state strings to complex or floats amplitudes\n\n    Returns:\n        the state in whatever format the backend provides.\n\n    Examples:\n        &gt;&gt;&gt; afm_string_state = {\"rrr\": 1.0 / math.sqrt(2), \"ggg\": 1.0 / math.sqrt(2)}\n        &gt;&gt;&gt; afm_state = State.from_state_string(\n        &gt;&gt;&gt;     basis=(\"r\", \"g\"), nqubits=3, strings=afm_string_state\n        &gt;&gt;&gt; )\n    \"\"\"\n    pass\n</code></pre>"},{"location":"base_classes/#emu_base.base_classes.state.State.inner","title":"<code>inner(other)</code>  <code>abstractmethod</code>","text":"<p>Compute the inner product between this state and other. Note that self is the left state in the inner product, so this function is linear in other, and anti-linear in self</p> PARAMETER DESCRIPTION <code>other</code> <p>the other state</p> <p> TYPE: <code>State</code> </p> RETURNS DESCRIPTION <code>float | complex</code> <p>inner product</p> Source code in <code>emu_base/base_classes/state.py</code> <pre><code>@abstractmethod\ndef inner(self, other: State) -&gt; float | complex:\n    \"\"\"\n    Compute the inner product between this state and other.\n    Note that self is the left state in the inner product,\n    so this function is linear in other, and anti-linear in self\n\n    Args:\n        other: the other state\n\n    Returns:\n        inner product\n    \"\"\"\n    pass\n</code></pre>"},{"location":"base_classes/#emu_base.base_classes.state.State.sample","title":"<code>sample(num_shots, p_false_pos=0.0, p_false_neg=0.0)</code>  <code>abstractmethod</code>","text":"<p>Sample bitstrings from the state, taking into account error rates.</p> PARAMETER DESCRIPTION <code>num_shots</code> <p>how many bitstrings to sample</p> <p> TYPE: <code>int</code> </p> <code>p_false_pos</code> <p>the rate at which a 0 is read as a 1</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> <code>p_false_neg</code> <p>the rate at which a 1 is read as a 0</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> RETURNS DESCRIPTION <code>Counter[str]</code> <p>the measured bitstrings, by count</p> Source code in <code>emu_base/base_classes/state.py</code> <pre><code>@abstractmethod\ndef sample(\n    self, num_shots: int, p_false_pos: float = 0.0, p_false_neg: float = 0.0\n) -&gt; Counter[str]:\n    \"\"\"\n    Sample bitstrings from the state, taking into account error rates.\n\n    Args:\n        num_shots: how many bitstrings to sample\n        p_false_pos: the rate at which a 0 is read as a 1\n        p_false_neg: the rate at which a 1 is read as a 0\n\n    Returns:\n        the measured bitstrings, by count\n    \"\"\"\n    pass\n</code></pre>"},{"location":"base_classes/#operator","title":"Operator","text":"<p>               Bases: <code>ABC</code></p>"},{"location":"base_classes/#emu_base.base_classes.operator.Operator.__add__","title":"<code>__add__(other)</code>  <code>abstractmethod</code>","text":"<p>Computes the sum of two operators.</p> PARAMETER DESCRIPTION <code>other</code> <p>the other operator</p> <p> TYPE: <code>Operator</code> </p> RETURNS DESCRIPTION <code>Operator</code> <p>the summed operator</p> Source code in <code>emu_base/base_classes/operator.py</code> <pre><code>@abstractmethod\ndef __add__(self, other: Operator) -&gt; Operator:\n    \"\"\"\n    Computes the sum of two operators.\n\n    Args:\n        other: the other operator\n\n    Returns:\n       the summed operator\n    \"\"\"\n    pass\n</code></pre>"},{"location":"base_classes/#emu_base.base_classes.operator.Operator.__matmul__","title":"<code>__matmul__(other)</code>  <code>abstractmethod</code>","text":"<p>Compose two operators. The ordering is that self is applied after other.</p> PARAMETER DESCRIPTION <code>other</code> <p>the operator to compose with self</p> <p> TYPE: <code>Operator</code> </p> RETURNS DESCRIPTION <code>Operator</code> <p>the composed operator</p> Source code in <code>emu_base/base_classes/operator.py</code> <pre><code>@abstractmethod\ndef __matmul__(self, other: Operator) -&gt; Operator:\n    \"\"\"\n    Compose two operators. The ordering is that\n    self is applied after other.\n\n    Args:\n        other: the operator to compose with self\n\n    Returns:\n        the composed operator\n    \"\"\"\n    pass\n</code></pre>"},{"location":"base_classes/#emu_base.base_classes.operator.Operator.__mul__","title":"<code>__mul__(other)</code>  <code>abstractmethod</code>","text":"<p>Apply the operator to a state</p> PARAMETER DESCRIPTION <code>other</code> <p>the state to apply this operator to</p> <p> TYPE: <code>State</code> </p> RETURNS DESCRIPTION <code>State</code> <p>the resulting state</p> Source code in <code>emu_base/base_classes/operator.py</code> <pre><code>@abstractmethod\ndef __mul__(self, other: State) -&gt; State:\n    \"\"\"\n    Apply the operator to a state\n\n    Args:\n        other: the state to apply this operator to\n\n    Returns:\n        the resulting state\n    \"\"\"\n    pass\n</code></pre>"},{"location":"base_classes/#emu_base.base_classes.operator.Operator.__rmul__","title":"<code>__rmul__(scalar)</code>  <code>abstractmethod</code>","text":"<p>Scale the operator by a scale factor.</p> PARAMETER DESCRIPTION <code>scalar</code> <p>the scale factor</p> <p> TYPE: <code>complex</code> </p> RETURNS DESCRIPTION <code>Operator</code> <p>the scaled operator</p> Source code in <code>emu_base/base_classes/operator.py</code> <pre><code>@abstractmethod\ndef __rmul__(self, scalar: complex) -&gt; Operator:\n    \"\"\"\n    Scale the operator by a scale factor.\n\n    Args:\n        scalar: the scale factor\n\n    Returns:\n        the scaled operator\n    \"\"\"\n    pass\n</code></pre>"},{"location":"base_classes/#emu_base.base_classes.operator.Operator.expect","title":"<code>expect(state)</code>  <code>abstractmethod</code>","text":"<p>Compute the expectation value of self on the given state.</p> PARAMETER DESCRIPTION <code>state</code> <p>the state with which to compute</p> <p> TYPE: <code>State</code> </p> RETURNS DESCRIPTION <code>float | complex</code> <p>the expectation</p> Source code in <code>emu_base/base_classes/operator.py</code> <pre><code>@abstractmethod\ndef expect(self, state: State) -&gt; float | complex:\n    \"\"\"\n    Compute the expectation value of self on the given state.\n\n    Args:\n        state: the state with which to compute\n\n    Returns:\n        the expectation\n    \"\"\"\n</code></pre>"},{"location":"base_classes/#emu_base.base_classes.operator.Operator.from_operator_string","title":"<code>from_operator_string(basis, nqubits, operations, operators={}, /, **kwargs)</code>  <code>abstractmethod</code> <code>staticmethod</code>","text":"<p>Create an operator in the backend-specific format from the pulser abstract representation https://www.notion.so/pasqal/Abstract-State-and-Operator-Definition By default it supports strings 'ij', where i and j in basis, to denote |i&gt;&lt;j|, but additional symbols can be defined in operators For a list of existing bases, see https://pulser.readthedocs.io/en/stable/conventions.html</p> PARAMETER DESCRIPTION <code>basis</code> <p>the eigenstates in the basis to use</p> <p> TYPE: <code>Iterable[str]</code> </p> <code>nqubits</code> <p>how many qubits there are in the state</p> <p> TYPE: <code>int</code> </p> <code>operations</code> <p>which bitstrings make up the state with what weight</p> <p> TYPE: <code>FullOp</code> </p> <code>operators</code> <p>additional symbols to be used in operations</p> <p> TYPE: <code>dict[str, QuditOp]</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>Operator</code> <p>the operator in whatever format the backend provides.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; basis = {\"r\", \"g\"} #rydberg basis\n&gt;&gt;&gt; nqubits = 3 #or whatever\n&gt;&gt;&gt; x = {\"rg\": 1.0, \"gr\": 1.0}\n&gt;&gt;&gt; z = {\"gg\": 1.0, \"rr\": -1.0}\n&gt;&gt;&gt; operators = {\"X\": x, \"Z\": z} #define X and Z as conveniences\n&gt;&gt;&gt;\n&gt;&gt;&gt; operations = [ # 4 X1X + 3 1Z1\n&gt;&gt;&gt;     (\n&gt;&gt;&gt;         1.0,\n&gt;&gt;&gt;         [\n&gt;&gt;&gt;             ({\"X\": 2.0}, [0, 2]),\n&gt;&gt;&gt;             ({\"Z\": 3.0}, [1]),\n&gt;&gt;&gt;         ],\n&gt;&gt;&gt;     )\n&gt;&gt;&gt; ]\n&gt;&gt;&gt; op = Operator.from_operator_string(basis, nqubits, operations, operators)\n</code></pre> Source code in <code>emu_base/base_classes/operator.py</code> <pre><code>@staticmethod\n@abstractmethod\ndef from_operator_string(\n    basis: Iterable[str],\n    nqubits: int,\n    operations: FullOp,\n    operators: dict[str, QuditOp] = {},\n    /,\n    **kwargs: Any,\n) -&gt; Operator:\n    \"\"\"\n    Create an operator in the backend-specific format from the\n    pulser abstract representation\n    &lt;https://www.notion.so/pasqal/Abstract-State-and-Operator-Definition&gt;\n    By default it supports strings 'ij', where i and j in basis,\n    to denote |i&gt;&lt;j|, but additional symbols can be defined in operators\n    For a list of existing bases, see\n    &lt;https://pulser.readthedocs.io/en/stable/conventions.html&gt;\n\n    Args:\n        basis: the eigenstates in the basis to use\n        nqubits: how many qubits there are in the state\n        operations: which bitstrings make up the state with what weight\n        operators: additional symbols to be used in operations\n\n    Returns:\n        the operator in whatever format the backend provides.\n\n    Examples:\n        &gt;&gt;&gt; basis = {\"r\", \"g\"} #rydberg basis\n        &gt;&gt;&gt; nqubits = 3 #or whatever\n        &gt;&gt;&gt; x = {\"rg\": 1.0, \"gr\": 1.0}\n        &gt;&gt;&gt; z = {\"gg\": 1.0, \"rr\": -1.0}\n        &gt;&gt;&gt; operators = {\"X\": x, \"Z\": z} #define X and Z as conveniences\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; operations = [ # 4 X1X + 3 1Z1\n        &gt;&gt;&gt;     (\n        &gt;&gt;&gt;         1.0,\n        &gt;&gt;&gt;         [\n        &gt;&gt;&gt;             ({\"X\": 2.0}, [0, 2]),\n        &gt;&gt;&gt;             ({\"Z\": 3.0}, [1]),\n        &gt;&gt;&gt;         ],\n        &gt;&gt;&gt;     )\n        &gt;&gt;&gt; ]\n        &gt;&gt;&gt; op = Operator.from_operator_string(basis, nqubits, operations, operators)\n    \"\"\"\n    pass\n</code></pre>"},{"location":"base_classes/#callback","title":"Callback","text":"<p>               Bases: <code>ABC</code></p> <p>The callback base class that can be subclassed to add new kinds of results to the Results object returned by the Backend</p> PARAMETER DESCRIPTION <code>evaluation_times</code> <p>the times at which to add a result to Results</p> <p> TYPE: <code>set[int]</code> </p> Source code in <code>emu_base/base_classes/callback.py</code> <pre><code>def __init__(self, evaluation_times: set[int]):\n    \"\"\"\n    The callback base class that can be subclassed to add new kinds of results\n    to the Results object returned by the Backend\n\n    Args:\n        evaluation_times: the times at which to add a result to Results\n    \"\"\"\n    self.evaluation_times = evaluation_times\n</code></pre>"},{"location":"base_classes/#emu_base.base_classes.callback.Callback.default_aggregation_type","title":"<code>default_aggregation_type: Optional[AggregationType]</code>  <code>property</code>","text":"<p>Defines how to combine by default multiple values from different simulation results. None means no default, therefore aggregator function is always user-provided.</p>"},{"location":"base_classes/#emu_base.base_classes.callback.Callback.name","title":"<code>name: str</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>The name of the observable, can be used to index into the Results object. Some Callbacks might have multiple instances, such as a callback to compute a fidelity on some given state. In that case, this method could make sure each instance has a unique name.</p> RETURNS DESCRIPTION <code>str</code> <p>the name of the callback</p>"},{"location":"base_classes/#emu_base.base_classes.callback.Callback.__call__","title":"<code>__call__(config, t, state, H, result)</code>","text":"<p>This function is called after each time step performed by the emulator. By default it calls apply to compute a result and put it in <code>result</code> if <code>t</code> in <code>self.evaluation_times</code>. It can be overloaded to define any custom behaviour for a <code>Callback</code>.</p> PARAMETER DESCRIPTION <code>config</code> <p>the config object passed to the run method</p> <p> TYPE: <code>BackendConfig</code> </p> <code>t</code> <p>the current time in ns</p> <p> TYPE: <code>int</code> </p> <code>state</code> <p>the current state</p> <p> TYPE: <code>State</code> </p> <code>H</code> <p>the Hamiltonian at this time</p> <p> TYPE: <code>Operator</code> </p> <code>result</code> <p>the results object</p> <p> TYPE: <code>Results</code> </p> Source code in <code>emu_base/base_classes/callback.py</code> <pre><code>def __call__(\n    self, config: BackendConfig, t: int, state: State, H: Operator, result: \"Results\"\n) -&gt; None:\n    \"\"\"\n    This function is called after each time step performed by the emulator.\n    By default it calls apply to compute a result and put it in `result`\n    if `t` in `self.evaluation_times`.\n    It can be overloaded to define any custom behaviour for a `Callback`.\n\n    Args:\n        config: the config object passed to the run method\n        t: the current time in ns\n        state: the current state\n        H: the Hamiltonian at this time\n        result: the results object\n    \"\"\"\n    if t in self.evaluation_times:\n        value_to_store = self.apply(config, t, state, H)\n        result.store(callback=self, time=t, value=value_to_store)\n</code></pre>"},{"location":"base_classes/#emu_base.base_classes.callback.Callback.apply","title":"<code>apply(config, t, state, H)</code>  <code>abstractmethod</code>","text":"<p>This method must be implemented by subclasses. The result of this method gets put in the Results object.</p> PARAMETER DESCRIPTION <code>config</code> <p>the config object passed to the run method</p> <p> TYPE: <code>BackendConfig</code> </p> <code>t</code> <p>the current time in ns</p> <p> TYPE: <code>int</code> </p> <code>state</code> <p>the current state</p> <p> TYPE: <code>State</code> </p> <code>H</code> <p>the Hamiltonian at this time</p> <p> TYPE: <code>Operator</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>the result to put in Results</p> Source code in <code>emu_base/base_classes/callback.py</code> <pre><code>@abstractmethod\ndef apply(self, config: BackendConfig, t: int, state: State, H: Operator) -&gt; Any:\n    \"\"\"\n    This method must be implemented by subclasses. The result of this method\n    gets put in the Results object.\n\n    Args:\n        config: the config object passed to the run method\n        t: the current time in ns\n        state: the current state\n        H: the Hamiltonian at this time\n\n    Returns:\n        the result to put in Results\n    \"\"\"\n    pass\n</code></pre>"},{"location":"observables/","title":"The callback mechanism","text":"<p>Since the desired output of the emulator can be quite user dependent, emu-mps uses a callback mechanism to specify its output. The available callbacks, together with examples for how to create them are on this page. How to use created callbacks to obtain results from an emulation is shown in the example notebooks (here).</p> <p>The following default callbacks are available:</p>"},{"location":"observables/#stateresult","title":"StateResult","text":"<p>               Bases: <code>Callback</code></p> <p>Store the quantum state in whatever format the backend provides</p> PARAMETER DESCRIPTION <code>evaluation_times</code> <p>the times at which to store the state</p> <p> TYPE: <code>set[int]</code> </p> Source code in <code>emu_base/base_classes/default_callbacks.py</code> <pre><code>def __init__(self, evaluation_times: set[int]):\n    super().__init__(evaluation_times)\n</code></pre>"},{"location":"observables/#bitstrings","title":"BitStrings","text":"<p>               Bases: <code>Callback</code></p> <p>Store bitstrings sampled from the current state. Error rates are taken from the config passed to the run method of the backend. The bitstrings are stored as a Counter[str].</p> PARAMETER DESCRIPTION <code>evaluation_times</code> <p>the times at which to sample bitstrings</p> <p> TYPE: <code>set[int]</code> </p> <code>num_shots</code> <p>how many bitstrings to sample each time this observable is computed</p> <p> TYPE: <code>int</code> DEFAULT: <code>1000</code> </p> Source code in <code>emu_base/base_classes/default_callbacks.py</code> <pre><code>def __init__(self, evaluation_times: set[int], num_shots: int = 1000):\n    super().__init__(evaluation_times)\n    self.num_shots = num_shots\n</code></pre>"},{"location":"observables/#fidelity","title":"Fidelity","text":"<p>               Bases: <code>Callback</code></p> <p>Store \\(&lt;\u03c8|\u03c6(t)&gt;\\) for the given state \\(|\u03c8&gt;\\), and the state \\(|\u03c6(t)&gt;\\) obtained by time evolution.</p> PARAMETER DESCRIPTION <code>evaluation_times</code> <p>the times at which to compute the fidelity</p> <p> TYPE: <code>set[int]</code> </p> <code>state</code> <p>the state |\u03c8&gt;. Note that this must be of appropriate type for the backend</p> <p> TYPE: <code>State</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; state = State.from_state_string(...) #see State API\n&gt;&gt;&gt; fidelity = Fidelity([400], state) #measure fidelity on state at t=400ns\n</code></pre> Source code in <code>emu_base/base_classes/default_callbacks.py</code> <pre><code>def __init__(self, evaluation_times: set[int], state: State):\n    super().__init__(evaluation_times)\n    global _fidelity_counter\n    _fidelity_counter += 1\n    self.index = _fidelity_counter\n    self.state = state\n</code></pre>"},{"location":"observables/#expectation","title":"Expectation","text":"<p>               Bases: <code>Callback</code></p> <p>Store the expectation of the given operator on the current state (i.e. \\(\\langle \u03c6(t)|\\mathrm{operator}|\u03c6(t)\\rangle\\)).</p> PARAMETER DESCRIPTION <code>evaluation_times</code> <p>the times at which to compute the expectation</p> <p> TYPE: <code>set[int]</code> </p> <code>operator</code> <p>the operator to measure. Must be of appropriate type for the backend.</p> <p> TYPE: <code>Operator</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; op = Operator.from_operator_string(...) #see Operator API\n&gt;&gt;&gt; expectation = Expectation([400], op) #measure the expecation of op at t=400ns\n</code></pre> Source code in <code>emu_base/base_classes/default_callbacks.py</code> <pre><code>def __init__(self, evaluation_times: set[int], operator: Operator):\n    super().__init__(evaluation_times)\n    global _expectation_counter\n    _expectation_counter += 1\n    self.index = _expectation_counter\n    self.operator = operator\n</code></pre>"},{"location":"observables/#correlationmatrix","title":"CorrelationMatrix","text":"<p>               Bases: <code>Callback</code></p> <p>Store the correlation matrix for the current state. Requires specification of the basis used in the emulation https://pulser.readthedocs.io/en/stable/conventions.html It currently supports - the rydberg basis ('r','g') - the xy basis ('0', '1') and returns</p> <p><code>[[&lt;\u03c6(t)|n_i n_j|\u03c6(t)&gt; for j in qubits] for i in qubits]</code></p> <p>n_i being the operator that projects qubit i onto the state that measures as 1. The diagonal of this matrix is the QubitDensity. The correlation matrix is stored as a list of lists.</p> PARAMETER DESCRIPTION <code>evaluation_times</code> <p>the times at which to compute the correlation matrix</p> <p> TYPE: <code>set[int]</code> </p> <code>basis</code> <p>the basis used by the sequence</p> <p> TYPE: <code>tuple[str, ...]</code> </p> <code>nqubits</code> <p>the number of qubits in the Register</p> <p> TYPE: <code>int</code> </p> Notes <p>See the API for <code>Operator.from_operator_string</code> for an example of what to do with basis and nqubits.</p> Source code in <code>emu_base/base_classes/default_callbacks.py</code> <pre><code>def __init__(self, evaluation_times: set[int], basis: tuple[str, ...], nqubits: int):\n    super().__init__(evaluation_times)\n    self.operators: list[list[Operator]] | None = None\n    self.basis = set(basis)\n    if self.basis == {\"r\", \"g\"}:\n        self.op_string = \"rr\"\n    elif self.basis == {\"0\", \"1\"}:\n        self.op_string = \"11\"\n    else:\n        raise ValueError(\"Unsupported basis provided\")\n    self.nqubits = nqubits\n</code></pre>"},{"location":"observables/#qubitdensity","title":"QubitDensity","text":"<p>               Bases: <code>Callback</code></p> <p>Requires specification of the basis used in the emulation https://pulser.readthedocs.io/en/stable/conventions.html It currently supports - the rydberg basis ('r','g') - the xy basis ('0', '1') and returns</p> <p><code>[&lt;\u03c6(t)|n_i|\u03c6(t)&gt; for i in qubits]</code></p> <p>n_i being the operator that projects qubit i onto the state that measures as 1. The qubit density is stored as a list.</p> PARAMETER DESCRIPTION <code>evaluation_times</code> <p>the times at which to compute the density</p> <p> TYPE: <code>set[int]</code> </p> <code>basis</code> <p>the basis used by the sequence</p> <p> TYPE: <code>tuple[str, ...]</code> </p> <code>nqubits</code> <p>the number of qubits in the Register</p> <p> TYPE: <code>int</code> </p> Notes <p>See the API for <code>State.from_state_string</code> for an example of what to do with basis and nqubits.</p> Source code in <code>emu_base/base_classes/default_callbacks.py</code> <pre><code>def __init__(self, evaluation_times: set[int], basis: tuple[str, ...], nqubits: int):\n    super().__init__(evaluation_times)\n    self.operators: list[Operator] | None = None\n    self.basis = set(basis)\n    if self.basis == {\"r\", \"g\"}:\n        self.op_string = \"rr\"\n    elif self.basis == {\"0\", \"1\"}:\n        self.op_string = \"11\"\n    else:\n        raise ValueError(\"Unsupported basis provided\")\n    self.nqubits = nqubits\n</code></pre>"},{"location":"observables/#energy","title":"Energy","text":"<p>               Bases: <code>Callback</code></p> <p>Store the expectation value of the current Hamiltonian (i.e. \\(\\langle \u03c6(t)|H(t)|\u03c6(t) \\rangle\\))</p> PARAMETER DESCRIPTION <code>evaluation_times</code> <p>the times at which to compute the expectation</p> <p> TYPE: <code>set[int]</code> </p> Source code in <code>emu_base/base_classes/default_callbacks.py</code> <pre><code>def __init__(self, evaluation_times: set[int]):\n    super().__init__(evaluation_times)\n</code></pre>"},{"location":"observables/#secondmomentofenergy","title":"SecondMomentOfEnergy","text":"<p>               Bases: <code>Callback</code></p> <p>Store the expectation value \\(\\langle \u03c6(t)|H(t)^2|\u03c6(t)\\rangle\\). Useful for computing the variance when averaging over many executions of the program.</p> PARAMETER DESCRIPTION <code>evaluation_times</code> <p>the times at which to compute the variance</p> <p> TYPE: <code>set[int]</code> </p> Source code in <code>emu_base/base_classes/default_callbacks.py</code> <pre><code>def __init__(self, evaluation_times: set[int]):\n    super().__init__(evaluation_times)\n</code></pre>"},{"location":"observables/#energyvariance","title":"EnergyVariance","text":"<p>               Bases: <code>Callback</code></p> <p>Store the variance of the current Hamiltonian (i.e. \\(\\langle \u03c6(t)|H(t)^2|\u03c6(t)\\rangle - \\langle \u03c6(t)|H(t)|\u03c6(t)\\rangle^2\\))</p> PARAMETER DESCRIPTION <code>evaluation_times</code> <p>the times at which to compute the variance</p> <p> TYPE: <code>set[int]</code> </p> Source code in <code>emu_base/base_classes/default_callbacks.py</code> <pre><code>def __init__(self, evaluation_times: set[int]):\n    super().__init__(evaluation_times)\n</code></pre>"},{"location":"observables/#defining-your-own-callbacks","title":"Defining your own callbacks","text":"<p>Most commonly desired information can be obtained using the classes documented above</p> <ul> <li>arbitrary observables can be measured using <code>Expectation</code></li> <li>fidelities on arbitrary states can be computed using <code>Fidelity</code></li> <li>Information about the time dependent states and Hamiltonians is available via <code>StateResult</code>, <code>Energy</code> etc.</li> </ul> <p>If additional behaviour is desired (e.g. the kurtosis of the energy, or entanglement entropy), the user can subclass the <code>Callback</code> class to implement any behaviour only depending on the parameters of its <code>__call__</code> method (see here). Computation of the entanglement entropy, for example, cannot be done in a backend-independent manner, so it is unlikely to ever make it into the above default list. However, we do intend to define backend-specific callbacks in the future, which would belong to the API of a specific backend. Callbacks that can be implemented in a backend-independent manner can be added to the above list upon popular request.</p>"},{"location":"advanced/","title":"Advanced topics","text":"<p>You have reached the advanced topics. Links to the individual pages discussing the various topics can be found in the sidebar to the left. The content here all relates to the inner workings of emu-mps and is more conceptual in nature. You will not find information here about how to actually run a simulation, but rather</p> <ul> <li>What Hamiltonian the emulator uses for time-evolution</li> <li>Some relevant information about the MPS representation</li> <li>A summary of the TDVP algorithm</li> <li>What sources of error TDVP incurs</li> <li>What the various configuration parameters mean mathematically</li> <li>How to determine whether your results are accurate</li> <li>How to estimate the memory consumption and the runtime of a simulation in advance</li> </ul> <p>For the experienced user, this will help get the most out of emu-mps.</p>"},{"location":"advanced/config/","title":"Explanation of config values","text":"<p>The following config values to emu-mps relate to the functioning of the tdvp algorithm used to evolve the quantum state in time, and will be explained in more detail below:</p> <ul> <li>dt</li> <li>precision</li> <li>max_bond_dim</li> <li>max_krylov_dim</li> <li>extra_krylov_tolerance</li> </ul>"},{"location":"advanced/config/#dt","title":"dt","text":"<p>Note that emu-mps assumes the Hamiltonian is piece-wise constant in time for intervals of <code>dt</code>. It then constructs the Hamiltonian by sampling the amplitude, detuning and phase of the pulse midway through the interval, and making a single Hamiltonian. The TDVP algorithm is then used to evolve the state by <code>dt</code>. There are two sources of error related to <code>dt</code>.</p> <ul> <li>The discretization of the pulse</li> <li>TDVP</li> </ul> <p>Both sources of error dictate that <code>dt</code> shall not be too small, but the functioning of TDVP also dictates that a very small <code>dt</code> requires improving the precision, as described in the next section.</p>"},{"location":"advanced/config/#precision","title":"precision","text":"<p>The 2-site TDVP algorithm used in emu-mps works by repeatedly time-evolving two neighbouring qubits in the MPS, and then truncating the result. Truncation is done by applying an SVD to the matrix representing the 2-qubit subsystem. The singular values give much information about the state. Denote the singular values by \\(d_i\\), and assume they are ordered in decreasing magnitude. Then the norm of the state will be \\(\\sum_i d_i^2\\) and the entanglement entropy between the left and right parts of the state will be \\(\\sum_i d_i \\log_2(d_i)\\), for example.</p> <p>The truncation mentioned above functions by throwing away the smallest singular values, until their squared sum exceeds \\(precision^2\\). The result is that the truncation procedure finds the smallest MPS whose distance is less than <code>precision</code> away from the original state. As described on the page of errors in TDVP, the error in TDVP increases with the number of timesteps, so for long sequences or small <code>dt</code>, improving the precision might be required.</p>"},{"location":"advanced/config/#max_bond_dim","title":"max_bond_dim","text":"<p>In addition to the above procedure, at each truncation step, no more than <code>max_bond_dim</code> singular values are kept. This parameter will impose a hard cap on the memory consumed by the quantum state, at the cost of losing control over the magnitude of the truncation errors.</p>"},{"location":"advanced/config/#max_krylov_dim","title":"max_krylov_dim","text":"<p>Time evolution of each qubit pair is done by the Lanczos algorithm. This algorithm works by iteratively constructing a basis in which the Hamiltonian is close to diagonal. In this basis, the time-evolution of the state can efficiently be approximated by exponentiating a truncated Hamiltonian. The algorithm will never construct more than <code>max_krylov_dim</code> basis vectors, limiting the runtime and memory consumption of the time-evolution.</p> <p>Note that the number of iterations the Lanczos algorithm needs to converge to the required tolerance depends on the <code>dt</code> parameter also present in the config (see the api specification). The default value of <code>max_krylov_dim</code> should work for most reasonable values of <code>dt</code>, so if you get a recursion error out of the Lanczos algorithm, ensure you understand how the errors in TDVP depend on <code>dt</code>.</p>"},{"location":"advanced/config/#extra_krylov_tolerance","title":"extra_krylov_tolerance","text":"<p>In addition to the above hard cap on the number of basis vectors, the algorithm will also attempt to estimate the error incurred by computing the matrix exponential using only the current basis vectors. In principle, it is not needed to compute the time-evolution more precisely than <code>precision</code> since extra precision will be lost in the truncation. However, in practice it turns out that existing error estimates tend to underestimate the error. <code>extra_krylov_tolerance</code> is a fudge factor for how big the desired precision should be compared to <code>precision</code>. Its default value is <code>1e-3</code>.</p>"},{"location":"advanced/convergence/","title":"Validating correctness of the results from a simulation","text":"<p>By limiting the bond dimension of the state, systems of arbitrary size can be simulated (memory consumption). However, when truncation of the state hits the hard cap of <code>max_bond_dim</code>, control over the error incurred by truncation is lost, and care must be taken that the results are still accurate. By setting <code>max_bond_dim = 1600</code> <code>extra_krylov_tolerance=1e-5</code> and <code>precision=1e-6</code>, we were able to run the adiabatic pulse from the benchmarks for a 7x7 grid. For an analysis of the performance, see the benchmark page. This is a pulse that creates an antiferromagnetic state for smaller grids. However, whether or not a state is still effectively adiabatic depends on the energy gap of the system, and this decreases with system size. This example is instructive because lack of antiferromagnetic structure for larger systems does not automatically mean that the simulation was not accurate. The obtained qubit density was</p> 0.87  0.47  0.62  0.56  0.62  0.47  0.87  0.47  0.43  0.41  0.42  0.41  0.43  0.47  0.62  0.41  0.47  0.45  0.47  0.41  0.62  0.56  0.42  0.45  0.45  0.45  0.42  0.56  0.62  0.41  0.47  0.45  0.47  0.41  0.62  0.47  0.43  0.41  0.42  0.41  0.43  0.47  0.87  0.47  0.62  0.56  0.62  0.47  0.87"},{"location":"advanced/convergence/#trusting-your-results","title":"Trusting your results","text":"<p>First let's discuss whether these results are trustworthy, and then how the values of <code>max_bond_dim</code> and <code>precision</code> were obtained iteratively.</p> <p>For verifying the validity of the results, users should vary the parameters of the emulator until the results become insensitive to their variation (see here). This is what was done to obtain the above results, and then the main question is whether long-range interactions are correctly taken into account by the TDVP algorithm. It is worth noting that TDVP is a 1-d algorithm, so that qubits that are close in physical space are not necessarily close in the MPS layout. Specifically, the register ordering we used in the MPS simply concatenates all the colums of the above grid, and uses the resulting linear ordering, so while qubit \\((1,1)\\) and \\((1,2)\\) are neighbours in the MPS, qubits \\((1,1)\\) and \\((2,1)\\) are not, and this creates an artifical long-range interaction, which TDVP handles through an effective description (see here). If the effective description of the interaction did not take the Rydberg interaction properly into account, we would expect to see different structure in the qubit densities along the horizontal axis than along the vertical one, due to the error in the effective description. This is not the case because the table of qubit densities shown above obeys the symmetries of the grid: the table can be reflected along the horizontal and vertical axis, as well as rotated by right angles (and because these tranformations form a group, reflection symmetry around the diagonals follows, etc.).</p> <p>Since the qubit density results have symmetries that we expect to be broken by the errors intrinsic in TDVP, it is likely that the above results are correct even though only weak antiferromagnetic structure is present. Instead, the lack of antiferromagnetic structure probably occurs because the pulse used is no longer effectively adiabatic for this system size.</p> <p>Now let us consider why we used the config values quoted above.</p>"},{"location":"advanced/convergence/#exploring-the-parameter-space","title":"exploring the parameter space","text":"<p>Since the starting point of a parameter search is always a bit arbitrary, we started by seeing with what <code>max_bond_dim</code> we could still simulate the pulse, for the default precision, on 2 gpus. This turns out to have been 1800. Then the first point of investigation was how much this result depends on bond dimension. Only in the below equations, let \\(\\psi_d\\) denote the state obtained for <code>max_bond_dim=d</code>, then we found</p> \\[ \\langle\\psi_{1800}, \\psi_{1700}\\rangle = 0.999 \\] \\[ \\langle\\psi_{1800}, \\psi_{1600}\\rangle = 0.999 \\] <p>These inner products mean the output state hardly changes, and sure enough, various observables, such as the fidelity on the antiferromagnetic state and the qubit density are also basically constant. We could probably have reduced <code>max_bond_dim</code> even further without much consequence, but <code>max_bond_dim=1600</code> was sufficient to run simulations with much better precisions, so we did not investigate further. Recall that by default <code>precision=1e-5</code>. We now ran simulations, all with <code>max_bond_dim=1600</code> but <code>precision</code> one of <code>[1e-7,2e-7,5e-7,1e-6,2e-6,5e-6]</code> and <code>extra_krylov_tolerance=1e-5</code>. The value of <code>extra_krylov_tolerance</code> was chosen so that for <code>precision=1e-7</code>, the precision in the Lanczos algorithm was the same as the default in ITensors. Only in the below equations, let \\(\\psi_p\\) denote the state obtained for <code>precision=p</code>, then we found</p> \\[ \\langle\\psi_{1e-7}, \\psi_{1e-5}\\rangle = 0.937 \\] \\[ \\langle\\psi_{2e-7}, \\psi_{1e-5}\\rangle = 0.937 \\] \\[ \\langle\\psi_{5e-7}, \\psi_{1e-5}\\rangle = 0.937 \\] \\[ \\langle\\psi_{1e-6}, \\psi_{1e-5}\\rangle = 0.938 \\] \\[ \\langle\\psi_{2e-6}, \\psi_{1e-5}\\rangle = 0.912 \\] \\[ \\langle\\psi_{5e-6}, \\psi_{1e-5}\\rangle = 0.898 \\] <p>Notice that this list of inner products stabilizes up to 3 digits for precisions better than <code>1e-6</code>. Assuming a Hermitian operator \\(A\\) and a normalized state, we can write</p> \\[ \\langle\\psi |A | \\psi \\rangle - \\langle \\phi | A | \\phi \\rangle \\leq 4 \\| A \\| (1 - abs(\\langle \\psi, \\phi \\rangle)) \\] <p>Since \\(\\|A\\| = 1\\) if \\(A\\) is a Pauli string operator, we can specifically expect the qubit density to be accurate up to the second digit for <code>precision &lt; 1e-6</code>. This is why the qubit density was only printed for two digits at the start of this page, and from the numerics, we also find the above observation holds. The above also shows that for <code>precision &gt; 1e-6</code> we can expect variations in the qubit density in the second digit, which we also observe in the numerics. Specifically, for <code>precision &gt; 1e-6</code>, the reflection and rotation symmetries of the qubit densities only hold up the first digit. Since the qubit density at the center of the grid only differs in the second digit, precisions larger that <code>1e-6</code> were not deemed sufficient to judge whether the pulse was accurately simulated.</p> <p>Since the results obtained for <code>max_bond_dim = 1600</code>, <code>extra_krylov_tolerance=1e-5</code> and <code>precision=1e-6</code> are accurate enough for the purposes of this discussion, we did not investigate the impact of varying <code>dt</code>.</p>"},{"location":"advanced/errors/","title":"An explanation of the sources of error in TDVP","text":"<p>Emu-mps uses a 2nd order 2-site time-dependent variational principle to compute the time evolution of the qubit registers (see here). There are four sources of error inherent in this algorithm (see here)</p> <ul> <li>effective description of long-range terms in the Hamiltonian</li> <li>looping over pairs of qubits</li> <li>iterative computation of the 2-site effective evolution</li> <li>truncation of the state</li> </ul> <p>Let us briefly explain how each of these terms introduce errors into the simulation, and let us try to estimate their size.</p>"},{"location":"advanced/errors/#effective-description-of-long-range-terms-in-the-hamiltonian","title":"effective description of long-range terms in the Hamiltonian","text":"<p>The rydberg Hamiltonian is long range, so when evolving 2 neighbouring qubits in one of the TDVP steps, it is necessary to approximate terms coupling these two qubits to far away qubits. Specifically, say we are evolving the pair \\((j,j+1)\\) and the Hamiltonian contains an interaction term of the form \\(A_iB_j\\) where \\(i &lt; j-1\\), so that this interaction term is not taken into account by any of the other pair evolutions (currently only the Rydberg interaction \\(n_i n_j\\) is supported, but other interaction types will be added in the future). Then as part of the effective Hamiltonian for the pair, this interaction term shows up as \\(Tr_{&lt;j}(A_iB_j)\\), where \\(Tr_{&lt;j}\\) denotes the partial trace over the left side of the system. Unless the system is in an eigenstate of \\(A_i\\), this term will only approximate the action of the interaction term, and the error is proportional to the variance \\(Var(A_i)\\).</p> <p>For example, take the term \\(\\sigma^-_i\\sigma^+_n\\) from the XY-Hamiltonian, and assume \\(|\\psi&gt; = |1&gt;_i|0&gt;_n\\otimes \\phi\\) where \\(\\phi\\) denote the state on the other qubits, that will not impact the result in the example, other than that it must be normalized. In this case we compute \\(Tr_{&lt;n}(\\sigma^-_i\\sigma^+_n) = 0\\) because \\(\\sigma^-_i|1&gt;_i \\perp |1&gt;_i\\), and the interaction term is not taken into account. The above example was chosen to be particularly bad, since \\(\\sigma^-\\) is not diagonalizable, and \\(|\\psi&gt;\\) was as far from an eigenvector as possible, for other states, the error incurred in the approximation will be smaller. For the Rydberg interaction, which is diagonalizable, the maximum error is smaller. However, this shows that when simulating systems with long-range interactions (2d systems, for example, behave like 1d systems with long-range interactions according to the above reasoning), care should be taken that the interaction terms are properly accounted for by the TDVP scheme.</p>"},{"location":"advanced/errors/#looping-over-pairs-of-qubits","title":"looping over pairs of qubits","text":"<p>Even if the Hamiltonian only has nearest-neighbour interactions, so that the above error is \\(0\\), we still incur an error by repeatedly evolving a 2-site subsystem, rather than the entire system at once. Take for example the interaction term \\(A_nB_{n+1}\\), in the 2-site TDVP scheme, there are 10 time evolution steps that incorporate this interaction term:</p> <ul> <li>3 2-site time evolutions evolving either qubit \\(n\\) or \\(n+1\\) during the left-right sweep</li> <li>2 1-site time evolutions evolving either qubit \\(n\\) or \\(n+1\\) during the left-right sweep</li> <li>the same 5 time evolutions durig the right-left sweep</li> </ul> <p>Similar to how for trotterization</p> \\[ e^{-i t (A + B)} = e^{-i t A}e^{-i t B} +O(t^2) = e^{-it B / 2} e^{-i t A} e^{-i t B / 2} + O(t^3) \\] <p>so also, by sweeping left-right and then right-left, the magnitude of this error reduced is reduced from \\(O(dt)\\) to \\(O(dt^2)\\). The prefactor in the order notation depends on the bond-dimension of the state, becoming smaller as the bond-dimension grows.</p>"},{"location":"advanced/errors/#iterative-computation-of-the-2-site-effective-evolution","title":"iterative computation of the 2-site effective evolution","text":"<p>Each 2-site time evolution corresponds to solving a Schroedinger equation for the corresponding subsystem, which is done numerically, and incurs a corresponding numerical error. We solve the Schroedinger equation by using the Lanczos algorithm to exponentiate the effective 2-site Hamiltonian directly. This algorithm computes the vector \\(e^{i t H}\\psi\\) by iteratively constructing the vectors \\(\\{\\psi, H\\psi,..., H^n\\psi\\}\\) and exponentiating \\(H\\) on this subspace. The algorithm aboards the iterations when the estimated precision for \\(e^{i t H}\\psi\\) has been obtained (this precision can be set via the config), but experience teaches that the error is underestimated. When choosing the precision high enough, this error is negligible compared the others in described here.</p>"},{"location":"advanced/errors/#truncation-of-the-state","title":"truncation of the state","text":"<p>After each 2-site evolution, an SvD is applied to split the vector for the 2-site subsystem back into 2 tensors for the MPS. The behaviour of this truncation is identical to that of general MPS truncation (see here).</p> <p>As explained there, each truncation finds the smallest MPS whose norm-distance is less than the precision from the original MPS. TDVP sweeps from left two right over neighbouring pairs of qubits, and back. This means that for each timestep, <code>2*(nqubits-1)</code> truncations are performed, so by the triangle inequality, TDVP will output a state whose distance is less than <code>2*(nqubits-1)*precision</code> from the state TDVP would have output without truncation. Note that the truncation errors will not all point in the same direction, so the actual error will likely be closer to <code>sqrt(2*(nqubits-1))*precision</code>, similar to the error in a gaussian random walk. The default precision is <code>1e-5</code>, meaning that each tdvp step will likely be accurate up to order <code>1e-4</code> assuming no more than order <code>1e2</code> qubits.</p> <p>Similarly, when performing multiple TDVP steps, the maximum possible error scales linearly in the number of steps, but the error is more likely to scale as the square root of the number of time steps. Notice that there is a tradeoff when decreasing the value of \\(dt\\) between the truncation error and the other errors in this list. Decreasing \\(dt\\) means applying more truncations, which means a bigger expected error. Additionally, when \\(|e^{- i t H}\\psi - \\psi| \\approx precision\\) TDVP becomes meaningless, because each time evolution step is accompanied by a truncation that perturbs the state at least as much.</p> <p>When in doubt about the convergence of the algorithm, try to improve the precision of both truncation and the Lanczos algorithm, and also make sure that <code>max_bond_dim</code> does not truncate the state too agressively. This can be done by tweaking these parameters, and checking whether output observables like the correlation matrix and energy variance change significantly. The effective 2-site Hamiltonian used to evolve each subsystem is constructed in such a way all powers of the Hamiltonian are constants of the motion. This means that any change in the moments of \\(H(t)\\) (and specifically the expectation and variance of the energy) due to the tdvp step at time \\(t\\) is due to truncation, or the precision in the Lanczos algorithm. Regarding the correlation matrix, long-range entanglement, as signified by elements of the correlation matrix far from the diagonal, contributes strongly to the bond dimension of the MPS, so the parts of the wave function creating such entanglement are likely to be truncated away when truncation is performed too agressively. As a corrolary, observables which do not strongly depend on off-diagonal elements of the correlation matrix are less sensitive to truncation. After these considerations, when still in doubt, try to reduce \\(dt\\). When still in doubt, question whether TDVP correctly takes into account long-range interactions.</p>"},{"location":"advanced/hamiltonian/","title":"QPU Hamiltonian","text":"<p>In all cases we will refer to \\(H\\) as being of the form</p> \\[ H = -\\sum_j\\Delta_jn_j \\ + \\ \\sum_j\\Omega_j\\sigma^x_j \\ + \\ H_{i} \\] <p>where \\(H_i\\) is the interaction term in the Hamiltonian. Values of \\(\\Omega_j\\) and \\(\\Delta_j\\) respectively represent the amplitude and the detuning of the driving field applied to the qubit \\(j\\). Avoiding technical details we will refer to eigenstates of \\(H\\) (and in particular to the ground state) as equilibrium states.</p> <p>Although the QPU currently only supports a Rydberg interaction, emu-mps supports both the Rydberg interaction term and the XY interaction.</p> <p>The Rydberg interaction reads</p> \\[ H_{rr} = \\sum_{i&gt;j} U_{ij} n_{i}n_{j} \\] <p>where</p> \\[ U_{ij} = \\frac{C_{6}}{r_{ij}^{6}}, \\] <p>and the XY interaction reads</p> \\[ H_{xy} = \\sum_{i&gt;j} U_{ij} (\\sigma^+_{i}\\sigma^-_{j} + h.c.) \\] <p>where</p> \\[ U_{ij} = \\frac{C_{3}(1-3 \\cos^2(\\theta_{ij}))}{r_{ij}^{3}}, \\] <p>In these formulas, \\(r_{ij}\\) represents the distance between qubits \\(i\\) and \\(j\\), and \\(\\theta_{ij}\\) represents a configurable angle (see here). Currently, Pasqal quantum devices only support Rydberg interactions, and different devices have different \\(C_6\\) coefficients and support for different maximum driving amplitudes \\(\\Omega\\). Intuitively, under stronger interactions (rydberg-rydberg and laser-rydberg), bond dimension will grow more quickly (see here), thus affecting performance of our tensor network based emulator. For a list of the available devices and their specifications, please refer to the Pulser documentation (see here).</p>"},{"location":"advanced/noise/","title":"Noise Implementation in emu-mps","text":"<p>To faithfully emulate the Pasqal QPU using emu-mps, we need to include noise effects, as these effects cannot be neglected in a real quantum system\u2014they significantly impact the performance and fidelity of the QPU.</p> <p>In open quantum many-body systems, noise is typically expressed in terms of mixed states and noise channels using a density matrix representation. Similar to a state-vector emulator, emu-mps only handles pure states. Therefore, we implement noise using a higher order Monte Carlo method (see here), where we evolve the system using an effective Hamiltonian and then apply a quantum jump at certain times. This method is probabilistic in the sense that it approximates the simulation of a mixed state using many non-deterministic pure state simulations.</p>"},{"location":"advanced/noise/#noise-types","title":"Noise Types","text":"<p>Our implementation supports different types of noise:</p> <ul> <li>relaxation: due to a decay from the Rydberg to the ground state. It is parameterized by relaxation_rate.</li> <li>dephasing: due to a random phase flip (Z). It is parameterized by dephazing_rate.</li> <li>depolarizing: used as a tool to test the system under a uniform combination of phase flip (Z) and bit flip (X) errors. It is parameterized by depolarizing_rate.</li> <li>eff_noise: general effective noise channel defined by the set of collapse operators eff_noise_opers and their corresponding rates eff_noise_rates.</li> <li>SPAM errors: parameterized by state_prep_error, p_false_pos and p_false_neg.</li> </ul> <p>Users can refer to the Pulser documentation for a detailed overview of the different noise models currently available. Currently, emu-mps does not support the amplitude noise, Doppler noise and leakage.</p>"},{"location":"advanced/noise/#effective-hamiltonian","title":"Effective Hamiltonian","text":"<p>The non-hermitian effective Hamiltonian used in noisy emu-mps simulations includes both the physical Hamiltonian \\(H_{physical}\\), which governs the noiseless evolution of the system, and a term representing noise:</p> \\[ H_{\\text{eff}} = H_{\\text{physical}} \\ - \\ \\frac{i}{2} \\sum_m L^{\\dagger}_m L_m. \\] <p>where: - \\(H_{physical}\\) is the Hamiltonian of the noiseless system. - The second term is a sum over the Lindblad operators (<code>L</code>), which represent different types of noise.</p>"},{"location":"advanced/noise/#time-evolution-mechanism","title":"Time Evolution Mechanism","text":"<p>The system undergoes deterministic time evolution from time \\(t\\) to \\(t + \\delta t\\) using TDVP (see here) with the effective Hamiltonian. At the end of each evolution step, the norm of the evolved quantum state \\(\\vert \\psi (t + \\delta t)\\rangle\\) is compared to a collapse threshold, which is a random number between \\(0\\) and \\(1\\):</p> <ul> <li>If the square of the norm of the evolved state is greater than the random number, the system successfully evolves under the effective Hamiltonian \\(H_{\\text{eff}}\\) to time \\(t + \\delta t\\), and proceeds to the next time step.</li> <li>If the square of the norm of the evolved state is less than the random number, a quantum jump occurs. This can be understood as a simulation of a noise event (e.g. spontaneous emission, dephasing, etc.).</li> </ul>"},{"location":"advanced/noise/#warning","title":"WARNING:","text":"<p>It is important to note that the norm of the state also decreases due to truncation effects. Therefore, it is recommended to choose an appropriate precision when performing Monte Carlo simulations. Additionally, computing the collapse times may become unreliable when the maximum bond dimension chosen by the user is reached, as truncation errors can become difficult to control.</p>"},{"location":"advanced/noise/#locating-the-quantum-jump","title":"Locating the Quantum Jump","text":"<p>To determine when a quantum jump occurs between time \\(t\\) and \\(t + \\delta t\\), the TDVP is applied multiple times (both forward and backward in time) to approximate the collapse time. During this process, the norm of the evolved state is checked and compared to the collapse threshold. This evolution procedure is repeated until the norm converges to the collapse threshold.</p>"},{"location":"advanced/noise/#applying-the-quantum-jump","title":"Applying the Quantum Jump","text":"<p>Once the time of collapse is located, a Lindblad operator is randomly applied to a qubit (based on the collapse weight), then the evolution of the normalized state is continued to complete the time step of size \\(\\delta t\\).</p> <p>Upon completion of the current time step, the time evolution continues with the next step.</p>"},{"location":"advanced/noise/#physical-interpretation-spontaneous-emission-in-the-two-level-system","title":"Physical Interpretation: Spontaneous Emission in the Two-Level System","text":"<p>To better understand how the quantum jump process describes a physical event (noise) which occurs during time evolution, let us consider a two-level system initially in the state \\(\\vert \\psi(t)\\rangle = \\alpha\\vert g\\rangle + \\beta \\vert e\\rangle\\), where \\(\\alpha\\) and \\(\\beta\\) are complex coefficients. By setting both the amplitude and detuning to zero, \\(\\Omega = \\delta = 0\\), we can then ask what happens in a single step depending on whether a spontaneously emitted photon occurs or not. For this, we examine a single quantum jump operator \\(L = \\sqrt{\\Gamma}\\vert g\\rangle\\langle e\\vert\\), and an effective Hamiltonian \\(H_{eff} = -i(\\Gamma/2)\\vert e\\rangle\\langle e\\vert\\).</p> <p>If a quantum jump occurs in a time step \\(\\delta t\\), then the state following the jump becomes $$ \\vert \\psi(t+\\delta t)\\rangle \\ = \\ \\frac{L\\vert\\psi(t)\\rangle}{\\vert\\vert L \\vert \\psi(t)\\rangle\\vert\\vert} \\ = \\ \\vert g\\rangle. $$</p> <p>In other words, when a spontaneous emission event occurs, the evolved state of the system collapses onto the ground state \\(\\vert g\\rangle\\). This demonstrates how noisy events, like spontaneous emission, can alter the dynamics of a quantum system, even in the absence of direct observation of emitted photons.</p>"},{"location":"advanced/resource_estimation/","title":"Estimating Memory Consumption and Runtime","text":"<p>The presence of the <code>max_bond_dim</code> and <code>max_krylov_dim</code> config parameters means an upper bound on memory consumption and the complexity of the time evolving algorithm can be estimated. By limiting the <code>max_bond_dim</code> of a simulation to make it fit in the available hardware memory, it can be guaranteed to run for arbitrary times for an arbitrary number of qubits. Of course, the sources of error described on the error page imply that limiting the memory consumption of the program will negatively impact the quality of the results once a certain threshold is exceeded. The page in this link, for example, outlines a case study to determine whether emulation results are accurate.</p>"},{"location":"advanced/resource_estimation/#estimating-the-memory-consumption-of-a-simulation","title":"Estimating the memory consumption of a simulation","text":"<p>In this section we outline how to estimate the memory consumption of a simulation, for a given <code>max_bond_dim</code>, a Krylov subspace of size <code>max_krylov_dim</code>, and for \\(N\\) being the number of qubits to be simulated. There are four contributions to the peak memory consumption of emu-mps that will be discussed in the next sections:</p> <ul> <li>the state</li> <li>the baths</li> <li>the Krylov space</li> <li>temporary tensors</li> </ul>"},{"location":"advanced/resource_estimation/#contribution-from-the-state","title":"Contribution from the state","text":"<p>The quantum state is stored in MPS format (see here). At worst, the bond dimensions of the tensors in an MPS grow exponentially inwards as</p> \\[ 2,4,8,16...,16,8,4,2 \\] <p>in which case an MPS will take more memory than a state vector. Let \\(\\chi\\) denote the value of <code>max_bond_dim</code>. When \\(\\chi&lt;2^{N/2}\\), the bond dimensions in the center all cap at that fixed value of <code>max_bond_dim</code>.  Since each tensor in the MPS has 2 bonds of size at most \\(\\chi\\), and a physical index of size \\(p=2\\), where each element in the tensor takes \\(s=16\\) bytes (2 8-byte floats to store a complex number), the memory consumption of the state reads</p> \\[ |\\psi| &lt; spN\\chi^2 = 32N\\chi^2 \\] <p>Note that this is a strict over-estimation because the outer bonds in the MPS will be much smaller than \\(\\chi\\).</p>"},{"location":"advanced/resource_estimation/#contribution-from-the-baths","title":"Contribution from the baths","text":"<p>For TDVP, for each qubit a left and a right bath tensor is stored. The bath tensors are used to compute an effective interaction between the 2-qubit subsystem being evolved, and the rest of the system (see here). Each of them has 3 indices. Two of them will have a size that depends on the state that is evolved, here upper bounded by the maximum allowed value \\(\\chi\\) for the bond dimension. For the third, the size \\(h\\) will depend on the interaction type. In concrete, for each qubit, \\(h\\) will be the bond dimension of the MPO representation of the Hamiltonian. In summary, for the Rydberg Hamiltonian we expect that \\(h=2+\\text{floor}(n/2)\\), and for the XY Hamiltonian that \\(h=2+2\\text{floor}(n/2)\\), where in both cases \\(n=\\text{min}(i,N-i)\\) for the bath associated with the qubit \\(i\\). The computation is slightly involved, but summing all the contributions leads to a total memory occupation of the baths:</p> \\[ |\\mathrm{bath}| &lt; Ns\\chi^2h = 4\\chi^2N(N+10) \\] <p>Note that the baths take up more memory than the state, always, and potentially much more. Furthermore, just as for the state this is a strict over-estimation, because it assumes all the bonds in the state are of size \\(\\chi\\).</p>"},{"location":"advanced/resource_estimation/#contribution-from-the-krylov-space","title":"Contribution from the Krylov space","text":"<p>The remainder of the memory consumption is to compute the time-evolution of qubit pairs in TDVP. This is done by contracting 2 tensors from the MPS together into a single 2-qubit tensor, and time-evolving it by applying an effective Hamiltonian constructed from the baths and the Hamiltonian MPO. Each 2-qubit tensor has a size bounded by \\(sp^2\\chi^2\\), so the memory of the Krylov vectors used in the Lanczos algorithm reads</p> \\[ |\\mathrm{krylov}| \\leq ksp^2\\chi^2 = 64k\\chi^2 \\] <p>where \\(k\\) is the value of <code>max_krylov_dim</code>. Recall that the default value of \\(k=100\\) and if the Lanczos algorithm requires more Krylov vectors to converge to the tolerance, it will error, rather than exceed the above bound.</p>"},{"location":"advanced/resource_estimation/#contribution-from-temporary-tensors","title":"Contribution from temporary tensors","text":"<p>Finally, to compute the above Krylov vectors, the effective two-site Hamiltonian has to be applied to the previous Krylov vector to obtain the next one. The resulting tensor network contraction cannot be done in-place, so it has to store two intermediate results that get very large. The intermediate results take the most memory at the center qubit, where the bond dimension of the Hamiltonian becomes \\(h\\), where</p> \\[ |\\mathrm{intermediate}| = 2*shp^2\\chi^2 = 128h\\chi^2 \\] <p>It should be noted that the value of \\(h\\) cited above assumes that all qubits in the system interact via a two-body term, which is technically true for the Rydberg interaction.</p>"},{"location":"advanced/resource_estimation/#benchmarking-memory-footprint","title":"Benchmarking memory footprint","text":"<p>Putting all of this together, for the total memory consumption \\(m\\) of the program, we can write the following bound:</p> \\[  m(N,\\chi,k) = |\\psi| + |\\mathrm{bath}| + |\\mathrm{krylov}| + |\\mathrm{intermediate}| &lt; 32N\\chi^2 + 4\\chi^2N(N+10) + 64*k*\\chi^2 + 64(N+4)\\chi^2 = 4\\chi^2[N(N+34) + 16k + 64] \\] <p>Note that this estimate is pessimistic, since not all \\(k\\) Krylov vectors are likely to be needed, and not all tensors in \\(\\psi\\) and the baths have the maximum bond dimension \\(d\\). On the other hand, the estimate for \\(|intermediate|\\) is likely to be accurate, since the bond dimension of \\(\\chi\\) is probably attained at the center qubit.</p> <p>To test the accuracy of the above memory estimations, we run the TDVP time evolution algorithm, fixing the bond dimension to a particular desired value. For different combinations of the number of atoms in a register \\(N\\) and the fixed bond dimension \\(chi\\), we collect the maximum resident size, or RSS, which is expected to capture the maximum memory needed to run the emulation. We plot the RSS in the following picture (left), as a function of the number of qubits and for different bond dimensions. Notice that, once the RSS is normalized by \\(\\chi^2\\), as suggested by our estimate above, all the points fall into the same functional dependency on the number of atoms. Moreover, as we plot the normalized function \\(m(N,\\chi,k)/\\chi^2\\), for a reasonable estimate of the size of the Krylov subspace (\\(k=30\\)), it is clear that our upper bound on memory occupation can be reasonably trusted on a wide range of qubit number and bond dimensions.</p> <p> </p> <p>Finally, having established an estimate for the memory consumption, it makes sense to explore what are the available regimes of qubits/bond dimension can be reached for a given hardware capability. Since all heavy simulations will be run on an NVIDIA A100 (on Pasqal's DGX cluster), we have 40 GB of available memory. Therefore, above, we show (right image) the contour lines of the RSS estimate \\(m(N,\\chi,k=30) &lt; 40\\) GB for particular useful values of the total memory, allowing to quickly estimate the memory footprint of an emu-mps emulation.</p>"},{"location":"advanced/resource_estimation/#an-example","title":"An example","text":"<p>For example, the results from the case study were obtained using \\(N=49\\) and \\(d=1600\\) on 2 GPUs. Taking the above formula, and halving the contributions from \\(\\psi\\) and \\(|\\mathrm{bath}|\\) since they are split evenly on the GPUs, we reproduce the memory consumption of the program for \\(k=13\\). Notice that the actual number of Krylov vectors required to reach convergence is likely closer to around \\(30\\), but here we underestimate it, since the contributions of \\(\\psi\\) and \\(|\\mathrm{bath}|\\) are over-estimated.</p>"},{"location":"advanced/resource_estimation/#estimating-the-runtime-of-a-simulation","title":"Estimating the runtime of a simulation","text":"<p>Similarly to the previous section, here, we briefly estimate the complexity of the two-site TDVP algorithm we use to time evolve the state in a single pulse sequence step. As before, the two relevant computational steps are</p> <ul> <li>Computing the baths</li> <li>Applying the effective Hamiltonian</li> </ul> <p>In both cases, it will boil down to an exercise in complexity estimation of tensor network contractions. For simplicity, as before, we will restrict to the worst case scenario in which the bond dimension \\(\\chi\\) always take the maximum allowed value. Importantly, another significant contribution to the runtime can come from computing complex observables like two-point correlation functions, which is not included here.</p>"},{"location":"advanced/resource_estimation/#contribution-from-the-baths_1","title":"Contribution from the baths","text":"<p>Roughly, baths computation involves the represented tensor network contraction:</p> <p></p> <p>Each of these tensor multiplication takes respectively \\(O(ph\\chi^3)\\), \\(O(p^2h^2\\chi^2)\\), and \\(O(ph\\chi^3)\\). In an all-to-all Rydberg interaction, we already argued that the bond dimension of the Hamiltonian MPO should scale as the number of atoms. Moreover, the left and right baths need to be computed roughly N times, thus the overall expected complexity is \\(O(N^2\\chi^3) + O(N^3\\chi^2)\\).</p>"},{"location":"advanced/resource_estimation/#contribution-from-the-effective-hamiltonian","title":"Contribution from the effective Hamiltonian","text":"<p>Applying the effective two-body Hamiltonian is slightly a more involved tensor network contraction:</p> <p></p> <p>In steps, it is composed by applying:</p> <ul> <li>the left bath: \\(O(p^2h\\chi^3)\\)</li> <li>a two-body term coming form the MPO Hamiltonian: \\(O(p^4h^2\\chi^2)\\)</li> <li>the right bath: \\(O(p^2h\\chi^3)\\)</li> </ul> <p>As before, for an all-to-all Rydberg interaction we expect \\(h\\sim N\\). Moreover, the effective Hamiltonian application needs to be done \\(k\\) times, to build the appropriate Krylov subspace, and for every pair. Finally, to complete the time evolution and bring back the tensors of the state into an MPS form, a final singular value decomposition is required. For every pair, this requires \\(O(N\\chi^3)\\) to be done. Overall, the expected complexity is thus \\(O(kN^2\\chi^3) + O(kN^3\\chi^2) + O(N\\chi^3)\\).</p>"},{"location":"advanced/resource_estimation/#benchmarking-runtime","title":"Benchmarking runtime","text":"<p>From the previous complexity estimations, we thus expect the complexity of the two-sites TDVP algorithm to have two main contributions</p> \\[\\Delta t_{\\text{TDVP}}(N,\\chi,k)\\sim \\alpha N^2\\chi^3 + \\beta N^3\\chi^2\\] <p>To check such estimation, as before, we run TDVP multiple times, measuring the average runtime to perform a step. Below, we show the obtained results for different number of atoms in a register \\(N\\) at fixed bond dimension \\(\\chi\\) (left), and at different fixed \\(N\\) but increasing the bond dimension (left). On top of these data points, we also plot the resulting fit of the complexity estimation presented in the equation above. Remarkably, with just two parameters \\(\\alpha\\) and \\(\\beta\\) with get good agreement.</p> <p> </p> <p>To wrap up, and to provide an useful tool for runtime estimation for emu-mps, the time to perform a single  time step in a sequence can be conveniently visualized (below) for both \\(N\\) and \\(\\chi\\) on contour lines.</p> <p></p> <p>Superimposing the 40 GB hardware constrain derived in the previous section, it is easy to see that in worst-case scenario, a TDVP step will take roughly 250 seconds to be computed.</p>"},{"location":"advanced/tdvp/","title":"Summary of the TDVP algorithm","text":"<p>Emu-mps uses a second order 2-site TDVP to compute the time-evolution of the system (see here for details). Briefly, the algorithm repeatedly computes the time-evolution for 2 neighbouring qubits while truncating the resulting MPS to keep the state small. It does this by</p> <ul> <li>evolving qubit 1 and 2 forwards in time by \\(dt/2\\)</li> <li>evolving qubit 2 backwards by \\(dt/2\\)</li> <li>evolving qubit 2 and 3 forwards in time by \\(dt/2\\)</li> </ul> <p>...</p> <ul> <li>evolving qubit \\(n-1\\) and \\(n\\) forward in time by \\(dt\\)</li> <li>evolving qubit \\(n-1\\) backwards in time by \\(dt/2\\)</li> <li>evolving qubit \\(n-2\\) and \\(n-1\\) forward in time by \\(dt/2\\)</li> </ul> <p>...</p> <ul> <li>evolving qubit 1 and 2 forwards in time by \\(dt/2\\)</li> </ul> <p>The fact that we sweep left-right and the right-left with timesteps of \\(dt/2\\) makes this a second-order TDVP.</p>"},{"location":"advanced/mps/","title":"The MPS representation of a state","text":"<p>As opposed to state vector solvers (of the Master/Schr\u00f6dinger equation), tensor network based approaches use adaptive data structures, which in the case of emu-mps are called matrix product state/operator (MPS/MPO). They are adaptive in the sense that the memory used to store such a state/operator does not only depend on the dimension of the state space, but also on the specific state you're trying to represent. In many relevant use cases, this makes representation more memory-efficient, which allows pushing for higher number of qubits compared to state vector solvers. However, it has the drawback that the cost of the simulation is less predictable since there is no a priori method to know how much information is going to be relevant at the next step of the solver. The are configurable hard caps on memory consumption built into emu-mps (see here), but when these are hit it becomes necessary to check for validity of the results (see here).</p> <p>The take-home message is that a reasonable way to assess emu-mps performance is by benchmarking relevant and meaningful sequences/use-cases (see here).</p>"},{"location":"advanced/mps/#bond-dimension","title":"Bond dimension","text":"<p>Please, have a look at http://tensornetwork.org/mps/ for a more general introduction to matrix product states.</p> <p>The MPS is the best understood factorization of an arbitrary tensor, for which many efficient algorithms have been developed. For a quick understanding, in tensor diagram notation, let's consider the wavefunction of \\(N\\) qubits:</p> <p></p> <p>Alternatively, the MPS of the state can be expressed in traditional notation as</p> \\[ |s_1 s_2\\dots s_N\\rangle = \\sum_{\\{\\alpha\\}}A^{s_1}_{\\alpha_1}A^{s_2}_{\\alpha_1\\alpha_2}\\dots A^{s_N}_{\\alpha_N} \\] <p>The state is therefore is represented as a product of tensors. The contracted (or summed over) indices \\(\\{\\alpha\\}\\) are called bond indices and their dimension (the bond dimension) can vary from bond to bond.</p> <p>The bond dimension required to perfectly represent a state depends on its entanglement (roughly, how much quantum information is stored in it). Up to this limit, a higher bond dimension will mean that the state is represented more faithfully. However, a higher bond dimension also implies that size of the state will be bigger, thus making the emulation more expensive.</p> <p>As a consequence, the real power of the MPS representation is that the bond dimension, \\(\\chi= dim(\\alpha)\\), gives us an additional knob to control how much information about the state we want to capture. Many relevant states can already be represented faithfully using less memory than a state vector, but by restricting \\(\\chi\\) further, additional memory savings are possible, potentially without loss of simulation quality (see here).</p>"},{"location":"advanced/mps/#truncation-of-the-state","title":"Truncation of the state","text":"<p>After each 2-site evolution (see here), an SvD is applied to split the state vector for the 2-site subsystem back into two tensors for the MPS. The number of singular values give the dimension of the bond connecting the 2 qubits in the MPS. To keep the memory consumption of the state in check, the set of singular values is truncated as per the <code>precision</code> and <code>max_bond_dim</code> arguments in the config.</p> <p>Of these two parameters, <code>precision</code> is the most physically relevant. Whenever truncation occurs, the smallest singular values are thrown away until doing so would increase the norm distance between the original and truncated states above <code>precision</code>. Notice that this does not give any guarantees on the state size after truncation. However, for a given <code>precision</code>, clear bounds can be given on the truncation error incurred by the simulation (see here) in terms of norm distance. This in turn can be used to derive upper bounds on the error incurred in various observables outputted by the simulation.</p> <p>The <code>max_bond_dim</code> argument, on the other hand gives strong memory consumption guaranteed. Whenever truncation occurs, the smallest singular values are thrown away until at most <code>max_bond_dim</code> values remain, even if this would cause the norm distance between the original and truncated states to exceed the <code>precision</code>. This means the <code>max_bond_dim</code> takes precedence over <code>precision</code> and imposes a hard cap on the memory consumption of the program. Since all the matrices involved in the simulation are also constrained in size, lowering <code>max_bond_dim</code> also benefits the runtime fo a simulation. The drawback is that the error cannot be estimated anymore a priori, so when the <code>max_bond_dim</code> is hit by the simulation, extra care needs to be taken that the simulation results are still accurate.</p>"},{"location":"benchmarks/","title":"emu-mps benchmarks","text":"<p>All the benchmarks are run on a single NVIDIA A100 GPU of Pasqal's DGX-cluster and for best performance on heavy workloads we recommend using such setup. There, users should expect emu-mps to emulate up to</p> <ul> <li>30 atoms for quenches</li> <li>50 atoms for adiabatic sequences</li> </ul> <p>for 2D systems and for realistic pulse sequences (~\u03bcs) that can be run on the QPU. For these relevant hard use-cases, described in more detail in the next section, the bond dimension is let to grow free to achieve the desired precision.</p> <p>In all other scenarios, for specific combinations of number of qubits \\(N\\) and bond dimension \\(\\chi\\), the resources needed to emulate a sequence can be estimated by providing some upper bounds to:</p> <ul> <li>RSS: the resident set size, i.e. the maximum needed memory</li> <li>\\(\\langle\\Delta t\\rangle\\): GPU time to do a single step in the time evolution</li> </ul> <p>These quantities are represented, in the following plots:</p> <p> </p> <p>The RSS plot (left) shows the peak memory cost of the emulation. It is expected to stay constant at fixed bond dimension and thus represent the total memory occupation of the emulation of a sequence. As evident, the emulator is mostly limited by the available memory (40 GB on NVIDIA A100), as it restricts the maximum number of qubits/bond dimension pair allowed. To get the total estimated runtime instead, one should simply multiply the time estimate in the timing plot (right) by the number of steps in the emulated sequence. Finally, given the technical nature of these estimates, they rely on some previous knowledge about matrix product states and the TDVP algorithm. We encourage anyone who might be interested into the derivation, to have a look at the resource estimation page in advanced topic section of this documentation.</p> <p>While the simple resource estimation provided above allows to upper bound the memory/time cost of an emulation, a final very important remark has to be made. If during an emulation, the bond dimension reach a user-set maximum value (with the <code>max_bond_dim</code> argument), the accuracy of the subsequent results of the time evolution cannot be guaranteed anymore, as discussed here.</p> <p>Having sketched up the expected performance, in the next section, we make those statements more concrete by providing more details about use-cases benchmarks. Concretely, we will discuss the relevant register/ pulse sequences and the performance metrics of choice.</p>"},{"location":"benchmarks/#use-case-benchmarks","title":"Use-case benchmarks","text":"<p>Benchmark efforts, documented here, are meant to provide insights for emu-mps users about</p> <ul> <li>Performance: runtime, memory usage, bond dimension as a function of qubit number (see here)</li> <li>Accuracy: different precision levels as compared to state vector solvers</li> </ul> <p>given a set of meaningful sequences of interest (quench, adiabatic and use-case sequences) that we are going to introduce case by case. Finally, we will only focus on 2D atomic registers as they represent the most numerically challenging and interesting case to study.</p> <p>The benchmarks are ordered in subpages by general topic.</p> <ul> <li>Accuracy</li> <li>Performance</li> <li>Noise</li> </ul> <p>The accuracy benchmarks compare results between emulators to create confidence in the results emu-mps generates. The performance benchmarks exist to exhibit the runtime and memory consumption characteristics of emu-mps. Based on these, the reader should get a feel for what kind of parameters would be required to be able to run a given sequence in a given time. Note that this is independent of whether the emulation results are actually accurate (see here). Finally, the noise page presents benchmarks regarding noisy simulations, focusing on effects specific to noise that are not already covered in the other pages.</p>"},{"location":"benchmarks/#sequences-used","title":"Sequences used","text":"<ul> <li>Adiabatic evolution: Here at each time step, the evolution of the driving \\(\\Omega, \\Delta\\) is slow enough to guarantee that the evolved state is still an equilibrium state of \\(H\\). Note that the adiabaticity of a sequence is dependent on the energy gaps in the Hamiltonian, and since these gaps decrease with qubit number, most sequences are only adiabatic up to a given qubit number.</li> </ul> <pre><code># from https://pulser.readthedocs.io/en/stable/tutorials/afm_prep.html\n# parameters in rad/\u00b5s and ns\nOmega_max = 2.0 * 2 * np.pi\nU = Omega_max / 2.0\ndelta_0 = -6 * U\ndelta_f = 2 * U\nt_rise = 500\nt_fall = 1000\nt_sweep = (delta_f - delta_0) / (2 * np.pi * 10) * 3000\nR_interatomic = MockDevice.rydberg_blockade_radius(U)\nreg = Register.rectangle(rows, columns, R_interatomic, prefix=\"q\")\nif perm_map:\n    reg_coords = reg._coords\n    reg = Register.from_coordinates([reg_coords[i] for i in perm_map])\nrise = Pulse.ConstantDetuning(RampWaveform(t_rise, 0.0, Omega_max), delta_0, 0.0)\nsweep = Pulse.ConstantAmplitude(\n    Omega_max, RampWaveform(t_sweep, delta_0, delta_f), 0.0\n)\nfall = Pulse.ConstantDetuning(RampWaveform(t_fall, Omega_max, 0.0), delta_f, 0.0)\nseq = Sequence(reg, MockDevice)\nseq.declare_channel(\"ising\", \"rydberg_global\")\nseq.add(rise, \"ising\")\nseq.add(sweep, \"ising\")\nseq.add(fall, \"ising\")\n</code></pre> <ul> <li>Quench: One of the most fundamental protocols to drive a system out of equilibrium, it is realized here as follows: at time \\(t=0\\) the system is prepared in the ground state \\(|\\psi_0\\rangle\\) of \\(H_0\\). The driving field is then suddenly turned on (\\(\\Omega\\neq0\\)) and the system is evolved for \\(t &gt; 0\\), as \\(|\\psi\\rangle=e^{-iHt}|\\psi_0\\rangle\\).</li> </ul> <pre><code>hx = 1.5  # hx/J_max\nhz = 0  # hz/J_max\nt = 1.5  # t/J_max\n# Set up Pulser simulations\nR = 7  # \u03bcm\nreg = Register.rectangle(nx, ny, R, prefix=\"q\")\n# Conversion from Rydberg Hamiltonian to Ising model\nU = AnalogDevice.interaction_coeff / R**6  # U_ij\nNN_coeff = U / 4\nomega = 2 * hx * NN_coeff\ndelta = -2 * hz * NN_coeff + 2 * U\nT = np.round(1000 * t / NN_coeff)\nseq = Sequence(reg, MockDevice) #circumvent the register spacing constraints\nseq.declare_channel(\"ising\", \"rydberg_global\")\n# Add the main pulse to the pulse sequence\nsimple_pulse = Pulse.ConstantPulse(T, omega, delta, 0)\nseq.add(simple_pulse, \"ising\")\n</code></pre> <p>These two types of driving typically complement each other. Since the matrix product state approach in emu-mps strives to minimize the stored information, keeping track of a single equilibrium state in adiabatic time evolution is typically easier. While this single state can be a complicated object itself, quenches, driving the system out of equilibrium, involve taking into account multiple excited states, and are typically computationally harder to emulate.</p>"},{"location":"benchmarks/#cpugpu-hardware","title":"CPU/GPU hardware","text":"<p>Emu-mps is built on top of pytorch. Thus, it can run on most available CPUs and GPUs, from a laptop to a cluster. The presented benchmarks are run on an NVIDIA DGX cluster node, requesting the following resources</p> <ul> <li>GPU: 1 NVIDIA A100 (40 GB)</li> <li>CPU: 16 cores on AMD EPYC 7742</li> </ul> <p>Of course, performance will vary depending on the hardware. For this reason, if at any point of your work, performance becomes critical, we always recommend to use Pasqal's DGX cluster. If you intend to run emu-mps on your laptop, for example, please be aware that the suggestion to use a GPU for heavier workloads might not be valid. In such case it is always good to check performance on a couple of runs, changing the emu-mps config default values as documented in the API. In particular <code>num_devices_to_use = 0</code> will run the emulation on CPU, while <code>num_devices_to_use \u2265 1</code> on GPU/s.</p>"},{"location":"benchmarks/accuracy/","title":"Accuracy","text":"<p>Here we discuss the emulator accuracy, as compared to Pulser state vector solver backend, but in the future we might directly compare with QPU results. Accuracy, here, specifically refers to observables:</p> <ul> <li>Energy: \\(E = \\langle\\psi|H|\\psi\\rangle\\)</li> <li>Energy variance: \\(\\Delta E = \\langle\\psi|H^2|\\psi\\rangle-E^2\\)</li> <li>Magnetization: \\(\\langle P_{0}^j\\rangle\\) where \\(P_{0}^j\\) projects qubit \\(j\\) onto the \\(|0\\rangle\\) state</li> </ul> <p>The emulated sequences are going to be the same as before, an adiabatic and a quench. In both cases, 9 qubits arrayed in a 3x3 grid are used, so that the results can also be simulated in Pulser. We will check accuracy against two main tunable parameters in emu-mps:</p> <ul> <li><code>precision</code><sup>[1]</sup>: at each step, throw away components of the state whose sum weighs less that the specified precision.</li> <li><code>dt</code>: sampling time step of the sequence.</li> </ul> <p>The goal is to show that for qubit numbers accessible to Pulser, the results are identical up to good precision.</p> <p> </p> <p>Both sequences are emulated multiple times by varying both the precision and time step. Notice that any deviations from Pulser for the adiabatic sequence are impossible to detect at the scale of the graph for a wide range of emulation parameters. For larger qubit numbers, such as the 7x7 grid, the question of convergence is much subtler (see here). Rather, what is interesting there, is that even for a 2d system, emu-mps correctly treats the Rydberg interaction, regardless of the effective description of long-range interaction terms that emu-mps uses.</p> <p>For the quench sequence, agreement with Pulser is still good for all shown parameter combinations, with the possible exception of the yellow curve, which has a deviation of 1%. For the quench sequence, the energy and energy variance are conserved quantities, meaning that all variation therein come from errors. Even though the relative errors are small, it's instructive to analyze the sources of these errors. For example, we see that emu-mps incurs the biggest error at the start of the emulation, when the bond dimension is still small (the bond dimension starts at 1, and increases from there). For a time-constant Hamiltonian, all deviations in the mean and variance of the energy come from truncation, and as expected, improving the precision reduces the error in the energy variance (see here). Finally, as explained in error sources in TDVP (see here), we see that reducing \\(dt\\) below a threshold (somewhere in the range of 1-5) causes a quick growth of the truncation errors, which requires improving the precision.</p> <p>The errors incurred by emu-mps can be contrasted with Pulser, which uses a generic ODE solver backend that does not take into account constants of the motion. Both the mean and variance of the energy exhibit a deviation from their initial value that is linear in the number of time-steps taken by the solver.</p>"},{"location":"benchmarks/noise/","title":"Noise","text":"<p>Here, we analyze the time evolution of a quantum state using the adiabatic sequence <sup>[1]</sup> under the influence of depolarizing noise. Typically, quantum systems are affected by interactions with their surrounding environment, making them open systems. To model the dynamics of such noisy quantum systems, one typically solves the Lindblad \"Master\" equation, which governs the time evolution of the density matrix, \\(\\rho\\).</p> <p>The following plot illustrates the time evolution of the initial state under the adiabatic \\(2\\text{D}\\) sequence. This is done by tracking the evolution of the energy (top left), variance (bottom left), and magnetization (top and bottom right) in the presence of depolarizing noise for a \\((2\\times2)\\) qubit register (\\(4\\) qubits). Specifically, we compare results from two different methods:</p> <ul> <li> <p>Pulser: explicitly solves the Lindblad Master equation, obtaining full information about the noise in the system through its probability distribution in phase space, as given by the density matrix</p> </li> <li> <p>emu-mps: uses a Monte Carlo (MC) method to probe the noise by obtaining sample statistics from its underlying probability distribution (see noise.md for further details).</p> </li> </ul> <p>The goal of this study is to demonstrate that the results obtained using the Monte Carlo method implemented in emu-mps are qualitatively similar to those found by solving the Lindblad master equation in Pulser.</p> <p></p> <p>The key advantage of the Monte Carlo method, if the Hilbert space of \\(N\\) qubits has dimension \\(dim(H) = d^N\\)\u200b, then propagating the density matrix using the Lindblad equation requires handling an object of size \\([dim(H)]^2\\)\u200b. In contrast, the stochastic sampling of states with emu-mps involves the propagation of state vectors of size \\(dim(H)\\) only. This drastically reduces the memory cost of the simulation, especially when the number of qubits is large. In return, the Monte Carlo method requires performing many runs if sample statistics are desired.</p>"},{"location":"benchmarks/noise/#accuracy-of-the-method","title":"Accuracy of the method","text":"<p>In this study, we consider two different depolarization noise rates: \\(0.2\\) and \\(0.5\\). These represent different levels of interaction with the environment, with \\(0.5\\) introducing stronger noise effects than \\(0.2\\). For the emu-mps simulations, the following parameters are used:</p> <ul> <li> <p>Monte Carlo runs: 100</p> </li> <li> <p>Precision: \\(10^{-6}\\), which is better than the default value (\\(10^{-5}\\)), as recommended in the warning found here.</p> </li> </ul> <p>Since the Monte Carlo method in emu-mps relies on stochastic sampling, the number of Monte Carlo runs chosen by the user determines the accuracy of the simulation. Each data point (e.g., in the energy plot) in the emu-mps results represents the statistical average observable value across all Monte Carlo runs at a given time \\(t\\). The plots demonstrate that with \\(100\\) Monte Carlo runs, emu-mps already yields qualitative agreement with Pulser. We expect that, increasing the number of Monte Carlo runs should smoothen the emu-mps curves further, leading to even closer agreement with the Pulser method.</p> <p>The overall energy of the system initially rises due to the presence of depolarizing noise, which introduces interactions between the system and the environment. This interaction reduces even further the strength of the spin correlations in the paramagnetic state. The system with higher noise rate (\\(0.5\\)) experiences stronger interaction effects, leading to a more pronounced increase in both the energy and energy fluctuations \\(\\Delta E\\). However, as the system continues to evolve, it begins to move toward an antiferromagnetic (AFM) correlated state, causing the energy and fluctuations to decrease. During this middle phase, the spin correlations become more meaningful, and the state grows gradually ordered. Eventually, the system undergoes a quantum phase transition at \\(t \\approx 3000\\) ns, moving from a paramagnetic state, where the spins are randomly aligned, to a true AFM state with well-defined spin ordering. This transition is reflected in the further reduction of energy fluctuations as the state becomes antiferromagnetic.</p>"},{"location":"benchmarks/noise/#performance","title":"Performance","text":"<p>Above we discussed the behaviour of an average over a larger number of noisy runs. Now, let us discuss the performance characteristics of a single run in more detail.</p> <p>In the following graph we show the performance characteristics of a single run of the above sequence, as a function of the time step, and as a function of qubit number. Do note that we have used the default precision of \\(10^{-5}\\), because that makes the parameters the same as the noiseless adiabatic benchmark here. This allows us to discuss the effect of adding Lindbladian noise to simulations on the performance characteristics.</p> <p></p> <p>One thing we immediately see is that all the bond dimensions are larger than in the noiseless case. As discussed above, the depolarizing noise pumps energy into the system, causing more high-energy states to be excited. When averaged over many runs, this causes correlations in the system to decrease, but during a single run, this means many highly-entangled states are excited by the quantum jumps, leading to a stark rise in the bond-dimension. Most of the difference in memory usage and runtime can be attributed to the fact that the quantum state being simulated is more complex than in the noiseless case. However, two effects particular to the simulation of noisy systems are visible in the graph:</p> <ul> <li>The peaks in the \\(\\Delta t\\) graph correspond to the occurence of a quantum jump</li> <li>In the absence of a quantum jump, the time for a single step is still longer.</li> </ul> <p>Regarding the first item, on the cluster you will occasionally see spikes in the time required for a single step even in the noiseless case. In that case, it is caused by load on the hardware from other jobs and more subtle factors. When doing quantum jumps, it is actually a feature of the algorithm. When doing a timestep according to the config parameter <code>dt</code>, the time evolution generally overshoots the time when a jump needs to occur. A numerical root-finding algorithm is employed to evolve the state to the actual jump time, after which the quantum jump is performed and the system is evolved again to complete the timestep of length <code>dt</code>. This means that a minimum of three time evolutions have to be performed when a quantum jump occurs in the middle of a <code>dt</code> interval. Looking at the height of the peaks in runtime, we see that they are mostly 3 or 4 times the height of the baseline, meaning that the root-finding algorithm converges to the collapse point in 1 or 2 steps the majority of the time, which is good performance. Note that the number of quantum jumps in the graph is quite large, because the depolarizing rate is <code>0.5</code>, which is much bigger than any of the noise rates in the physical device.</p> <p>Regarding the second point above, the effective Hamiltonian used to evolve the system is no longer Hermitian (see here), and our time-evolution algorithm is more expensive on non-Hermitian matrices. The overhead is dependent on the bond-dimension of the system. At the start, when the bond-dimension is close to 1, we see an overhead of about 10% runtime per step, but as the bond-dimension increases to 1000, it grows to around 50%.</p> <p>Since the runtime and memory required to compute a single time step depend polynomially on the bond-dimension, the most important question in determining the effect of noise on the performance of the simulation is how the bond-dimension of the state will be affected by said noise. In the example presented here, we used an adiabatic sequence for anti-ferromagnetic state preparation, and the noise can be seen to negatively impact adiabaticity of the sequence close to the quantum phase transition, just as if the qubit number increases<sup>[1]</sup>. This, in turn, means that for this specific pulse sequence, noise negatively impacts the size of the system that can still be simulated. The degree to which this effect manifests will depend on the sequence being simulated, and the type of noise under consideration.</p>"},{"location":"benchmarks/performance/","title":"Performance","text":"<p>Here, as anticipated in the introduction page of the benchmarks, we will track several relevant metrics associated with runtime, memory usage and bond dimension:</p> <ul> <li>Bond dimension \\(\\chi\\): the maximum internal link dimension of the MPS representation of the time evolved state (see here).</li> <li>State size \\(|\\psi|\\): memory footprint of the state (in MB).</li> <li>RSS: peak memory allocated by the emulation.</li> <li>\\(\\Delta t\\): CPU/GPU time to complete a time step.</li> </ul> <p>We will give information about these metrics for various values of N, the qubit number, to give an idea of how performance scales.</p>"},{"location":"benchmarks/performance/#adiabatic-sequence","title":"Adiabatic sequence","text":"<p>We run an adiabatic sequence to make an antiferromagnetic (AFM) state, as taken from Pulser documentation, for a 2D register of atoms in a grid.</p> <p>Performance metrics, for the defined sequence and for the biggest register (7x7) are shown below, in the left column of the figures, for CPU and GPU workloads. From the plots it is easy to understand that all the metrics heavily correlate with each other. Specifically a higher bond dimension will translate to higher memory footprint and longer runtimes (see here).</p> <p> </p> <p>In the right column (both CPU and GPU figure), we explore the available register size. Simply increasing the number of atoms by \\(N=N_x\\times N_y\\), and extracting the maximum metric and the total runtime for each run, the user can get a feeling on how much memory and time a specific sequence is going to take to emulate. Note that all qubit numbers which are not a square show up twice, since the rectangles making up this qubit number can be oriented two ways. The reason why orientation matters is explained by the results in the benchmark on qubit shuffling. Note that it's possible to simulate larger systems than done in this benchmark. For example, by tuning the config parameters, it's possible to accurately simulate the above pulse for a 7x7 grid (see here).</p>"},{"location":"benchmarks/performance/#performance-for-a-7x7-grid","title":"Performance for a 7x7 grid","text":"<p>Let us now analyze the performance of the simulation for a much larger system. We show results for the adiabatic sequence with 49 qubits arranged in a 7x7 grid. The parameters of the simulation were <code>max_bond_dim = 1600</code>, <code>extra_krylov_tolerance=1e-5</code> and <code>precision=1e-6</code>, and we ran the simulation on 2 GPUs. The maximum bond dimension of the state, its size in memory, the total memory consumption of the program on GPU 1, and the time taken per emulation time step (there are 390 time steps of <code>dt=10 ns</code> each) are shown in the graph below.</p> <p>First off, note that the peak memory consumption on GPU 1 reaches almost 30 GB at the end of the simulation and the memory profile on GPU 2 will be very similar. Note that this memory consumption can be estimated (see here), and that the simulation would not have fit on a single GPU. Next, the memory consumption stops increasing as quickly when the maximum bond dimension plateaus, but it does not stop increasing entirely. This is because when the maximum bond dimension reaches the cutoff value of <code>1600</code>, most of the tensors in the MPS will not have reached maximum size yet. However, the rate of memory consumption growth will decrease as more of the tensors reach this maximum size.</p> <p>Finally, it can be seen that the time taken per time step scales roughly linearly with the memory consumption of the quantum state. This proposes an obvious method for speeding up the simulation. We've mentioned above, that the qubit density results were insensitive to changes in <code>max_bond_dim</code>, and that a value of <code>max_bond_dim</code> smaller than <code>1600</code> would likely still generate good results. As a consequence of the above graph, we ran the simulation with <code>max_bond_dim=1000</code> and all other parameters the same, and indeed, the qubit density was identical up to the 2 digits of precision used above. As can be read off from the above graph, this corresponds to a final time per step of <code>100s</code>, yielding a significant reduction in simulation time while keeping the results at the desired precision.</p>"},{"location":"benchmarks/performance/#quench","title":"Quench","text":"<p>Here, we explore performance in the very same way as before, but for the quench sequence discussed in the introduction. The overall metrics, as before, both for a single run (left) and for multiple runs varying the register size (right, \\(N=N_x\\times N_y\\)) are presented below:</p> <p> </p> <p>As expected, a quench requires significantly more memory to run than the adiabatic sequence (see here).</p>"},{"location":"benchmarks/performance/#qubit-shuffling","title":"Qubit shuffling","text":"<p>A seemingly innocuous operation like reordering the register labels can actually affect the performance, as a consequence of the MPS representation (see here). In simple terms, the additional memory cost, and thus performance decrease, comes from representing two strongly interacting atoms in two far apart tensors in the MPS, since all the intermediate tensors in the chain have to somehow pass that information between them.</p> <p>To be more quantitative, in the following benchmark case, we run the same AFM sequence from before, but shuffling the qubit labeling order.</p> <p>The unshuffled register ordering is that given by <code>Register.rectangle</code> as used in the above two sequences. For the 3x3 grid used in this benchmark, that means a register ordering of</p> 1  2  3  4  5  6  7  8  9  <p>Compare this with the shuffled register, which was constructed to put qubits that are close in physical space far away in index space</p>  2  7  4   5  1  9   8  3  6  <p>The left column of the image shows no accuracy degradation from the qubit shuffling, returning equivalent observables. That is expected since both runs were able to converge to the desired precision.</p> <p>However, performance metrics (allocations and runtime) of the shuffled case significantly worsen, because shuffling the qubits introduces artificial long-range entanglement into the system, increasing the bond dimension. This larger bond dimension means the matrices involved in the computations are bigger, requiring more memory and compute time.</p> <p>In the future we plan to apply register ordering strategies by default, but for the moment, the take-home message is that a good register embedding is important. Ideally, one should keep strongly interactive pairs or atoms the closest possible when enumerating them in the register.</p>"},{"location":"developer/ising_MPO/","title":"ising MPO","text":"In\u00a0[1]: Copied! <pre># import libraries\n!pip install sympy\nimport sympy as sp\nfrom sympy.physics.quantum import TensorProduct as TP\nfrom IPython.display import display, Latex\n</pre> # import libraries !pip install sympy import sympy as sp from sympy.physics.quantum import TensorProduct as TP from IPython.display import display, Latex <pre>Requirement already satisfied: sympy in /home/mauro/miniforge3/envs/pulserenv/lib/python3.12/site-packages (1.13.1)\nRequirement already satisfied: mpmath&lt;1.4,&gt;=1.1.0 in /home/mauro/miniforge3/envs/pulserenv/lib/python3.12/site-packages (from sympy) (1.3.0)\n</pre> <p>We will use Sympy for the symbolic representation of the elements in the MPO. This will help us understand which operators are applied to each site and where to place the constants that represent the interaction terms.</p> <p>In the following section, we will define functions that will assist in constructing the MPO.</p> In\u00a0[2]: Copied! <pre># creation of the identity and number operators\ndef iden_op(i:int):\n    \"\"\"Single qubit identity operator\"\"\"\n    return sp.Symbol(f\"\ud835\udfd9_{i}\", commutative=False)\n\ndef n_op(i:int):\n    \"\"\"Single qubit number operator\"\"\"\n    return sp.Symbol(f\"n_{i}\", commutative=False)\n</pre> # creation of the identity and number operators def iden_op(i:int):     \"\"\"Single qubit identity operator\"\"\"     return sp.Symbol(f\"\ud835\udfd9_{i}\", commutative=False)  def n_op(i:int):     \"\"\"Single qubit number operator\"\"\"     return sp.Symbol(f\"n_{i}\", commutative=False) In\u00a0[3]: Copied! <pre>#utility functions\ndef gate_at(d: dict[int, sp.Symbol], n: int):\n    \"\"\"Utility function for filling operators with identities.\"\"\"\n    return TP(*(\n        iden_op(i) if i not in d\n        else d[i]\n        for i in range(n)\n    ))\n\n\ndef mpo_factors_product_pairwise(a: sp.Matrix, b: sp.Matrix):\n    \"\"\"Matrix product where element-wise multiplication is the tensor product.\"\"\"\n\n    assert sp.shape(a)[1] == sp.shape(b)[0], \"Incompatible matrix dimensions\"\n\n    common_dim = sp.shape(a)[1]\n\n    res_rows = sp.shape(a)[0]\n    res_cols = sp.shape(b)[1]\n\n    res = sp.Matrix([\n            [sum(TP(a[row, k], b[k, col]).expand(tensorproduct=True) for k in range(common_dim))\n                for col in range(res_cols)\n            ]\n        for row in range(res_rows)\n    ])\n\n    if res_rows == res_cols == 1:\n        return res[0, 0]\n\n    return res\n\n\ndef mpo_factors_product(*args):\n    \"\"\"n-ary matrix product where element-wise multiplication is the tensor product.\"\"\"\n\n    assert len(args) &gt;= 2\n    if len(args) == 2:\n        return mpo_factors_product_pairwise(*args)\n    \n    return mpo_factors_product_pairwise(args[0], mpo_factors_product(*args[1:]))\n</pre> #utility functions def gate_at(d: dict[int, sp.Symbol], n: int):     \"\"\"Utility function for filling operators with identities.\"\"\"     return TP(*(         iden_op(i) if i not in d         else d[i]         for i in range(n)     ))   def mpo_factors_product_pairwise(a: sp.Matrix, b: sp.Matrix):     \"\"\"Matrix product where element-wise multiplication is the tensor product.\"\"\"      assert sp.shape(a)[1] == sp.shape(b)[0], \"Incompatible matrix dimensions\"      common_dim = sp.shape(a)[1]      res_rows = sp.shape(a)[0]     res_cols = sp.shape(b)[1]      res = sp.Matrix([             [sum(TP(a[row, k], b[k, col]).expand(tensorproduct=True) for k in range(common_dim))                 for col in range(res_cols)             ]         for row in range(res_rows)     ])      if res_rows == res_cols == 1:         return res[0, 0]      return res   def mpo_factors_product(*args):     \"\"\"n-ary matrix product where element-wise multiplication is the tensor product.\"\"\"      assert len(args) &gt;= 2     if len(args) == 2:         return mpo_factors_product_pairwise(*args)          return mpo_factors_product_pairwise(args[0], mpo_factors_product(*args[1:])) <p>$\\newcommand\\unity{1\\!\\!1}$</p> In\u00a0[4]: Copied! <pre>#implementation of S, E, Li, Rj and E\ndef _first_factor_rydberg(gate: sp.Symbol)-&gt;sp.Matrix:\n    \"\"\"\n    Creates the first Rydberg Hamiltonian factor.\n    \"\"\"\n    fac = sp.zeros(1, 3) \n    fac[0, 1] = iden_op(0)\n    fac[0, 2] = n_op(0)  # number operator\n\n    fac[0, 0] = gate\n    return fac\n\n\ndef _last_factor_rydberg(gate: sp.Symbol, scale: float | complex, num_atoms: int)-&gt;sp.Matrix:\n    \"\"\"\n    Creates the last Rydberg Hamiltonian factor.\n    \"\"\"\n    fac = sp.zeros(3, 1)\n    fac[0, 0] = iden_op(num_atoms)\n    fac[2, 0] = scale * n_op(num_atoms)\n\n    fac[1, 0] = gate\n    return fac\n\n\ndef _left_factor_rydberg(gate: sp.Symbol, scales: list[sp.Symbol], num_atom: int)-&gt;sp.Matrix:\n    \"\"\"\n    Creates the Rydberg Hamiltonian factors in the left half of the MPS, excepted the first factor.\n    \"\"\"\n    index = len(scales)\n    fac = sp.zeros(\n        index + 2,\n        index + 3,\n    )\n    for i, val in enumerate(scales):\n        fac[i + 2, 0] = val * n_op(num_atom)  # interaction with previous qubits\n    fac[1, index + 2] = n_op(num_atom)  #  interaction with next qubits\n    for i in range(index + 2):\n        fac[i, i] = iden_op(\n            num_atom\n        )  # identity matrix to carry the gates of other qubits\n\n    fac[1, 0] = gate\n    return fac\n\n\ndef _right_factor_rydberg(gate: sp.Symbol, scales: list[sp.Symbol], num_atom: int)-&gt;sp.Matrix:\n    \"\"\"\n    Creates the Rydberg Hamiltonian factors in the right half of the MPS, excepted the last factor.\n    \"\"\"\n    index = len(scales)\n    fac = sp.zeros(index + 3, index + 2)\n    for i, val in enumerate(scales):\n        fac[1, i + 2] = val * n_op(num_atom)  # XY interaction with previous qubits\n    fac[2, 0] = n_op(num_atom)  # XY interaction with next qubits\n    for i in range(2, index + 2):\n        fac[i + 1, i] = iden_op(num_atom)\n    fac[0, 0] = iden_op(\n        num_atom\n    )  # identity to carry the next gates to the previous qubits\n    fac[1, 1] = iden_op(num_atom)  # identity to carry previous gates to next qubits\n\n    fac[1, 0] = gate\n    return fac\n\n\ndef _middle_factor_rydberg(\n    gate: sp.Symbol,\n    scales_l: list[sp.Symbol],\n    scales_r: list[sp.Symbol],\n    scales_mat: list[list[sp.Symbol]],\n    num_atom:int\n)-&gt;sp.Matrix:\n    \"\"\"\n    Creates the Rydberg Hamiltonian factor at index \u230an/2\u230b of the n-qubit MPO.\n    \"\"\"\n    assert len(scales_mat) == len(scales_l)\n    assert all(len(x) == len(scales_r) for x in scales_mat)\n\n    fac = sp.zeros(\n        len(scales_l) + 2,\n        len(scales_r) + 2,\n    )\n    for i, val in enumerate(scales_r):\n        fac[1, i + 2] = val * n_op(num_atom)  # rydberg interaction with previous qubits\n    for i, val in enumerate(scales_l):\n        fac[i + 2, 0] = val * n_op(num_atom)  # rydberg interaction with next qubits\n    for i, row in enumerate(scales_mat):\n        for j, val in enumerate(row):\n            fac[i + 2, j + 2] = (\n                val * iden_op(num_atom)\n            )  # rydberg interaction of previous with next qubits\n    fac[0, 0] = iden_op(num_atom)  # identity to carry the next gates to the previous qubits\n    fac[1, 1] = iden_op(num_atom)  # identity to carry previous gates to next qubits\n\n    fac[1, 0] = gate\n    return fac\n</pre> #implementation of S, E, Li, Rj and E def _first_factor_rydberg(gate: sp.Symbol)-&gt;sp.Matrix:     \"\"\"     Creates the first Rydberg Hamiltonian factor.     \"\"\"     fac = sp.zeros(1, 3)      fac[0, 1] = iden_op(0)     fac[0, 2] = n_op(0)  # number operator      fac[0, 0] = gate     return fac   def _last_factor_rydberg(gate: sp.Symbol, scale: float | complex, num_atoms: int)-&gt;sp.Matrix:     \"\"\"     Creates the last Rydberg Hamiltonian factor.     \"\"\"     fac = sp.zeros(3, 1)     fac[0, 0] = iden_op(num_atoms)     fac[2, 0] = scale * n_op(num_atoms)      fac[1, 0] = gate     return fac   def _left_factor_rydberg(gate: sp.Symbol, scales: list[sp.Symbol], num_atom: int)-&gt;sp.Matrix:     \"\"\"     Creates the Rydberg Hamiltonian factors in the left half of the MPS, excepted the first factor.     \"\"\"     index = len(scales)     fac = sp.zeros(         index + 2,         index + 3,     )     for i, val in enumerate(scales):         fac[i + 2, 0] = val * n_op(num_atom)  # interaction with previous qubits     fac[1, index + 2] = n_op(num_atom)  #  interaction with next qubits     for i in range(index + 2):         fac[i, i] = iden_op(             num_atom         )  # identity matrix to carry the gates of other qubits      fac[1, 0] = gate     return fac   def _right_factor_rydberg(gate: sp.Symbol, scales: list[sp.Symbol], num_atom: int)-&gt;sp.Matrix:     \"\"\"     Creates the Rydberg Hamiltonian factors in the right half of the MPS, excepted the last factor.     \"\"\"     index = len(scales)     fac = sp.zeros(index + 3, index + 2)     for i, val in enumerate(scales):         fac[1, i + 2] = val * n_op(num_atom)  # XY interaction with previous qubits     fac[2, 0] = n_op(num_atom)  # XY interaction with next qubits     for i in range(2, index + 2):         fac[i + 1, i] = iden_op(num_atom)     fac[0, 0] = iden_op(         num_atom     )  # identity to carry the next gates to the previous qubits     fac[1, 1] = iden_op(num_atom)  # identity to carry previous gates to next qubits      fac[1, 0] = gate     return fac   def _middle_factor_rydberg(     gate: sp.Symbol,     scales_l: list[sp.Symbol],     scales_r: list[sp.Symbol],     scales_mat: list[list[sp.Symbol]],     num_atom:int )-&gt;sp.Matrix:     \"\"\"     Creates the Rydberg Hamiltonian factor at index \u230an/2\u230b of the n-qubit MPO.     \"\"\"     assert len(scales_mat) == len(scales_l)     assert all(len(x) == len(scales_r) for x in scales_mat)      fac = sp.zeros(         len(scales_l) + 2,         len(scales_r) + 2,     )     for i, val in enumerate(scales_r):         fac[1, i + 2] = val * n_op(num_atom)  # rydberg interaction with previous qubits     for i, val in enumerate(scales_l):         fac[i + 2, 0] = val * n_op(num_atom)  # rydberg interaction with next qubits     for i, row in enumerate(scales_mat):         for j, val in enumerate(row):             fac[i + 2, j + 2] = (                 val * iden_op(num_atom)             )  # rydberg interaction of previous with next qubits     fac[0, 0] = iden_op(num_atom)  # identity to carry the next gates to the previous qubits     fac[1, 1] = iden_op(num_atom)  # identity to carry previous gates to next qubits      fac[1, 0] = gate     return fac In\u00a0[5]: Copied! <pre>def general_make_H(interaction_matrix:list[list[sp.Symbol]],single_qubit_term:list[sp.Symbol]):\n    \"\"\"Based on make_H function of emu-mps. \n    Constains the basics functions that creates the MPO for the \n    Hamiltonian: H = SL1...La M R1 .... Rb E \"\"\"\n\n    \n    nqubits = interaction_matrix.shape[0]\n    cores = [_first_factor_rydberg(single_qubit_term[0])]\n    if nqubits &gt; 2:\n        for i in range(1, nqubits // 2):\n\n            cores.append(\n                _left_factor_rydberg(\n                    single_qubit_term[i],\n                    [interaction_matrix[j, i] for j in range(i)],\n                i)\n            )\n\n        i = nqubits // 2\n        cores.append(\n            _middle_factor_rydberg(\n                single_qubit_term[i],\n                [interaction_matrix[j, i] for j in range(i)],\n                [interaction_matrix[i, j] for j in range(i + 1, nqubits)],\n                [\n                    [interaction_matrix[k, j] for j in range(i + 1, nqubits)]\n                    for k in range(i)\n                ],\n            i)\n        )\n\n        for i in range(nqubits // 2 + 1, nqubits - 1):\n            cores.append(\n                _right_factor_rydberg(\n                    single_qubit_term[i],\n                    [interaction_matrix[i, j] for j in range(i + 1, nqubits)],\n                i)\n            )\n\n    scale = 1 # int for printing with sympy \n    if nqubits == 2:\n        scale = interaction_matrix[0, 1]\n    cores.append(\n        _last_factor_rydberg(\n            single_qubit_term[-1],\n            scale,nqubits-1\n        )\n    )\n    return cores\n</pre> def general_make_H(interaction_matrix:list[list[sp.Symbol]],single_qubit_term:list[sp.Symbol]):     \"\"\"Based on make_H function of emu-mps.      Constains the basics functions that creates the MPO for the      Hamiltonian: H = SL1...La M R1 .... Rb E \"\"\"           nqubits = interaction_matrix.shape[0]     cores = [_first_factor_rydberg(single_qubit_term[0])]     if nqubits &gt; 2:         for i in range(1, nqubits // 2):              cores.append(                 _left_factor_rydberg(                     single_qubit_term[i],                     [interaction_matrix[j, i] for j in range(i)],                 i)             )          i = nqubits // 2         cores.append(             _middle_factor_rydberg(                 single_qubit_term[i],                 [interaction_matrix[j, i] for j in range(i)],                 [interaction_matrix[i, j] for j in range(i + 1, nqubits)],                 [                     [interaction_matrix[k, j] for j in range(i + 1, nqubits)]                     for k in range(i)                 ],             i)         )          for i in range(nqubits // 2 + 1, nqubits - 1):             cores.append(                 _right_factor_rydberg(                     single_qubit_term[i],                     [interaction_matrix[i, j] for j in range(i + 1, nqubits)],                 i)             )      scale = 1 # int for printing with sympy      if nqubits == 2:         scale = interaction_matrix[0, 1]     cores.append(         _last_factor_rydberg(             single_qubit_term[-1],             scale,nqubits-1         )     )     return cores  In\u00a0[6]: Copied! <pre># declaring a symbol A for single site operator and U for the interaction coefficient\ndef A(i: int)-&gt;sp.Symbol:\n    \"\"\"Single qubit terms\"\"\"\n    return sp.Symbol(f\"A_{i}\", commutative=False)\n\ndef U(i: int, j: int)-&gt;sp.Symbol:\n    \"\"\"Interaction coefficient for i,j atoms\"\"\"\n    return sp.Symbol(f\"U_{i}{j}\")\n</pre> # declaring a symbol A for single site operator and U for the interaction coefficient def A(i: int)-&gt;sp.Symbol:     \"\"\"Single qubit terms\"\"\"     return sp.Symbol(f\"A_{i}\", commutative=False)  def U(i: int, j: int)-&gt;sp.Symbol:     \"\"\"Interaction coefficient for i,j atoms\"\"\"     return sp.Symbol(f\"U_{i}{j}\") In\u00a0[7]: Copied! <pre>#interaction matrix \ndef general_interaction_matrix(num_atoms:int)-&gt;sp.Matrix:\n    \"\"\"\" For this tutorial purpuses: generates a symmetric matrix where its elements U\u1d62\u2c7c represents the Rydberg interaction\n    between atom i and atom j.\"\"\"\n    interaction_matrix = sp.zeros(num_atoms,num_atoms)\n    for numi in range(num_atoms):\n        for numj in range(numi + 1, num_atoms):\n            interaction_matrix[numi,numj] = U(numi,numj)\n            interaction_matrix[numj, numi] = interaction_matrix[numi, numj] # for symmetry \n    return interaction_matrix\n</pre> #interaction matrix  def general_interaction_matrix(num_atoms:int)-&gt;sp.Matrix:     \"\"\"\" For this tutorial purpuses: generates a symmetric matrix where its elements U\u1d62\u2c7c represents the Rydberg interaction     between atom i and atom j.\"\"\"     interaction_matrix = sp.zeros(num_atoms,num_atoms)     for numi in range(num_atoms):         for numj in range(numi + 1, num_atoms):             interaction_matrix[numi,numj] = U(numi,numj)             interaction_matrix[numj, numi] = interaction_matrix[numi, numj] # for symmetry      return interaction_matrix In\u00a0[8]: Copied! <pre>single_terms = [A(0),A(1),A(2)]\ninter_matri = general_interaction_matrix(3)\ncores = general_make_H(inter_matri,single_terms)\nprint(\"Matrix S:\")\ndisplay(cores[0])\nprint(\"Matrix M:\")\ndisplay(cores[1])\nprint(\"Matrix E:\")\ndisplay(cores[2])\n</pre> single_terms = [A(0),A(1),A(2)] inter_matri = general_interaction_matrix(3) cores = general_make_H(inter_matri,single_terms) print(\"Matrix S:\") display(cores[0]) print(\"Matrix M:\") display(cores[1]) print(\"Matrix E:\") display(cores[2]) <pre>Matrix S:\n</pre>  $\\displaystyle \\left[\\begin{matrix}A_{0} &amp; \ud835\udfd9_{0} &amp; n_{0}\\end{matrix}\\right]$  <pre>Matrix M:\n</pre>  $\\displaystyle \\left[\\begin{matrix}\ud835\udfd9_{1} &amp; 0 &amp; 0\\\\A_{1} &amp; \ud835\udfd9_{1} &amp; U_{12} n_{1}\\\\U_{01} n_{1} &amp; 0 &amp; U_{02} \\cdot \ud835\udfd9_{1}\\end{matrix}\\right]$  <pre>Matrix E:\n</pre>  $\\displaystyle \\left[\\begin{matrix}\ud835\udfd9_{2}\\\\A_{2}\\\\n_{2}\\end{matrix}\\right]$  <p>The final Rydberg Hamiltonian with all its terms:</p> In\u00a0[9]: Copied! <pre>mpo_factors_product(*cores)\n</pre> mpo_factors_product(*cores) Out[9]:  $\\displaystyle U_{01} {n_{0}}\\otimes {{n_{1}}\\otimes {\ud835\udfd9_{2}}} + U_{02} {n_{0}}\\otimes {{\ud835\udfd9_{1}}\\otimes {n_{2}}} + U_{12} {\ud835\udfd9_{0}}\\otimes {{n_{1}}\\otimes {n_{2}}} + {A_{0}}\\otimes {{\ud835\udfd9_{1}}\\otimes {\ud835\udfd9_{2}}} + {\ud835\udfd9_{0}}\\otimes {{A_{1}}\\otimes {\ud835\udfd9_{2}}} + {\ud835\udfd9_{0}}\\otimes {{\ud835\udfd9_{1}}\\otimes {A_{2}}}$  In\u00a0[10]: Copied! <pre>def reference_hamiltonian(qubit_count: int):\n    \"\"\"For testing puruposes: creates the Rydberg Hamiltonian \"\"\"\n    result = sum(gate_at({i: A(i)}, qubit_count) for i in range(qubit_count))\n\n    result += sum(\n        U(j, i) *\n        gate_at({\n            i: n_op(i),\n            j: n_op(j)\n        }, qubit_count)\n        for i in range(qubit_count) for j in range(i)\n    )\n\n    return result\n</pre> def reference_hamiltonian(qubit_count: int):     \"\"\"For testing puruposes: creates the Rydberg Hamiltonian \"\"\"     result = sum(gate_at({i: A(i)}, qubit_count) for i in range(qubit_count))      result += sum(         U(j, i) *         gate_at({             i: n_op(i),             j: n_op(j)         }, qubit_count)         for i in range(qubit_count) for j in range(i)     )      return result In\u00a0[11]: Copied! <pre>## simple testing the MPO for 3 atoms with the reference Hamiltonian\nstr(reference_hamiltonian(3)) == str(mpo_factors_product(*cores))\n</pre> ## simple testing the MPO for 3 atoms with the reference Hamiltonian str(reference_hamiltonian(3)) == str(mpo_factors_product(*cores)) Out[11]: <pre>True</pre> In\u00a0[12]: Copied! <pre>single_terms = [A(0),A(1),A(2),A(3),A(4)]\ninter_matri = general_interaction_matrix(5)\ncores = general_make_H(inter_matri,single_terms)\nprint(\"Matrix S:\")\ndisplay(cores[0])\ndisplay(Latex(f\"Matrix $L_1$:\"))\n\ndisplay(cores[1])\nprint(\"Matrix M:\")\ndisplay(cores[2])\ndisplay(Latex(f\"Matrix $R_1$:\"))\ndisplay(cores[3])\nprint(\"Matrix E:\")\ndisplay(cores[4])\n</pre> single_terms = [A(0),A(1),A(2),A(3),A(4)] inter_matri = general_interaction_matrix(5) cores = general_make_H(inter_matri,single_terms) print(\"Matrix S:\") display(cores[0]) display(Latex(f\"Matrix $L_1$:\"))  display(cores[1]) print(\"Matrix M:\") display(cores[2]) display(Latex(f\"Matrix $R_1$:\")) display(cores[3]) print(\"Matrix E:\") display(cores[4]) <pre>Matrix S:\n</pre>  $\\displaystyle \\left[\\begin{matrix}A_{0} &amp; \ud835\udfd9_{0} &amp; n_{0}\\end{matrix}\\right]$   Matrix $L_1$:   $\\displaystyle \\left[\\begin{matrix}\ud835\udfd9_{1} &amp; 0 &amp; 0 &amp; 0\\\\A_{1} &amp; \ud835\udfd9_{1} &amp; 0 &amp; n_{1}\\\\U_{01} n_{1} &amp; 0 &amp; \ud835\udfd9_{1} &amp; 0\\end{matrix}\\right]$  <pre>Matrix M:\n</pre>  $\\displaystyle \\left[\\begin{matrix}\ud835\udfd9_{2} &amp; 0 &amp; 0 &amp; 0\\\\A_{2} &amp; \ud835\udfd9_{2} &amp; U_{23} n_{2} &amp; U_{24} n_{2}\\\\U_{02} n_{2} &amp; 0 &amp; U_{03} \\cdot \ud835\udfd9_{2} &amp; U_{04} \\cdot \ud835\udfd9_{2}\\\\U_{12} n_{2} &amp; 0 &amp; U_{13} \\cdot \ud835\udfd9_{2} &amp; U_{14} \\cdot \ud835\udfd9_{2}\\end{matrix}\\right]$   Matrix $R_1$:   $\\displaystyle \\left[\\begin{matrix}\ud835\udfd9_{3} &amp; 0 &amp; 0\\\\A_{3} &amp; \ud835\udfd9_{3} &amp; U_{34} n_{3}\\\\n_{3} &amp; 0 &amp; 0\\\\0 &amp; 0 &amp; \ud835\udfd9_{3}\\end{matrix}\\right]$  <pre>Matrix E:\n</pre>  $\\displaystyle \\left[\\begin{matrix}\ud835\udfd9_{4}\\\\A_{4}\\\\n_{4}\\end{matrix}\\right]$  <p>The final Rydberg Hamiltonian with all its terms is:</p> In\u00a0[13]: Copied! <pre>mpo_factors_product(*cores)\n</pre> mpo_factors_product(*cores) Out[13]:  $\\displaystyle U_{01} {n_{0}}\\otimes {{n_{1}}\\otimes {{\ud835\udfd9_{2}}\\otimes {{\ud835\udfd9_{3}}\\otimes {\ud835\udfd9_{4}}}}} + U_{02} {n_{0}}\\otimes {{\ud835\udfd9_{1}}\\otimes {{n_{2}}\\otimes {{\ud835\udfd9_{3}}\\otimes {\ud835\udfd9_{4}}}}} + U_{03} {n_{0}}\\otimes {{\ud835\udfd9_{1}}\\otimes {{\ud835\udfd9_{2}}\\otimes {{n_{3}}\\otimes {\ud835\udfd9_{4}}}}} + U_{04} {n_{0}}\\otimes {{\ud835\udfd9_{1}}\\otimes {{\ud835\udfd9_{2}}\\otimes {{\ud835\udfd9_{3}}\\otimes {n_{4}}}}} + U_{12} {\ud835\udfd9_{0}}\\otimes {{n_{1}}\\otimes {{n_{2}}\\otimes {{\ud835\udfd9_{3}}\\otimes {\ud835\udfd9_{4}}}}} + U_{13} {\ud835\udfd9_{0}}\\otimes {{n_{1}}\\otimes {{\ud835\udfd9_{2}}\\otimes {{n_{3}}\\otimes {\ud835\udfd9_{4}}}}} + U_{14} {\ud835\udfd9_{0}}\\otimes {{n_{1}}\\otimes {{\ud835\udfd9_{2}}\\otimes {{\ud835\udfd9_{3}}\\otimes {n_{4}}}}} + U_{23} {\ud835\udfd9_{0}}\\otimes {{\ud835\udfd9_{1}}\\otimes {{n_{2}}\\otimes {{n_{3}}\\otimes {\ud835\udfd9_{4}}}}} + U_{24} {\ud835\udfd9_{0}}\\otimes {{\ud835\udfd9_{1}}\\otimes {{n_{2}}\\otimes {{\ud835\udfd9_{3}}\\otimes {n_{4}}}}} + U_{34} {\ud835\udfd9_{0}}\\otimes {{\ud835\udfd9_{1}}\\otimes {{\ud835\udfd9_{2}}\\otimes {{n_{3}}\\otimes {n_{4}}}}} + {A_{0}}\\otimes {{\ud835\udfd9_{1}}\\otimes {{\ud835\udfd9_{2}}\\otimes {{\ud835\udfd9_{3}}\\otimes {\ud835\udfd9_{4}}}}} + {\ud835\udfd9_{0}}\\otimes {{A_{1}}\\otimes {{\ud835\udfd9_{2}}\\otimes {{\ud835\udfd9_{3}}\\otimes {\ud835\udfd9_{4}}}}} + {\ud835\udfd9_{0}}\\otimes {{\ud835\udfd9_{1}}\\otimes {{A_{2}}\\otimes {{\ud835\udfd9_{3}}\\otimes {\ud835\udfd9_{4}}}}} + {\ud835\udfd9_{0}}\\otimes {{\ud835\udfd9_{1}}\\otimes {{\ud835\udfd9_{2}}\\otimes {{A_{3}}\\otimes {\ud835\udfd9_{4}}}}} + {\ud835\udfd9_{0}}\\otimes {{\ud835\udfd9_{1}}\\otimes {{\ud835\udfd9_{2}}\\otimes {{\ud835\udfd9_{3}}\\otimes {A_{4}}}}}$  In\u00a0[14]: Copied! <pre>#simple testing the Hamiltonian generated\nstr(reference_hamiltonian(5)) == str(mpo_factors_product(*cores))\n</pre> #simple testing the Hamiltonian generated str(reference_hamiltonian(5)) == str(mpo_factors_product(*cores)) Out[14]: <pre>True</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"developer/ising_MPO/#rydberg-hamiltonian-to-mpo","title":"Rydberg Hamiltonian to MPO\u00b6","text":"<p>In this notebook, we will demostrate how to construct a Matrix Product Operator (MPO) representation of a Hamiltonian with two-body Rydberg-Rydberg interaction ,</p> <p>$$H= \\sum _{i} \\biggr(\\frac{\\Omega_i}{2} \\sigma_x - \\delta _i n_i \\biggr) + \\sum_ {i&lt;j} c_ {i,j} n_i n_j, $$</p> <p>This document is intended for developers and curious users who want to understand how to practically implement such a Hamiltonian in a Matrix Product State (MPS) emulator, like Pasqal's emu-mps.</p> <p>We will introduce the concept of operator-valued matrices, which are key to constructing the MPO. Through practical examples, we aim to clarify the procedure.</p> <p>This tutorial is organized as follows: The first section, Rydberg Hamiltonian to MPO, will cover the basic theory behind our implementation. The next section, Code Implementation, will contain the functions that generate the MPO of the Rydberg Hamiltonian. Finally, the Examples section will demonstrate the results for 3 and 5 atoms.</p>"},{"location":"developer/ising_MPO/#rydberg-hamiltonian-to-mpo","title":"Rydberg Hamiltonian to MPO\u00b6","text":"<p>We aim to represent the Rydberg Hamiltonian, given by:</p> <p>$$H= \\sum _{i} \\biggr(\\frac{\\Omega_i}{2} \\sigma_x - \\delta _i n_i \\biggr) + \\sum_ {i&lt;j} c_ {i,j} n_i n_j, $$</p> <p>where $n$ is the number operator and $\\sigma_x$ is the x pauli operator as a Matrix Product Operator or MPO</p> <p>As can be seen, we have set the phase to zero ($\\phi=0$), which cancels out the $\\sigma_y$ term in the original Hamiltonian. However, this will not affect the resulting MPO because, as we will see later, all single-gate terms will be located in a specific position within the MPO.</p> <p>To facilitate the calculations, let us express a rank-4 tensor</p> <p>as operator-valued matrices, given by  $\\begin{bmatrix}  B_{0,0} &amp; B_{0,1} &amp; \\ldots \\\\  B_{1,0} &amp; B_{1,1} &amp; \\ldots \\\\  \\ldots &amp; \\ldots &amp;\\ddots \\end{bmatrix}$</p> <p>where each $B_{i,j}$ has indices $k,l$. Additionally, we define the multiplication of the inner matrices as the Kronecker product $\\otimes$. Then, an MPO consists of a series of matrices, and performing matrix multiplication is equivalent to contracting the bonds and reshaping all physical input and output indices into a single \u201cfat\u201d index for input and output, respectively.</p>"},{"location":"developer/ising_MPO/#single-terms","title":"Single terms\u00b6","text":"<p>The sum of single-qubit terms such as: $$ A_i = \\left( \\frac{\\Omega_i}{2} \\sigma_i^x - \\delta_i n_i \\right), $$</p> <p>we can implement them with a bond dimension of 2.</p> <p>For each qubit $i$, the Hamiltonian term $A_i$\u200b is represented as a $2\\times 2$ matrix in the MPO at position $i$. Thus, the MPO takes the following structure: \\begin{bmatrix}\\unity_i &amp; 0 \\\\ A_i &amp; \\unity _i \\end{bmatrix} The overall Hamiltonian MPO for multiple qubits is constructed by taking the matrix product of these individual MPOs</p> <p>For example, let\u2019s create the MPOs for the Rydberg Hamiltonian of 3 atoms, where only single operators $A_i = X_i$ are applied to each atom:</p> <p>$$H = \\begin{bmatrix} X_1 &amp; \\unity_1 \\\\ \\end{bmatrix} \\begin{bmatrix}\\unity_2 &amp; 0 \\\\ X_2 &amp; \\unity  \\end{bmatrix}  \\begin{bmatrix}  \\unity_3 \\\\ X_3 \\end{bmatrix} $$</p> <p>$$H = \\begin{bmatrix} X_1 \\otimes  \\unity_2 + \\unity_1  \\otimes X_1 &amp; \\unity_2  \\end{bmatrix}  \\begin{bmatrix}  \\unity_3 \\\\ X_3 \\end{bmatrix}$$</p> <p>$$H = X_1 \\otimes \\unity_2 \\otimes \\unity_3 + \\unity_1 \\otimes X_2 \\otimes \\unity_3 +\\unity_1 \\otimes \\unity_2 \\otimes X_3 $$</p> <p>Thus, we can generalize any given 2x2 matrix $A_i$ for $N$ atoms as follows:</p> <p>$$H = \\begin{bmatrix} A_1 &amp; \\unity \\\\ \\end{bmatrix} \\begin{bmatrix}\\unity &amp; 0 \\\\ A_1 &amp; \\unity  \\end{bmatrix} \\ldots  \\begin{bmatrix}\\unity &amp; 0 \\\\ A_{N-1} &amp; \\unity  \\end{bmatrix} \\begin{bmatrix}  \\unity \\\\ A_N \\end{bmatrix} $$</p> <p>Note that $0$ is the zero 2x2 matrix, and $\\unity_i$ is the 2x2 identity matrix.</p> <p>In summary, the single operators will always appear in these specific positions in the MPO, regardless of the operator(s) applied.</p>"},{"location":"developer/ising_MPO/","title":"\u00b6","text":""},{"location":"developer/ising_MPO/#rydberg-hamiltonian","title":"Rydberg Hamiltonian\u00b6","text":"<p>There are various ways to obtain the MPO for the Rydberg Hamiltonian (lecture notes, L08 or check chapter 3, ) . However, the most efficient method so far, and the one we use in EMU-MPS, is as follows. The MPO of the Rydberg Hamiltonian can be expressed as a combination of matrices $S$, $L$, $M$, $R$, and $E$:</p> <p>$$H = S L_1 \\ldots L_a M R_b \\ldots R_1 E, $$</p> <p>where $a+b+3=N$, with $a=\\lfloor \\frac{N-2}{2} \\rfloor$, and $N$ is the number of atoms. The matrices are defined as follows:</p> <ul> <li><p>$S = \\begin{bmatrix} A_1 &amp; \\unity_1  &amp; n_1  \\end{bmatrix}$ is the first MPO matrix</p> </li> <li><p>$E = \\begin{bmatrix}  \\unity_N   \\\\ A_N  \\\\ n_N  \\end{bmatrix}$ unless $N=2$,  $E = \\begin{bmatrix}  \\unity_2   \\\\ A_2  \\\\ C_{12}n_2  \\end{bmatrix}$,  with $\\unity_i$ being the 2x2 identity matrix at atom $i$, $n_i$ is the number operator at atom $i$ and $E$ is always located at the end.</p> </li> </ul> <p>The left-term matrices $L_i$ are defined as:</p> <p>$L_i = \\ \\ \\overset{\\text{3+i} \\longrightarrow}{  \\stackrel{2+i \\downarrow}{}{ \\begin{bmatrix} \\unity_{i+1} &amp; \\mathbb{0} &amp; 0 &amp; \\mathbb{0} &amp; 0 &amp; 0 \\\\ A_{i+1} &amp; \\unity_{i+1} &amp;\\mathbb{0} &amp;\\dots&amp; 0 &amp;n_{i+1} \\\\ C_{1,i+1} n_{i+1} &amp; 0 &amp; \\unity_{i+1} &amp; 0 &amp; \\ldots &amp;0 \\\\  \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp;\\ldots &amp; 0 \\\\  C_{k,i+1} n_{i+1} &amp; 0&amp; 0 &amp;\\ldots &amp; \\unity_{i+1} &amp;0 \\end{bmatrix}}} $ with $k= 1,\\ldots, i$, and $C_{i,j}$ indicates the interaction between atom $i$ and $j$. $L_i$ matrices grow from left to right (until matrix $M$).</p> <p>The right-term matrices $R_i$ are given by:</p> <p>$ R_i = \\ \\ \\ \\ \\overset{\\text{2+i} \\longrightarrow}{ \\stackrel{3+i \\downarrow}{}{ \\begin{bmatrix} \\unity_k &amp; 0 &amp;0&amp;\\ldots &amp;  0 \\\\  A_k &amp; \\unity_k &amp; C_{k,k+1} n_k &amp;\\ldots &amp;C_{k,k+b}n_k \\\\ n_k &amp; 0 &amp; 0 &amp; \\dots&amp;0 \\\\ 0 &amp; 0 &amp;\\unity_k &amp;  \\ldots&amp;0\\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; 0 \\\\ 0 &amp; 0 &amp; \\dots &amp; \\ldots &amp; \\unity_k \\end{bmatrix} }} $ with $k=a+b+i+1$. The $R_i$ matrix grows from right to left (until matrix $M$)</p> <p>The middle matrix $M$ is defined as:</p> <p>$M = \\begin{bmatrix}\\unity_{a+2}  &amp; 0 &amp; 0 \\ldots &amp; 0 &amp;0 \\\\ A_{a+2} &amp; \\unity_{a+2} &amp; C_{a+2,a+3}n_{a+2} &amp; \\ldots &amp; C_{a+2,N}n_{a+2}\\\\ C_{1,a+2}n_{a+2} &amp; 0 &amp; C_{i,j} \\unity_{a+2} &amp; C_{i,j+1} \\unity_{a+2} &amp;\\ldots\\\\ \\vdots &amp; 0 &amp; C_{i+1,j} \\unity_{a+2} &amp; C_{i+1,j+1} \\unity_{a+2} &amp;\\ldots\\\\ C_{a+1,a+2} n_{a+2} &amp; 0 &amp;\\vdots &amp; \\ldots &amp;\\ddots \\end{bmatrix}$ where the Bloch of $C_{i,j} \\unity$ with $i&lt;a+2$ and $j&gt;a+2$ are the interaction terms for past and future interactions.</p> <p>These matrices are written in EMU-MPS, however, for this tutorial we are going to use a simplified version of them.</p>"},{"location":"developer/ising_MPO/#code-implementation","title":"Code Implementation\u00b6","text":"<p>In the following section, the examples will ilustrate how all these matrices forms the MPO.</p>"},{"location":"developer/ising_MPO/#examples","title":"Examples\u00b6","text":""},{"location":"developer/ising_MPO/#example-using-3-atoms","title":"Example using 3 atoms\u00b6","text":"<p>The MPO for 3 atoms should contain 3 matrices: $S, M,E$. We should feed the <code>general_make_H</code> function with 3 single operators terms like [A(0),A(1),A(2)] that act on each atom and the respective interaction matrix <code>inter_matri</code>.</p>"},{"location":"developer/ising_MPO/#for-testing-purposes","title":"For testing purposes\u00b6","text":"<p>We are going to create a Rydberg Hamiltonian and test it with our MPO implementation</p>"},{"location":"developer/ising_MPO/#example-for-5-atoms","title":"Example for 5 atoms\u00b6","text":"<p>The MPO for 5 should contain 5 matrices: $S, L_1, M, R_1,E$</p>"},{"location":"notebooks/","title":"Example Notebooks","text":"<p>You have found the base page for all our example notebooks. Here you find rendered web versions of the notebooks, the originals are available in the repo (see here).</p>"},{"location":"notebooks/emu_mps_notebooks/getting_started/","title":"Getting started with emu-mps","text":"<p>Let's first import all the needed libraries.</p> In\u00a0[16]: Copied! <pre>import matplotlib.pyplot as plt\nfrom emu_mps import (\n    MPS,\n    MPSConfig,\n    MPSBackend,\n    BitStrings,\n    Fidelity,\n    QubitDensity,\n)\nfrom utils_examples import afm_sequence_from_register, square_perimeter_points\n\nimport pulser\nfrom pulser.devices import AnalogDevice\nimport numpy as np\n</pre> import matplotlib.pyplot as plt from emu_mps import (     MPS,     MPSConfig,     MPSBackend,     BitStrings,     Fidelity,     QubitDensity, ) from utils_examples import afm_sequence_from_register, square_perimeter_points  import pulser from pulser.devices import AnalogDevice import numpy as np <p>To make this tutorial focused on the backend functionalities we use two auxiliary functions to quickly create the Pulser object.</p> <p>The function <code>square_perimeter_points</code> calculates the coordinates of the atoms located on the perimeter of a square. The qubits will be labeled starting from the bottom-left corner and moving counter-clockwise around the square. Please, notice that the measured bitstrings will depend on the order chosen for the atom locations.</p> <p>The function <code>afm_sequence_from_register</code> creates the pulse sequence for the AFM state for the specified register. The sequence will consist of three phases: a rise, a sweep, and a fall where the sweep time is proportional to the rise and fall times.</p> <p>We start by defining the main physical quantities needed to prepare the system. For the reader's conveninence we recall here their meaining:</p> <ul> <li><code>Omega_max</code> is the peak laser amplitude used in the pulse sequence</li> <li><code>delta_0</code> is the initial detuning used in the pulse</li> <li><code>delta_f</code> is the final detuning used in the pulse</li> <li><code>t_rise</code> is the duration of the rise phase</li> <li><code>t_fall</code> is the duraction of the fall phase</li> <li><code>sweep_factor</code> is a scale factor expressing the duration of the sweep phase in terms of <code>delta_f - delta_0</code> Note that we make the interatomic distance depend on <code>Omega_max</code> so that the interaction strength in the system is relative to the pulse parameters.</li> </ul> In\u00a0[17]: Copied! <pre>Omega_max = 2 * 2 * np.pi\ndelta_0 = -6 * Omega_max / 2\ndelta_f = 1 * Omega_max / 2\nt_rise = 500\nt_fall = 1500\nsweep_factor = 2\n\nsquare_length = 3\nR_interatomic = AnalogDevice.rydberg_blockade_radius(Omega_max / 2)\n</pre> Omega_max = 2 * 2 * np.pi delta_0 = -6 * Omega_max / 2 delta_f = 1 * Omega_max / 2 t_rise = 500 t_fall = 1500 sweep_factor = 2  square_length = 3 R_interatomic = AnalogDevice.rydberg_blockade_radius(Omega_max / 2) <p>We can now create the register consisting of 8 atom locations.</p> In\u00a0[18]: Copied! <pre>coords = R_interatomic * square_perimeter_points(square_length)\nreg = pulser.Register.from_coordinates(coords)\nreg.draw(blockade_radius=R_interatomic, draw_graph=True, draw_half_radius=True)\n</pre> coords = R_interatomic * square_perimeter_points(square_length) reg = pulser.Register.from_coordinates(coords) reg.draw(blockade_radius=R_interatomic, draw_graph=True, draw_half_radius=True) <p>And finally the pulse sequence that will realize the AFM state:</p> In\u00a0[19]: Copied! <pre>seq = afm_sequence_from_register(\n    reg, Omega_max, delta_0, delta_f, t_rise, t_fall, sweep_factor, AnalogDevice\n)\nseq.draw(\"input\")\n</pre> seq = afm_sequence_from_register(     reg, Omega_max, delta_0, delta_f, t_rise, t_fall, sweep_factor, AnalogDevice ) seq.draw(\"input\") In\u00a0[20]: Copied! <pre>dt = 100\nfinal_time = (\n    seq.get_duration() // dt * dt\n)  # final_time should be a multiple of dt, and not exceed the sequence duration\neval_times = [final_time]\n\nbasis = {\n    \"r\",\n    \"g\",\n}\n</pre> dt = 100 final_time = (     seq.get_duration() // dt * dt )  # final_time should be a multiple of dt, and not exceed the sequence duration eval_times = [final_time]  basis = {     \"r\",     \"g\", } In\u00a0[21]: Copied! <pre>sampling_times = 1000\nbitstrings = BitStrings(evaluation_times=eval_times, num_shots=sampling_times)\n</pre> sampling_times = 1000 bitstrings = BitStrings(evaluation_times=eval_times, num_shots=sampling_times) In\u00a0[22]: Copied! <pre>nqubits = len(seq.register.qubit_ids)\n\nafm_string_pure = {\"rgrgrgrg\": 1}\n\nafm_mps_state = MPS.from_state_string(\n    basis=basis, nqubits=nqubits, strings=afm_string_pure\n)\nfidelity_mps_pure = Fidelity(evaluation_times=eval_times, state=afm_mps_state)\n</pre> nqubits = len(seq.register.qubit_ids)  afm_string_pure = {\"rgrgrgrg\": 1}  afm_mps_state = MPS.from_state_string(     basis=basis, nqubits=nqubits, strings=afm_string_pure ) fidelity_mps_pure = Fidelity(evaluation_times=eval_times, state=afm_mps_state) In\u00a0[23]: Copied! <pre>density = QubitDensity(\n    evaluation_times=[x for x in range(0, final_time, dt)], basis=basis, nqubits=nqubits\n)\n</pre> density = QubitDensity(     evaluation_times=[x for x in range(0, final_time, dt)], basis=basis, nqubits=nqubits ) In\u00a0[24]: Copied! <pre>mpsconfig = MPSConfig(\n    dt=dt,\n    observables=[\n        bitstrings,\n        fidelity_mps_pure,\n        density,\n    ],\n)\n</pre> mpsconfig = MPSConfig(     dt=dt,     observables=[         bitstrings,         fidelity_mps_pure,         density,     ], ) In\u00a0[25]: Copied! <pre>sim = MPSBackend()\nresults = sim.run(seq, mpsconfig)\n</pre> sim = MPSBackend() results = sim.run(seq, mpsconfig) <pre>Will save simulation state to file \"emu_mps_save_8e085f0a-df20-11ef-a097-1d5816720d25.dat\"\n            every 600 seconds.\nTo resume: `MPSBackend().resume(\"/home/stefano/Workspace/emulators/docs/notebooks/emu_mps_notebooks/emu_mps_save_8e085f0a-df20-11ef-a097-1d5816720d25.dat\")`\nstep = 1/34, \u03c7 = 2, |\u03c8| = 0.001 MB, RSS = 11.685 MB, \u0394t = 0.099 s\nstep = 2/34, \u03c7 = 2, |\u03c8| = 0.001 MB, RSS = 11.685 MB, \u0394t = 0.108 s\nstep = 3/34, \u03c7 = 3, |\u03c8| = 0.002 MB, RSS = 11.685 MB, \u0394t = 0.115 s\nstep = 4/34, \u03c7 = 4, |\u03c8| = 0.002 MB, RSS = 11.685 MB, \u0394t = 0.140 s\nstep = 5/34, \u03c7 = 4, |\u03c8| = 0.002 MB, RSS = 11.685 MB, \u0394t = 0.137 s\nstep = 6/34, \u03c7 = 5, |\u03c8| = 0.003 MB, RSS = 11.685 MB, \u0394t = 0.140 s\nstep = 7/34, \u03c7 = 5, |\u03c8| = 0.003 MB, RSS = 11.685 MB, \u0394t = 0.146 s\nstep = 8/34, \u03c7 = 5, |\u03c8| = 0.003 MB, RSS = 11.685 MB, \u0394t = 0.149 s\nstep = 9/34, \u03c7 = 5, |\u03c8| = 0.004 MB, RSS = 11.685 MB, \u0394t = 0.154 s\nstep = 10/34, \u03c7 = 5, |\u03c8| = 0.004 MB, RSS = 11.685 MB, \u0394t = 0.146 s\nstep = 11/34, \u03c7 = 5, |\u03c8| = 0.004 MB, RSS = 11.685 MB, \u0394t = 0.145 s\nstep = 12/34, \u03c7 = 6, |\u03c8| = 0.004 MB, RSS = 11.685 MB, \u0394t = 0.136 s\nstep = 13/34, \u03c7 = 6, |\u03c8| = 0.004 MB, RSS = 11.685 MB, \u0394t = 0.135 s\nstep = 14/34, \u03c7 = 7, |\u03c8| = 0.005 MB, RSS = 11.685 MB, \u0394t = 0.133 s\nstep = 15/34, \u03c7 = 8, |\u03c8| = 0.006 MB, RSS = 11.685 MB, \u0394t = 0.126 s\nstep = 16/34, \u03c7 = 9, |\u03c8| = 0.006 MB, RSS = 11.685 MB, \u0394t = 0.123 s\nstep = 17/34, \u03c7 = 10, |\u03c8| = 0.007 MB, RSS = 11.685 MB, \u0394t = 0.121 s\nstep = 18/34, \u03c7 = 10, |\u03c8| = 0.008 MB, RSS = 11.685 MB, \u0394t = 0.134 s\nstep = 19/34, \u03c7 = 11, |\u03c8| = 0.008 MB, RSS = 11.685 MB, \u0394t = 0.126 s\nstep = 20/34, \u03c7 = 11, |\u03c8| = 0.008 MB, RSS = 11.685 MB, \u0394t = 0.121 s\nstep = 21/34, \u03c7 = 11, |\u03c8| = 0.008 MB, RSS = 11.685 MB, \u0394t = 0.120 s\nstep = 22/34, \u03c7 = 12, |\u03c8| = 0.009 MB, RSS = 11.685 MB, \u0394t = 0.116 s\nstep = 23/34, \u03c7 = 12, |\u03c8| = 0.009 MB, RSS = 11.685 MB, \u0394t = 0.111 s\nstep = 24/34, \u03c7 = 12, |\u03c8| = 0.009 MB, RSS = 11.685 MB, \u0394t = 0.111 s\nstep = 25/34, \u03c7 = 13, |\u03c8| = 0.009 MB, RSS = 11.685 MB, \u0394t = 0.112 s\nstep = 26/34, \u03c7 = 13, |\u03c8| = 0.009 MB, RSS = 11.685 MB, \u0394t = 0.111 s\nstep = 27/34, \u03c7 = 13, |\u03c8| = 0.009 MB, RSS = 11.685 MB, \u0394t = 0.113 s\nstep = 28/34, \u03c7 = 13, |\u03c8| = 0.009 MB, RSS = 11.685 MB, \u0394t = 0.115 s\nstep = 29/34, \u03c7 = 13, |\u03c8| = 0.009 MB, RSS = 11.685 MB, \u0394t = 0.108 s\nstep = 30/34, \u03c7 = 14, |\u03c8| = 0.010 MB, RSS = 11.685 MB, \u0394t = 0.104 s\nstep = 31/34, \u03c7 = 14, |\u03c8| = 0.010 MB, RSS = 11.685 MB, \u0394t = 0.106 s\nstep = 32/34, \u03c7 = 14, |\u03c8| = 0.010 MB, RSS = 11.685 MB, \u0394t = 0.129 s\nstep = 33/34, \u03c7 = 14, |\u03c8| = 0.010 MB, RSS = 11.685 MB, \u0394t = 0.104 s\nstep = 34/34, \u03c7 = 14, |\u03c8| = 0.010 MB, RSS = 11.685 MB, \u0394t = 0.573 s\n</pre> <p>During simulation time one has access to the following information:</p> <ul> <li>step: the whole sequence is discretized by dt and this generates a number of steps.</li> <li>$\\chi$ : is the bond dimension</li> <li>$|\\Psi|$: memory footprint</li> <li>RSS: max memory allocation</li> <li>$\\triangle t$: time that the step took to run</li> </ul> In\u00a0[26]: Copied! <pre>results.get_result_names()\n</pre> results.get_result_names() Out[26]: <pre>['qubit_density', 'bitstrings', 'fidelity_1']</pre> <p>Notice that the fidelity name contains an index, because it is possible to create several fidelities on different states, and the names must be unique.</p> In\u00a0[27]: Copied! <pre>bitstrings_final = results[bitstrings.name][final_time]\nresults.get_result_times(bitstrings.name)\n\nmax_val = max(bitstrings_final.values())  # max number of counts in the bitstring\nmax_string = [key for key, value in bitstrings_final.items() if value == max_val]\nprint(\n    \"The most frequent bitstring is {} which was sampled {} times\".format(\n        max_string, max_val\n    )\n)\n\nfiltered_counts = [count for count in bitstrings_final.values() if count &gt; 20]\nfiltered_bitstrings = [\n    bitstring for bitstring, count in bitstrings_final.items() if count &gt; 20\n]\nx_labels = range(len(filtered_bitstrings))\nwith plt.style.context(\"seaborn-v0_8-darkgrid\"):\n    fig, ax = plt.subplots()\n    ax.bar(x_labels, filtered_counts, color=\"teal\", alpha=0.8)\n    ax.set_xlabel(\"Bitstrings\")\n    ax.set_ylabel(\"Counts\")\n    ax.set_title(\"Histogram of Bitstring Counts (Counts &gt; 20)\")\n    ax.set_xticks(x_labels)\n    ax.set_xticklabels(filtered_bitstrings, rotation=\"vertical\")\n    ax.spines[\"top\"].set_visible(False)\n    ax.spines[\"right\"].set_visible(False)\n    plt.tight_layout()\n    plt.show()\n</pre> bitstrings_final = results[bitstrings.name][final_time] results.get_result_times(bitstrings.name)  max_val = max(bitstrings_final.values())  # max number of counts in the bitstring max_string = [key for key, value in bitstrings_final.items() if value == max_val] print(     \"The most frequent bitstring is {} which was sampled {} times\".format(         max_string, max_val     ) )  filtered_counts = [count for count in bitstrings_final.values() if count &gt; 20] filtered_bitstrings = [     bitstring for bitstring, count in bitstrings_final.items() if count &gt; 20 ] x_labels = range(len(filtered_bitstrings)) with plt.style.context(\"seaborn-v0_8-darkgrid\"):     fig, ax = plt.subplots()     ax.bar(x_labels, filtered_counts, color=\"teal\", alpha=0.8)     ax.set_xlabel(\"Bitstrings\")     ax.set_ylabel(\"Counts\")     ax.set_title(\"Histogram of Bitstring Counts (Counts &gt; 20)\")     ax.set_xticks(x_labels)     ax.set_xticklabels(filtered_bitstrings, rotation=\"vertical\")     ax.spines[\"top\"].set_visible(False)     ax.spines[\"right\"].set_visible(False)     plt.tight_layout()     plt.show() <pre>The most frequent bitstring is ['10101010'] which was sampled 243 times\n</pre> In\u00a0[28]: Copied! <pre>fidelity_pure = results[fidelity_mps_pure.name][final_time]\n\nprint(\n    \"The fidelity computed for the system final state against the pure state |rgrgrgr&gt; is {}.\\nThe probability of the system being in that sate is equal to {} \".format(\n        fidelity_pure, abs(fidelity_pure) ** 2\n    )\n)\n</pre> fidelity_pure = results[fidelity_mps_pure.name][final_time]  print(     \"The fidelity computed for the system final state against the pure state |rgrgrgr&gt; is {}.\\nThe probability of the system being in that sate is equal to {} \".format(         fidelity_pure, abs(fidelity_pure) ** 2     ) ) <pre>The fidelity computed for the system final state against the pure state |rgrgrgr&gt; is (0.48847400095986215-0.12589877707801103j).\nThe probability of the system being in that sate is equal to 0.2544573516834741 \n</pre> In\u00a0[29]: Copied! <pre>magnetization_values = np.array(list(results[density.name].values()))\nmagnetization_times = results.get_result_times(density.name)\n</pre> magnetization_values = np.array(list(results[density.name].values())) magnetization_times = results.get_result_times(density.name) In\u00a0[30]: Copied! <pre>fig, ax = plt.subplots(figsize=(8, 4), layout=\"constrained\")\n\nnum_time_points, positions = magnetization_values.shape\nx, y = np.meshgrid(np.arange(num_time_points), np.arange(1, positions + 1))\nim = plt.pcolormesh(magnetization_times, y, magnetization_values.T, shading=\"auto\")\nax.set_xlabel(\"Time [ns]\")\nax.set_ylabel(\"Qubit\")\nax.set_title(\"State Density\")\nax.set_yticks(np.arange(1, positions + 1))\ncb = fig.colorbar(im, ax=ax)\n</pre> fig, ax = plt.subplots(figsize=(8, 4), layout=\"constrained\")  num_time_points, positions = magnetization_values.shape x, y = np.meshgrid(np.arange(num_time_points), np.arange(1, positions + 1)) im = plt.pcolormesh(magnetization_times, y, magnetization_values.T, shading=\"auto\") ax.set_xlabel(\"Time [ns]\") ax.set_ylabel(\"Qubit\") ax.set_title(\"State Density\") ax.set_yticks(np.arange(1, positions + 1)) cb = fig.colorbar(im, ax=ax)"},{"location":"notebooks/emu_mps_notebooks/getting_started/#getting-started-with-emu-mps","title":"Getting started with emu-mps\u00b6","text":"<p>The aim of this tutorial is to show how emu-mps can be used as a Pulser backend to run a pulse sequence and how to extract the most important information of the system via observables such as magnetization and few more. In this tutorial we show how to emulate step-by-step an antiferromagnetic (AFM) state with a 1D ring of atoms. For more information about this specific pulse sequence, please refer to the Pulser tutorial dedicated to such experiment.</p>"},{"location":"notebooks/emu_mps_notebooks/getting_started/#pulser-and-emu-mps","title":"Pulser and emu-mps\u00b6","text":"<p>Emu-mps is a Pulser backend, designed to Emulate the dynamics of programmable arrays of neutral atoms. It works in a very intuitive way: the main method is called <code>run</code> which is used to run the simulation. This method requires as argument a Pulser sequence and a configuration file.</p> <p>Here are the steps that we will go through in the following:</p> <ol> <li>using Pulser we will create first the atomic Register</li> <li>again with Pulser we will then generate the Pulse sequence that produce the AFM state for the created register</li> <li>we create the configuration object (<code>MPSConfig</code>) and we fill it with the needed observables and time step</li> <li>we instantiate the backend class (<code>MPSBackend</code>) and run the simulation</li> <li>we inspect the results obtained</li> </ol>"},{"location":"notebooks/emu_mps_notebooks/getting_started/#register-and-sequence-creation","title":"Register and Sequence creation\u00b6","text":""},{"location":"notebooks/emu_mps_notebooks/getting_started/#using-emu-mps-as-backend","title":"Using emu-mps as backend\u00b6","text":"<p>As mentioned earlier, to run a simulation with the emu-mps backend we need to provide as input a Pulse sequence - which we have just created - and a configuration object.</p> <p>We still have to create the configuration for the emu-mps backend. This is done via an instantiation of the configuration class <code>MPSConfig</code> which contains all the observables that we wish to measure and the time step chosen for the simulation, along with various algorithm specific parameters that are explained in the documentation.</p> <p>We start by setting a bigger discretization time than the default one provided ($dt=10$) and enforcing that the times at which we compute the observables are an integer multiple of $dt$. For simplicity, we will measure the observables only at the final time of the simulation.</p> <p>We also fix the basis along which the measurements will be done. For the details regarding the conventions used we refer to the Pulser documentation.</p>"},{"location":"notebooks/emu_mps_notebooks/getting_started/#bitstring-counts","title":"BitString counts\u00b6","text":"<p>It samples at desired time steps the evolved state, returning the bitStrings in a counter.</p>"},{"location":"notebooks/emu_mps_notebooks/getting_started/#fidelity","title":"Fidelity\u00b6","text":"<p>The fidelity is computed as $\\langle \\psi_{evolved} | \\phi_{given} \\rangle$ where</p> <ul> <li>$\\psi_{evolved}$ is the system state at desired steps</li> <li>$\\phi_{given}$ is the state in which we want to project the state system.</li> </ul> <p>In this tutorial we will compute the fidelity against the dominant of the two antiferromagnetic states $\\phi_{given} = |rgrgrgrg&gt;$</p>"},{"location":"notebooks/emu_mps_notebooks/getting_started/#qubit-density","title":"Qubit Density\u00b6","text":"<p>It is computed as $\\langle \\psi_{evolved} |\\frac{(1+Z_i)}{2}|\\psi_{evolved}\\rangle$ and often informally referred to as the magnetization at each atom site.</p>"},{"location":"notebooks/emu_mps_notebooks/getting_started/#configuration-object-for-emu-mps","title":"Configuration object for emu-mps\u00b6","text":""},{"location":"notebooks/emu_mps_notebooks/getting_started/#finally-we-run","title":"Finally we run\u00b6","text":"<p>We instantiate the backend class <code>MPSBackend</code> and use its <code>run</code> method where we pass as argument the <code>sequence</code> and the <code>backend configuration</code> objects.</p>"},{"location":"notebooks/emu_mps_notebooks/getting_started/#inspecting-the-result-object","title":"Inspecting the result object\u00b6","text":"<p>In the following lines, we are going to give a brief code examples of how you can get the information from the results object</p>"},{"location":"notebooks/emu_mps_notebooks/getting_started/#bitstrings-analysis","title":"Bitstrings analysis\u00b6","text":"<p>Below, we retrieve the bistrings computed. We observe that they were indeed computed only at a single time $ns = 3400$, and we find those that were sampled the highest number of times with their relative counting.</p>"},{"location":"notebooks/emu_mps_notebooks/getting_started/#fidelity-analysis","title":"Fidelity analysis\u00b6","text":"<p>Here we compute the fidelity of the system against the two different AFM state realizations defined above.</p>"},{"location":"notebooks/emu_mps_notebooks/getting_started/#evolution-of-the-state-in-time","title":"Evolution of the state in time\u00b6","text":"<p>Here, we plot the time evolution of the magnetization of the system sites, and we observe how the system slowly reaches the AFM state.</p>"},{"location":"notebooks/emu_mps_notebooks/noise/","title":"Running noisy simulations","text":"In\u00a0[48]: Copied! <pre>import pulser\nimport emu_mps\nimport emu_base\nimport numpy as np\nimport logging #used to turn of logging in emu_mps\n</pre> import pulser import emu_mps import emu_base import numpy as np import logging #used to turn of logging in emu_mps <p>Next we define the registers. Since we will turn off interactions, the qubit positions are arbitrarily chosen based on my number of fingers.</p> In\u00a0[49]: Copied! <pre>reg = pulser.Register.from_coordinates([[0,0],[10,0]])\nreg.draw(blockade_radius=1e-10, draw_graph=True, draw_half_radius=True) #draw blockade radius as 0, since we will mask interactions in the MPSConfig\n</pre> reg = pulser.Register.from_coordinates([[0,0],[10,0]]) reg.draw(blockade_radius=1e-10, draw_graph=True, draw_half_radius=True) #draw blockade radius as 0, since we will mask interactions in the MPSConfig <p>Next we define the <code>Sequence</code>. It consists of one constant pulse on the Rydberg channel with no amplitude and detuning. The duration of the pulse is taken as <code>t=1000</code> since it makes the graphs a nice length. It also has to be a multiple of whatever <code>dt</code> we choose below, which we keep at the default <code>dt=10</code>.</p> In\u00a0[50]: Copied! <pre>seq = pulser.Sequence(reg, pulser.devices.MockDevice)\nt = 1000\npulse = pulser.Pulse.ConstantAmplitude(\n        0., pulser.waveforms.ConstantWaveform(t, 0.), 0.0\n    )\nseq.declare_channel(\"ising_global\", \"rydberg_global\")\nseq.add(pulse, \"ising_global\")\n</pre> seq = pulser.Sequence(reg, pulser.devices.MockDevice) t = 1000 pulse = pulser.Pulse.ConstantAmplitude(         0., pulser.waveforms.ConstantWaveform(t, 0.), 0.0     ) seq.declare_channel(\"ising_global\", \"rydberg_global\") seq.add(pulse, \"ising_global\") <p>We define the noise model to contain both a relaxation and a dephasing. For the system in question, dephasing has no actual influence on the dynamics since the system is always in an eigenstate of the dephasing jump operator. It's interesting to see that the correct relaxation rate still appears in the graphs though, which is why we are adding it. We're putting the rates to <code>1.</code> so that all the scaling of the graphs is in <code>t</code></p> In\u00a0[51]: Copied! <pre>noise = pulser.NoiseModel(relaxation_rate=1, dephasing_rate=1.)\n</pre> noise = pulser.NoiseModel(relaxation_rate=1, dephasing_rate=1.) <p>We'll measure the qubit density after each time step. Since we keep the default value of <code>dt=10</code> this means the measurements are at each multiple of <code>10ns</code>, as defined in <code>times</code> below.</p> In\u00a0[52]: Copied! <pre>times = np.arange(10, 1000, 10)\nbasis = (\"r\", \"g\")\nmagnetization = emu_mps.QubitDensity(evaluation_times=times, basis=basis, nqubits=2)\n</pre> times = np.arange(10, 1000, 10) basis = (\"r\", \"g\") magnetization = emu_mps.QubitDensity(evaluation_times=times, basis=basis, nqubits=2) <p>As described at the start of the notebook, we start from the <code>11</code> state.</p> In\u00a0[53]: Copied! <pre>#define initial state\ninitial_state = emu_mps.MPS.from_state_string(strings={\"rr\":1.},basis=basis, nqubits=2 )\n</pre> #define initial state initial_state = emu_mps.MPS.from_state_string(strings={\"rr\":1.},basis=basis, nqubits=2 ) <p>Now we create the <code>MPSConfig</code> and <code>MPSBackend</code> for the above.</p> In\u00a0[54]: Copied! <pre>#define config and backend\nconfig = emu_mps.MPSConfig(\n    noise_model=noise,\n    num_gpus_to_use=0, #small systems are faster on cpu\n    interaction_cutoff=1e10, #this will put all interactions to 0, regardless of spacing\n    initial_state=initial_state,\n    observables=[magnetization],\n    log_level = logging.WARN #don't print stuff for the many runs\n)\nbackend = emu_mps.MPSBackend()\n</pre> #define config and backend config = emu_mps.MPSConfig(     noise_model=noise,     num_gpus_to_use=0, #small systems are faster on cpu     interaction_cutoff=1e10, #this will put all interactions to 0, regardless of spacing     initial_state=initial_state,     observables=[magnetization],     log_level = logging.WARN #don't print stuff for the many runs ) backend = emu_mps.MPSBackend() <pre>Warning: The runs and samples_per_run values of the NoiseModel are ignored!\n</pre> <p>The way to handle results for many runs, is to store all the <code>Results</code> objects separately, and compute aggregated statistics from them afterwards.</p> In\u00a0[55]: Copied! <pre>results = []\nnruns = 500 #0.125 seconds per run on my machine\nfor _ in range(nruns):\n    results.append(backend.run(seq, config))\n</pre> results = [] nruns = 500 #0.125 seconds per run on my machine for _ in range(nruns):     results.append(backend.run(seq, config)) <p>Let's compute the average magnetization of qubit 0 over all the simulation results for each time. This can be done automatically by the <code>Results</code> class and its <code>aggregate</code> static factory method. For a given callback, the <code>Callback.default_aggregation_type</code> attribute indicates how <code>aggregate</code> processes the values from different runs. This is only a go-to setting that isn't always available, and can be overriden by the user for specific cases.</p> In\u00a0[56]: Copied! <pre>magnetization.default_aggregation_type\n</pre> magnetization.default_aggregation_type Out[56]: <pre>&lt;AggregationType.MEAN: 1&gt;</pre> <p>Here we get <code>AggregationType.MEAN</code> which indicates that qubit densities are averaged by default. To actually perform this aggregation over all results:</p> In\u00a0[57]: Copied! <pre>aggregated_results = emu_base.Results.aggregate(results)\naggregated_results[\"qubit_density\", 100][0] # average magnetization of qubit 0 at time 100ns\n</pre> aggregated_results = emu_base.Results.aggregate(results) aggregated_results[\"qubit_density\", 100][0] # average magnetization of qubit 0 at time 100ns Out[57]: <pre>0.894</pre> <p>If we were instead to be interested in the median qubit density over the <code>nruns</code>, we would have to define our own aggregation method. It would look like below. Note that magnetization values are given as list of lists, where each individual list corresponds to the magnetization values for qubits of a single run, and aggregation needs to happen over all those runs for each qubit separately.</p> In\u00a0[58]: Copied! <pre>import statistics\n\ndef median_qubit_density(qubit_density_values: list[list[float]]):\n    return [statistics.median(qubit_density[qubit_index] for qubit_density in qubit_density_values) for qubit_index in range(2)]\n\n# API for kwargs of `Results.aggregate` is `callback_name=callable_aggregator`\naggregated_median_qubit_density = emu_base.Results.aggregate(results, qubit_density=median_qubit_density)\naggregated_median_qubit_density[\"qubit_density\", 100][0] # median magnetization of qubit 0 at time 100ns\n</pre> import statistics  def median_qubit_density(qubit_density_values: list[list[float]]):     return [statistics.median(qubit_density[qubit_index] for qubit_density in qubit_density_values) for qubit_index in range(2)]  # API for kwargs of `Results.aggregate` is `callback_name=callable_aggregator` aggregated_median_qubit_density = emu_base.Results.aggregate(results, qubit_density=median_qubit_density) aggregated_median_qubit_density[\"qubit_density\", 100][0] # median magnetization of qubit 0 at time 100ns Out[58]: <pre>1.0</pre> <p>The median of the magnetization at time 100ns is 1. This can be a bit surprising, but is in fact perfectly natural given how the Monte Carlo simulation works: in a single run, qubit density is not continuous but randomly jumps from 1 to 0. We can check that e.g. by turning lists of magnetization values into Python sets with only 2 elements 0 and 1:</p> In\u00a0[\u00a0]: Copied! <pre>def set_density(qubit_density_values: list[list[float]]):\n    return [set(qubit_density[qubit_index] for qubit_density in qubit_density_values) for qubit_index in range(2)]\n\naggregated_set_qubit_density = emu_base.Results.aggregate(results, qubit_density=set_density)\naggregated_set_qubit_density[\"qubit_density\", 100][0]\n# The extra 0.999 value comes from floating-point maths, Monte-Carlo logic and state renormalization.\n</pre> def set_density(qubit_density_values: list[list[float]]):     return [set(qubit_density[qubit_index] for qubit_density in qubit_density_values) for qubit_index in range(2)]  aggregated_set_qubit_density = emu_base.Results.aggregate(results, qubit_density=set_density) aggregated_set_qubit_density[\"qubit_density\", 100][0] # The extra 0.999 value comes from floating-point maths, Monte-Carlo logic and state renormalization. Out[\u00a0]: <pre>{0.0, 0.9999999999999998, 1.0}</pre> <p>To show the convergence of that quantity as the number of runs grows, we can aggregate only the first <code>n &lt;= nruns</code> results. Here's a utility function doing that:</p> In\u00a0[60]: Copied! <pre>def densities(results, n):\n    return [density[0] for density in emu_base.Results.aggregate(results[:n])[\"qubit_density\"].values()]\n</pre> def densities(results, n):     return [density[0] for density in emu_base.Results.aggregate(results[:n])[\"qubit_density\"].values()] <p>Define the true mean of the magnetization towards which the sample statistics should converge as <code>nruns -&gt; inf</code></p> In\u00a0[61]: Copied! <pre>expected = [np.exp(-1*t/1000) for t in times]\n</pre> expected = [np.exp(-1*t/1000) for t in times] <p>Plot the magnetization. Here we see good agreement with the limit at <code>n=200</code> already, but if you're unlucky, even for <code>n=500</code> results can differ.</p> In\u00a0[62]: Copied! <pre>import matplotlib.pyplot as pl\npl.plot(times, expected, label=\"expected\")\nfor n in [100, 200, 500]:\n    pl.plot(times, densities(results, n), label=f\"n = {n}\")\npl.legend(loc=\"upper right\")\n</pre> import matplotlib.pyplot as pl pl.plot(times, expected, label=\"expected\") for n in [100, 200, 500]:     pl.plot(times, densities(results, n), label=f\"n = {n}\") pl.legend(loc=\"upper right\") Out[62]: <pre>&lt;matplotlib.legend.Legend at 0x7f037802ce80&gt;</pre>"},{"location":"notebooks/emu_mps_notebooks/noise/#running-noisy-simulations","title":"Running noisy simulations\u00b6","text":"<p>The aim of this notebook is to show how to do Monte Carlo simulations of noisy systems in emu-mps. The focus is on demonstrating the API, for information about the algorithm used, runtime and memory characteristics and potential pitfalls, please refer to the documentation.</p> <p>We will run a sequence without driving or interactions, starting from the <code>11</code> state, with dephasing and spontaneous emission noise, and show that when enough Monte Carlo runs are performed, the probability to find the first qubit in the <code>1</code> state decays with the spontaneous emission rate, as expected. It is impossible to run the simulation for a single qubit, since emu-mps does not support this edge case.</p> <p>First we import the required packages</p>"},{"location":"notebooks/emu_mps_notebooks/utils_examples/__init__/","title":"init","text":"In\u00a0[\u00a0]: Copied! <pre>from .afm_state_ring_reg import afm_sequence_from_register\nfrom .square_perimeter_reg import square_perimeter_points\n</pre> from .afm_state_ring_reg import afm_sequence_from_register from .square_perimeter_reg import square_perimeter_points In\u00a0[\u00a0]: Copied! <pre>__all__ = [\"afm_sequence_from_register\", \"square_perimeter_points\"]\n</pre> __all__ = [\"afm_sequence_from_register\", \"square_perimeter_points\"]"},{"location":"notebooks/emu_mps_notebooks/utils_examples/afm_state_ring_reg/","title":"Afm state ring reg","text":"In\u00a0[\u00a0]: Copied! <pre>import pulser\nimport numpy as np\n</pre> import pulser import numpy as np In\u00a0[\u00a0]: Copied! <pre>def afm_sequence_from_register(\n    reg: pulser.Register,\n    Omega_max: float,\n    delta_0: float,\n    delta_f: float,\n    t_rise: float,\n    t_fall: float,\n    factor_sweep: int,\n    device: pulser.devices = pulser.devices.MockDevice,\n) -&gt; pulser.Sequence:\n    \"\"\"Sequence that creates AntiFerromagnetic State (AFM) for 1d chain of atoms using pulser.\n    This function constructs a sequence of pulses to transition a system of qubits\n    distributed in a 1d chain (represented by `reg`) into an AFM state using a specified device.\n    The sequence consists of three phases: a rise, a sweep, and a fall.\n    For more information, check Pulser\n    [tutorial](https://pulser.readthedocs.io/en/stable/tutorials/afm_prep.html).\"\"\"\n\n    t_sweep = (delta_f - delta_0) / (2 * np.pi * 10) * 1000 * factor_sweep\n    rise = pulser.Pulse.ConstantDetuning(\n        pulser.waveforms.RampWaveform(t_rise, 0.0, Omega_max), delta_0, 0.0\n    )\n    sweep = pulser.Pulse.ConstantAmplitude(\n        Omega_max, pulser.waveforms.RampWaveform(t_sweep, delta_0, delta_f), 0.0\n    )\n    fall = pulser.Pulse.ConstantDetuning(\n        pulser.waveforms.RampWaveform(t_fall, Omega_max, 0.0), delta_f, 0.0\n    )\n\n    seq = pulser.Sequence(reg, device)\n    seq.declare_channel(\"ising_global\", \"rydberg_global\")\n    seq.add(rise, \"ising_global\")\n    seq.add(sweep, \"ising_global\")\n    seq.add(fall, \"ising_global\")\n\n    return seq\n</pre> def afm_sequence_from_register(     reg: pulser.Register,     Omega_max: float,     delta_0: float,     delta_f: float,     t_rise: float,     t_fall: float,     factor_sweep: int,     device: pulser.devices = pulser.devices.MockDevice, ) -&gt; pulser.Sequence:     \"\"\"Sequence that creates AntiFerromagnetic State (AFM) for 1d chain of atoms using pulser.     This function constructs a sequence of pulses to transition a system of qubits     distributed in a 1d chain (represented by `reg`) into an AFM state using a specified device.     The sequence consists of three phases: a rise, a sweep, and a fall.     For more information, check Pulser     [tutorial](https://pulser.readthedocs.io/en/stable/tutorials/afm_prep.html).\"\"\"      t_sweep = (delta_f - delta_0) / (2 * np.pi * 10) * 1000 * factor_sweep     rise = pulser.Pulse.ConstantDetuning(         pulser.waveforms.RampWaveform(t_rise, 0.0, Omega_max), delta_0, 0.0     )     sweep = pulser.Pulse.ConstantAmplitude(         Omega_max, pulser.waveforms.RampWaveform(t_sweep, delta_0, delta_f), 0.0     )     fall = pulser.Pulse.ConstantDetuning(         pulser.waveforms.RampWaveform(t_fall, Omega_max, 0.0), delta_f, 0.0     )      seq = pulser.Sequence(reg, device)     seq.declare_channel(\"ising_global\", \"rydberg_global\")     seq.add(rise, \"ising_global\")     seq.add(sweep, \"ising_global\")     seq.add(fall, \"ising_global\")      return seq"},{"location":"notebooks/emu_mps_notebooks/utils_examples/square_perimeter_reg/","title":"Square perimeter reg","text":"In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport math\n</pre> import numpy as np import math In\u00a0[\u00a0]: Copied! <pre>def square_perimeter_points(L: int) -&gt; np.ndarray:\n\n    \"\"\"\n    Calculate the coordinates of the points located on the perimeter of a square of size L.\n    The square is centered at the origin (0, 0) with sides parallel to the axes.\n    The points are ordered starting from the bottom-left corner and moving\n    counter-clockwise around the square. The order is important when measuare the bitstrings\n\n    Args:\n        L (int): The length of the side of the square. L should be a positive integer.\n\n    Returns:\n        np.ndarray: An array of shape (4*L-4, 2) containing the coordinates of the perimeter points.\n\n    Example:\n        &gt;&gt;&gt; square_perimeter_points(3)\n        array([[-1, -1],\n               [-1,  0],\n               [-1,  1],\n               [ 0,  1],\n               [ 1,  1],\n               [ 1,  0],\n               [ 1, -1],\n               [ 0, -1]])\n    \"\"\"\n    pairOrodd = L % 2\n    toGrid = int(math.floor(L / 2))\n    if pairOrodd == 0:\n        axis = list(range(-toGrid, toGrid, 1))\n    else:\n        axis = list(range(-toGrid, toGrid + 1, 1))\n    coord = []\n    for i in axis:  # from left, first column of the perimeter\n        coord.append([axis[0], i])\n\n    for i in axis[1:-1]:\n        coord.append([i, axis[-1]])\n\n    for i in reversed(axis):\n        coord.append([axis[-1], i])\n\n    for i in reversed(axis[1:-1]):\n        coord.append([i, axis[0]])\n\n    return np.array(coord)\n</pre> def square_perimeter_points(L: int) -&gt; np.ndarray:      \"\"\"     Calculate the coordinates of the points located on the perimeter of a square of size L.     The square is centered at the origin (0, 0) with sides parallel to the axes.     The points are ordered starting from the bottom-left corner and moving     counter-clockwise around the square. The order is important when measuare the bitstrings      Args:         L (int): The length of the side of the square. L should be a positive integer.      Returns:         np.ndarray: An array of shape (4*L-4, 2) containing the coordinates of the perimeter points.      Example:         &gt;&gt;&gt; square_perimeter_points(3)         array([[-1, -1],                [-1,  0],                [-1,  1],                [ 0,  1],                [ 1,  1],                [ 1,  0],                [ 1, -1],                [ 0, -1]])     \"\"\"     pairOrodd = L % 2     toGrid = int(math.floor(L / 2))     if pairOrodd == 0:         axis = list(range(-toGrid, toGrid, 1))     else:         axis = list(range(-toGrid, toGrid + 1, 1))     coord = []     for i in axis:  # from left, first column of the perimeter         coord.append([axis[0], i])      for i in axis[1:-1]:         coord.append([i, axis[-1]])      for i in reversed(axis):         coord.append([axis[-1], i])      for i in reversed(axis[1:-1]):         coord.append([i, axis[0]])      return np.array(coord)"},{"location":"notebooks/emu_sv_notebooks/getting_started_with_emu_sv/","title":"Emulation of sequences: AFM state sequence","text":"In\u00a0[11]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport pulser\n</pre> import numpy as np import matplotlib.pyplot as plt import pulser In\u00a0[12]: Copied! <pre># Setup\nL = 10\n\nOmega_max = 2.3 * 2 * np.pi\nU = Omega_max / 2.3\n\ndelta_0 = -3 * U\ndelta_f = 1 * U\n\nt_rise = 2000\nt_fall = 2000\nt_sweep = (delta_f - delta_0) / (2 * np.pi * 10) * 5000\n\n# Define a ring of atoms distanced by a blockade radius distance:\nR_interatomic = pulser.MockDevice.rydberg_blockade_radius(U)\ncoords = (\n    R_interatomic\n    / (2 * np.sin(np.pi / L))\n    * np.array(\n        [\n            (np.cos(theta * 2 * np.pi / L), np.sin(theta * 2 * np.pi / L))\n            for theta in range(L)\n        ]\n    )\n)\n\n# ring, periodic register\nreg = pulser.Register.from_coordinates(coords, prefix=\"q\")\n# or try open boundaries\n#reg = pulser.Register.rectangle(1,L,spacing=R_interatomic/1.2, prefix=\"q\")\n\nreg.draw(blockade_radius=R_interatomic, draw_half_radius=True, draw_graph=True)\n</pre> # Setup L = 10  Omega_max = 2.3 * 2 * np.pi U = Omega_max / 2.3  delta_0 = -3 * U delta_f = 1 * U  t_rise = 2000 t_fall = 2000 t_sweep = (delta_f - delta_0) / (2 * np.pi * 10) * 5000  # Define a ring of atoms distanced by a blockade radius distance: R_interatomic = pulser.MockDevice.rydberg_blockade_radius(U) coords = (     R_interatomic     / (2 * np.sin(np.pi / L))     * np.array(         [             (np.cos(theta * 2 * np.pi / L), np.sin(theta * 2 * np.pi / L))             for theta in range(L)         ]     ) )  # ring, periodic register reg = pulser.Register.from_coordinates(coords, prefix=\"q\") # or try open boundaries #reg = pulser.Register.rectangle(1,L,spacing=R_interatomic/1.2, prefix=\"q\")  reg.draw(blockade_radius=R_interatomic, draw_half_radius=True, draw_graph=True) <p>We use the drawing capabilities of the Register class to highlight the area half the blockade radius away from each atom, which makes it so that overlapping circles correspond to interacting atoms. This is further fleshed out by the graph edges drawn using the draw_graph option.</p> <p>In this register, we shall act with the following <code>pulser.Sequence</code>, which is designed to reach a state with antiferromagnetic order:</p> In\u00a0[13]: Copied! <pre>rise = pulser.Pulse.ConstantDetuning(\n    pulser.RampWaveform(t_rise, 0.0, Omega_max), delta_0, 0.0\n)\nsweep = pulser.Pulse.ConstantAmplitude(\n    Omega_max, pulser.RampWaveform(t_sweep, delta_0, delta_f), 0.0\n)\nfall = pulser.Pulse.ConstantDetuning(\n    pulser.RampWaveform(t_fall, Omega_max, 0.0), delta_f, 0.0\n)\n\nseq = pulser.Sequence(reg, pulser.MockDevice)\nseq.declare_channel(\"global\", \"rydberg_global\")\n\nseq.add(rise, \"global\")\nseq.add(sweep, \"global\")\nseq.add(fall, \"global\")\n\nseq.draw()\n</pre> rise = pulser.Pulse.ConstantDetuning(     pulser.RampWaveform(t_rise, 0.0, Omega_max), delta_0, 0.0 ) sweep = pulser.Pulse.ConstantAmplitude(     Omega_max, pulser.RampWaveform(t_sweep, delta_0, delta_f), 0.0 ) fall = pulser.Pulse.ConstantDetuning(     pulser.RampWaveform(t_fall, Omega_max, 0.0), delta_f, 0.0 )  seq = pulser.Sequence(reg, pulser.MockDevice) seq.declare_channel(\"global\", \"rydberg_global\")  seq.add(rise, \"global\") seq.add(sweep, \"global\") seq.add(fall, \"global\")  seq.draw() In\u00a0[14]: Copied! <pre>from emu_sv import SVBackend\nbknd = SVBackend()\n</pre> from emu_sv import SVBackend bknd = SVBackend() <p>Then, we need to initialize the desired observables, their evaluation times, and the basis. In this example we chose the final state and the magnetization profile.</p> In\u00a0[15]: Copied! <pre>from emu_sv import StateResult, SVConfig, QubitDensity\n\ndt = 10  # timestep in ns\nseq_duration = seq.get_duration()\n\neval_times = list(range(0, seq_duration + dt, dt))\n#magnetization  is given by -1+2*qubit_density\ndensity = QubitDensity(evaluation_times=eval_times, basis=(\"r\",\"g\"), nqubits=L)\nstate = StateResult(evaluation_times=[seq_duration])\n\nconfig = SVConfig(dt=dt, observables = [density, state], log_level=2000)\n</pre> from emu_sv import StateResult, SVConfig, QubitDensity  dt = 10  # timestep in ns seq_duration = seq.get_duration()  eval_times = list(range(0, seq_duration + dt, dt)) #magnetization  is given by -1+2*qubit_density density = QubitDensity(evaluation_times=eval_times, basis=(\"r\",\"g\"), nqubits=L) state = StateResult(evaluation_times=[seq_duration])  config = SVConfig(dt=dt, observables = [density, state], log_level=2000) <p>To run the simulation we simply use the method <code>run()</code> of the backend, passing the sequence we wish to emulate and the config file. It returns a <code>Results</code> object, which will allow the study or post-processing of the states for each time step in our simulation.</p> In\u00a0[16]: Copied! <pre>results = bknd.run(seq, config)\n</pre> results = bknd.run(seq, config) In\u00a0[17]: Copied! <pre>results[\"state\"][seq_duration].vector[:10]\n</pre> results[\"state\"][seq_duration].vector[:10] Out[17]: <pre>tensor([-2.2128e-05+0.0002j,  8.0325e-04-0.0002j,  8.0325e-04-0.0002j,\n        -7.4170e-04+0.0004j,  8.0325e-04-0.0002j, -1.6267e-03-0.0034j,\n        -7.4170e-04+0.0004j,  7.1285e-04-0.0003j,  8.0325e-04-0.0002j,\n        -2.7328e-03-0.0029j], dtype=torch.complex128)</pre> In\u00a0[18]: Copied! <pre>#getting the observables names\nresults.get_result_names()\n</pre> #getting the observables names results.get_result_names() Out[18]: <pre>['qubit_density', 'state']</pre> <p>We can sample the final state directly, using its <code>sample()</code> method from the <code>Results</code> object. For example, we sample it and discard the less frequent bitstrings:</p> In\u00a0[19]: Copied! <pre>final_state = results[\"state\"][seq_duration]\ncounts = final_state.sample(1000)\n\nlarge_counts = {k: v for k, v in counts.items() if v &gt; 5}\n\nplt.figure(figsize=(15, 4))\nplt.xticks(rotation=90, fontsize=14)\nplt.title(\"Most frequent observations\")\nplt.bar(large_counts.keys(), large_counts.values())\n</pre> final_state = results[\"state\"][seq_duration] counts = final_state.sample(1000)  large_counts = {k: v for k, v in counts.items() if v &gt; 5}  plt.figure(figsize=(15, 4)) plt.xticks(rotation=90, fontsize=14) plt.title(\"Most frequent observations\") plt.bar(large_counts.keys(), large_counts.values()) Out[19]: <pre>&lt;BarContainer object of 67 artists&gt;</pre> <p>Notice how the most frequent bitstrings correspond to the antiferromagnetic order states.</p> <p>We can also get the expectation values of operators for the states in the evolution. Since we asked for the qubit density (the Rydberg state population) in the config, we can plot its time evolution on each atom.</p> In\u00a0[20]: Copied! <pre>times = np.array(eval_times)\nmag = np.stack([-1.0+2.0*np.array(results[\"qubit_density\"][t]) for t in eval_times[1:]], axis=1)\n\nfig, axs = plt.subplots(1,2, figsize=(8,4))\n\nfor i in range(L):\n    axs[0].plot(eval_times[1:], mag[i,:])\naxs[0].set_xlabel(\"time [ns]\")\naxs[0].set_ylabel(r\"$\\langle Z_i\\rangle$\")\n\npc = axs[1].pcolor(eval_times[1:], range(L), mag)\naxs[1].set_xlabel(\"time [ns]\")\naxs[1].set_ylabel(\"qubit\")\nfig.colorbar(pc, ax=axs[1], label = r\"$\\langle Z_i\\rangle$\")\n</pre> times = np.array(eval_times) mag = np.stack([-1.0+2.0*np.array(results[\"qubit_density\"][t]) for t in eval_times[1:]], axis=1)  fig, axs = plt.subplots(1,2, figsize=(8,4))  for i in range(L):     axs[0].plot(eval_times[1:], mag[i,:]) axs[0].set_xlabel(\"time [ns]\") axs[0].set_ylabel(r\"$\\langle Z_i\\rangle$\")  pc = axs[1].pcolor(eval_times[1:], range(L), mag) axs[1].set_xlabel(\"time [ns]\") axs[1].set_ylabel(\"qubit\") fig.colorbar(pc, ax=axs[1], label = r\"$\\langle Z_i\\rangle$\") Out[20]: <pre>&lt;matplotlib.colorbar.Colorbar at 0x71bf4ac1a830&gt;</pre> <p>Notice how the local qubit density on each atom goes in the same way from 0 (which corresponds to the ground state) to 1/2. This is expected since as we saw above, the state after the evolution has antiferromagnetic-order, so at each site, there is a compensation of magnetization. The parity (even) and the boundary conditions (periodic) allow for two lowest-energy states, whose superposition is similar to that of the perfectly antiferromagnetic state: $\\left( |rgrg\\dots\\rangle+|grgr\\dots\\rangle \\right)/\\sqrt{2}$</p>"},{"location":"notebooks/emu_sv_notebooks/getting_started_with_emu_sv/#emulation-of-sequences-afm-state-sequence","title":"Emulation of sequences: AFM state sequence\u00b6","text":"<p>This example is taken from Pulser documentation.</p> <p>To illustrate the simulation of sequences, let us study a simple one-dimensional system with periodic boundary conditions (a ring of atoms):</p>"},{"location":"notebooks/emu_sv_notebooks/getting_started_with_emu_sv/#1-running-an-emulation","title":"1. Running an emulation\u00b6","text":"<p>First, we initialize the state vector backend:</p>"},{"location":"notebooks/emu_sv_notebooks/getting_started_with_emu_sv/#2-using-the-results","title":"2. Using the <code>Results</code>\u00b6","text":"<p>The <code>Results</code> object returned at the end of an emulation run, is a dictionary that contains the observables defined above, at each time step. We can access them using their name and time. The <code>Results</code> object that we created contains the final quantum state for example:</p>"},{"location":"optimatrix/","title":"Index","text":"# OptiMatrix   ![Code Coverage](https://img.shields.io/badge/Coverage-100%25-brightgreen.svg)   <p>OptiMatrix is a Python package designed to improve emu-mps simulations in terms of memory and therefore performance. It achieves this by improving qubit ordering, arranging them to closely resemble a 1D system. This approach ensures that the system is represented as a 1D structure with minimal long-range interactions.</p> <p>Effectively, it reduces the bandwidth of an interaction matrix \\(A_{ij}\\) in the Hamiltonian $$ H = \\sum A_{ij} n^z_i n^z_j + ..., $$ which perfectly fits to the description of the Rydberg or Ising-like systems.</p> <p>Methods used in the package are based on the Cuthill-McKee algorithm and can be further improved with integer linear programming techniques, see arxiv paper.</p>"},{"location":"optimatrix/#examples","title":"Examples","text":"<ul> <li>1D open chain. Randomly shuffled qubits got sorted.\\  Before \\(\\to\\) after.</li> </ul> <ul> <li>1D periodic chain. Periodic 1D nearest neighbor interacting chain transforms into open chain with next nearest neighbor interactions.\\  Before \\(\\to\\) after</li> </ul> <ul> <li>2D system. The classical zig-zag line is optimised such that the long interactions in quasi 1D are shorter.\\  Before \\(\\to\\) after</li> </ul> <p>The interaction matrix \\(A_{ij}\\) in the Hamiltonian $$ H = \\sum A_{ij} n^z_i n^z_j $$ transforms as:</p>"}]}