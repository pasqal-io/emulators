{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the Pasqal analog emulators","text":"<p>There are currently two emulators, emu-sv and emu-mps, the specific documentation for which you can access from the list above. As of this writing, the emulators are provided for Linux and macOS but will not work under Windows.</p>"},{"location":"#which-emulator-to-choose","title":"Which emulator to choose","text":"<p>Firstly, it will be useful to look at the list of supported features for emu-sv and emu-mps, since the emulators do not support exactly the same set of features. Secondly, there are in-depth benchmarks available for emu-sv and emu-mps to help determine which emulator, with which parameter settings, is most suitable for the problem you're trying to solve.</p> <p>As a general guideline, emu-sv with default precision settings is likely to be the best choice for noiseless simulations of up to 25 qubits. Shortly we will release support for noisy simulations using the Lindblad equation, and this will effectively halve the number of qubits that can be simulated. For larger qubit numbers, an emu-sv simulation is unlikely to fit on a gpu, and it is probably much slower than emu-mps, although accuracy will be better. Unless extreme accuracy is required, emu-mps is likely a better choice, and we strongly recommend you read through the documentation for that emulator to ensure you get correct results.</p>"},{"location":"#installation","title":"Installation","text":"<p>Warning: installing any emulator will update pulser-core</p>"},{"location":"#using-hatch-uv-or-any-pyproject-compatible-python-manager","title":"Using <code>hatch</code>, <code>uv</code> or any pyproject-compatible Python manager","text":"<p>To add <code>emu-sv</code> or <code>emu-mps</code>to your project, edit your <code>pyproject.toml</code> to add the line</p> <pre><code>  \"&lt;emulator&gt;\"\n</code></pre> <p>to the list of <code>dependencies</code>.</p>"},{"location":"#using-pip-or-pipx","title":"Using <code>pip</code> or <code>pipx</code>","text":"<p>To install the <code>pipy</code> package using <code>pip</code> or <code>pipx</code></p> <ol> <li>Create a <code>venv</code> if that's not done yet</li> </ol> <pre><code>$ python -m venv venv\n</code></pre> <ol> <li>Enter the venv</li> </ol> <p>If you're running Unix:</p> <pre><code>$ . venv/bin/activate\n</code></pre> <ol> <li>Install the package</li> </ol> <pre><code>$ pip install &lt;emulator&gt;\n# or\n$ pipx install &lt;emulator&gt;\n</code></pre> <p>Join us on Slack or by e-mail to give us feedback about how you plan to use the emulators or if you require specific feature-upgrades.</p>"},{"location":"#usage","title":"Usage","text":"<p>For the time being, the easiest way to learn how to use the emulators is to look at the examples in the repo, the emu-sv notebooks and the emu-mps notebooks.</p> <p>See also the emulator specific documentation for supported features, benchmarks etc.</p>"},{"location":"#getting-in-touch","title":"Getting in touch","text":"<ul> <li>Pasqal Community Portal (forums, chat, tutorials, examples, code library).</li> <li>GitHub Repository (source code, issue tracker).</li> <li>Professional Support (if you need tech support, custom licenses, a variant of this library optimized for your workload, your own QPU, remote access to a QPU, ...)</li> </ul>"},{"location":"#running-a-pulser-sequence-and-getting-results","title":"Running a Pulser sequence and getting results","text":"<p>Several example notebooks are included in this documentation. Please see the links provided under usage</p>"},{"location":"#more-info","title":"More Info","text":"<p>Many usage patterns are shared between all emulators. The computing observable page details how to compute observables (see here). The base classes enforcing the usage pattern are documented here.</p>"},{"location":"CODE_OF_CONDUCT/","title":"Code of Conduct","text":""},{"location":"CODE_OF_CONDUCT/#our-pledge","title":"Our Pledge","text":"<p>In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p>"},{"location":"CODE_OF_CONDUCT/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to creating a positive environment include:</p> <ul> <li>Using welcoming and inclusive language</li> <li>Being respectful of differing viewpoints and experiences</li> <li>Gracefully accepting constructive criticism</li> <li>Focusing on what is best for the community</li> <li>Showing empathy towards other community members</li> </ul> <p>Examples of unacceptable behavior by participants include:</p> <ul> <li>The use of sexualized language or imagery and unwelcome sexual attention or advances</li> <li>Trolling, insulting/derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or electronic address, without explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a professional setting</li> </ul>"},{"location":"CODE_OF_CONDUCT/#our-responsibilities","title":"Our Responsibilities","text":"<p>Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.</p> <p>Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.</p>"},{"location":"CODE_OF_CONDUCT/#scope","title":"Scope","text":"<p>This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.</p>"},{"location":"CONTRIBUTING/","title":"How to Contribute","text":"<p>We're grateful for your interest in contributing to our emulators! Please follow our guidelines to ensure a smooth contribution process.</p>"},{"location":"CONTRIBUTING/#reporting-an-issue-or-proposing-a-feature","title":"Reporting an Issue or Proposing a Feature","text":"<p>Your course of action will depend on your objective, but generally, you should start by creating an issue. If you've discovered a bug or have a feature you'd like to see added, feel free to create an issue on the issue tracker. Here are some steps to take:</p> <ol> <li>Quickly search the existing issues using relevant keywords to ensure your issue hasn't been addressed already.</li> <li> <p>If your issue is not listed, create a new one. Try to be as detailed and clear as possible in your description.</p> </li> <li> <p>If you're merely suggesting an improvement or reporting a bug, that's already excellent! We thank you for it. Your issue will be listed and, hopefully, addressed at some point.</p> </li> <li>However, if you're willing to be the one solving the issue, that would be even better! In such instances, you would proceed by preparing a Pull Request.</li> </ol>"},{"location":"CONTRIBUTING/#submitting-a-pull-request","title":"Submitting a Pull Request","text":"<p>We're excited that you're eager to contribute to our emulators! To contribute, create a branch on the emulators repository and once you are satisfied with your feature and all the tests pass create a Pull Request.</p> <p>Here's the process for making a contribution:</p> <p>Make a new branch via</p> <pre><code>git branch &lt;your initials&gt;/&lt;branch name&gt;\n</code></pre> <p>Next, checkout your new branch, and associate a branch to it on the GitHub server:</p> <pre><code>git checkout &lt;your initials&gt;/&lt;branch name&gt;\ngit push --set-upstream origin &lt;your initials&gt;/&lt;branch name&gt;\n</code></pre>"},{"location":"CONTRIBUTING/#setting-up-your-development-environment","title":"Setting up your development environment","text":"<p>Our repo is currently not compatible with <code>hatch</code>. The repo installs properly using <code>pip</code> directly.</p> <pre><code>pip install -e .\n</code></pre> <p>We recommend using a virtual environment. To run the automated tests, assuming you installed the repo using the above, use:</p> <pre><code>pip install -r test_requirements.txt\n\npytest\n</code></pre>"},{"location":"CONTRIBUTING/#useful-things-for-your-workflow-linting-and-testing","title":"Useful Things for your workflow: Linting and Testing","text":"<p>Use <code>pre-commit</code> hooks to make sure that the code is properly linted before pushing a new commit. Make sure that the unit tests and type checks are passing since the merge request will not be accepted if the automatic CI/CD pipeline do not pass.</p> <pre><code>pip install pre-commit\npre-commit install\npre-commit run --all-files\npytest\n</code></pre> <p>Make sure your docs build too! First, <code>pip</code> install the dependencies: <pre><code>pip install -r doc_requirements.txt\n</code></pre></p> <p>Then build the documentation:</p> <pre><code> mkdocs build --clean --strict\n</code></pre>"},{"location":"base_classes/","title":"Base Classes","text":"<p>The base classes below are defined in pulser. Different backends inherit from and specialize them if needed.</p>"},{"location":"base_classes/#backend","title":"Backend","text":"<p>               Bases: <code>ABC</code></p> <p>The backend abstract base class.</p> <p>Starts a new backend instance.</p>"},{"location":"base_classes/#pulser.backend.Backend.run","title":"<code>run()</code>  <code>abstractmethod</code>","text":"<p>Executes the sequence on the backend.</p>"},{"location":"base_classes/#pulser.backend.Backend.validate_sequence","title":"<code>validate_sequence(sequence, mimic_qpu=False)</code>  <code>staticmethod</code>","text":"<p>Validates a sequence prior to submission.</p>"},{"location":"base_classes/#emulatorbackend","title":"EmulatorBackend","text":"<p>               Bases: <code>Backend</code></p> <p>The emulator backend parent class.</p> <p>Initializes the backend.</p>"},{"location":"base_classes/#emulationconfig","title":"EmulationConfig","text":"<p>               Bases: <code>BackendConfig</code>, <code>Generic[StateType]</code></p> <p>Configures an emulation on a backend.</p> PARAMETER DESCRIPTION <code>observables</code> <p>A sequence of observables to compute at specific evaluation times. The observables without specified evaluation times will use this configuration's 'default_evaluation_times'.</p> <p> TYPE: <code>Sequence[Observable]</code> DEFAULT: <code>()</code> </p> <code>callbacks</code> <p>A general callback that is not an observable. Observables must be fed into the observables arg, since they all interact with the Results, and are subject to additional validation. Unlike observables, these are called at every emulation step.</p> <p> TYPE: <code>Sequence[Callback]</code> DEFAULT: <code>()</code> </p> <code>default_evaluation_times</code> <p>The default times at which observables are computed. Can be a sequence of unique relative times between 0 (the start of the sequence) and 1 (the end of the sequence), in ascending order. Can also be specified as \"Full\", in which case every step in the emulation will also be an evaluation time.</p> <p> TYPE: <code>Sequence[SupportsFloat] | Literal['Full']</code> DEFAULT: <code>(1.0,)</code> </p> <code>initial_state</code> <p>The initial state from which emulation starts. If specified, the state type needs to be compatible with the emulator backend. If left undefined, defaults to starting with all qudits in the ground state.</p> <p> TYPE: <code>StateType | None</code> DEFAULT: <code>None</code> </p> <code>with_modulation</code> <p>Whether to emulate the sequence with the programmed input or the expected output.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>interaction_matrix</code> <p>An optional interaction matrix to replace the interaction terms in the Hamiltonian. For an N-qudit system, must be an NxN symmetric matrix where entry (i, j) dictates the interaction coefficient between qudits i and j, ie it replaces the C_n/r_{ij}^n term.</p> <p> TYPE: <code>ArrayLike | None</code> DEFAULT: <code>None</code> </p> <code>prefer_device_noise_model</code> <p>If True, uses the noise model of the sequence's device (if the sequence's device has one), regardless of the noise model given with this configuration.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>noise_model</code> <p>An optional noise model to emulate the sequence with. Ignored if the sequence's device has default noise model and <code>prefer_device_noise_model=True</code>.</p> <p> TYPE: <code>NoiseModel</code> DEFAULT: <code>NoiseModel()</code> </p> Note <p>Additional parameters may be provided. It is up to the emulation backend that receives a configuration with extra parameters to assess whether it recognizes them and how it will use them. To know all parameters expected by an EmulatorBackend, consult its associated EmulationConfig subclass found under 'EmulatorBackend.default_config'.</p> <p>Initializes the EmulationConfig.</p>"},{"location":"base_classes/#pulser.backend.config.EmulationConfig.from_abstract_repr","title":"<code>from_abstract_repr(obj_str)</code>  <code>classmethod</code>","text":"<p>Deserialize an EmulationConfig from an abstract JSON object.</p> PARAMETER DESCRIPTION <code>obj_str</code> <p>the JSON string representing the sequence encoded in the abstract JSON format.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>EmulationConfig</code> <p>The EmulationConfig instance.</p> <p> TYPE: <code>EmulationConfig</code> </p>"},{"location":"base_classes/#pulser.backend.config.EmulationConfig.is_evaluation_time","title":"<code>is_evaluation_time(t, tol=1e-06)</code>","text":"<p>Assesses whether a relative time is an evaluation time.</p>"},{"location":"base_classes/#pulser.backend.config.EmulationConfig.is_time_in_evaluation_times","title":"<code>is_time_in_evaluation_times(t, evaluation_times, tol=1e-06)</code>  <code>staticmethod</code>","text":"<p>Checks if a time is within a collection of evaluation times.</p>"},{"location":"base_classes/#pulser.backend.config.EmulationConfig.to_abstract_repr","title":"<code>to_abstract_repr(skip_validation=False)</code>","text":"<p>Serialize <code>EmulationConfig</code> to a JSON formatted str.</p>"},{"location":"base_classes/#results","title":"Results","text":"<p>A collection of results.</p> PARAMETER DESCRIPTION <code>atom_order</code> <p>The order of the atoms/qudits in the results.</p> <p> TYPE: <code>tuple[str, ...]</code> </p> <code>total_duration</code> <p>The total duration of the sequence, in ns.</p> <p> TYPE: <code>int</code> </p>"},{"location":"base_classes/#pulser.backend.results.Results.from_abstract_repr","title":"<code>from_abstract_repr(repr)</code>  <code>classmethod</code>","text":"<p>Deserializes a Results object from json.</p> RETURNS DESCRIPTION <code>Results</code> <p>The deserialized Results object.</p>"},{"location":"base_classes/#pulser.backend.results.Results.get_result","title":"<code>get_result(observable, time)</code>","text":"<p>Get the a specific result at a given time.</p> PARAMETER DESCRIPTION <code>observable</code> <p>The observable instance used to calculate the result or its tag.</p> <p> TYPE: <code>Observable | str</code> </p> <code>time</code> <p>Relative time at which to get the result.</p> <p> TYPE: <code>float</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>The result.</p>"},{"location":"base_classes/#pulser.backend.results.Results.get_result_tags","title":"<code>get_result_tags()</code>","text":"<p>Get a list of results tags present in this object.</p>"},{"location":"base_classes/#pulser.backend.results.Results.get_result_times","title":"<code>get_result_times(observable)</code>","text":"<p>Get a list of times for which the given result has been stored.</p> PARAMETER DESCRIPTION <code>observable</code> <p>The observable instance used to calculate the result or its tag.</p> <p> TYPE: <code>Observable | str</code> </p> RETURNS DESCRIPTION <code>list[float]</code> <p>List of relative times.</p>"},{"location":"base_classes/#pulser.backend.results.Results.get_tagged_results","title":"<code>get_tagged_results()</code>","text":"<p>Gets the results for every tag.</p> RETURNS DESCRIPTION <code>dict[str, list[Any]]</code> <p>A mapping between a tag and the results associated to it,</p> <code>dict[str, list[Any]]</code> <p>at every evaluation time.</p>"},{"location":"base_classes/#pulser.backend.results.Results.to_abstract_repr","title":"<code>to_abstract_repr(skip_validation=False)</code>","text":"<p>Serializes this object into a json string.</p> <p>Numpy arrays and torch Tensors are converted into lists, and their original class is lost forever.</p> PARAMETER DESCRIPTION <code>skip_validation</code> <p>Whether to skip validating the json against the schema used for deserialization.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The json string</p>"},{"location":"base_classes/#state","title":"State","text":"<p>               Bases: <code>ABC</code>, <code>Generic[ArgScalarType, ReturnScalarType]</code></p> <p>Base class enforcing an API for quantum states.</p> <p>Each backend will implement its own type of state and the methods below.</p> <p>Initializes a State.</p>"},{"location":"base_classes/#pulser.backend.state.State.eigenstates","title":"<code>eigenstates</code>  <code>property</code>","text":"<p>The eigenstates that form a qudit's eigenbasis.</p> <p>The order of the states should match the order in a numerical (ie state vector or density matrix) representation. For example, with eigenstates (\"a\", \"b\", ...),  \"a\" will be associated to eigenvector (1, 0, ...), \"b\" to (0, 1, ...) and so on.</p>"},{"location":"base_classes/#pulser.backend.state.State.n_qudits","title":"<code>n_qudits</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>The number of qudits in the state.</p>"},{"location":"base_classes/#pulser.backend.state.State.qudit_dim","title":"<code>qudit_dim</code>  <code>property</code>","text":"<p>The dimensions (ie number of eigenstates) of a qudit.</p>"},{"location":"base_classes/#pulser.backend.state.State.from_state_amplitudes","title":"<code>from_state_amplitudes(*, eigenstates, amplitudes)</code>  <code>classmethod</code>","text":"<p>Construct the state from its basis states' amplitudes.</p> <p>Only states constructed with this method are allowed in remote backend.</p> PARAMETER DESCRIPTION <code>eigenstates</code> <p>The basis states (e.g., ('r', 'g')).</p> <p> TYPE: <code>Sequence[Eigenstate]</code> </p> <code>amplitudes</code> <p>A mapping between basis state combinations and complex amplitudes (e.g., {\"rgr\": 0.5, \"grg\": 0.5}).</p> <p> TYPE: <code>Mapping[str, ArgScalarType]</code> </p> RETURNS DESCRIPTION <code>StateType</code> <p>The state constructed from the amplitudes.</p>"},{"location":"base_classes/#pulser.backend.state.State.get_basis_state_from_index","title":"<code>get_basis_state_from_index(index)</code>","text":"<p>Generates a basis state combination from its index in the state.</p> <p>Assumes a state vector representation regardless of the actual support of the state.</p> PARAMETER DESCRIPTION <code>index</code> <p>The position of the state in a state vector.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The basis state combination for the desired index.</p>"},{"location":"base_classes/#pulser.backend.state.State.infer_one_state","title":"<code>infer_one_state()</code>","text":"<p>Infers the state measured as 1 from the eigenstates.</p> <p>Only works when the eigenstates form a known eigenbasis with a well-defined \"one state\".</p>"},{"location":"base_classes/#pulser.backend.state.State.overlap","title":"<code>overlap(other)</code>  <code>abstractmethod</code>","text":"<p>Compute the overlap between this state and another of the same type.</p> <p>Generally computes <code>Tr[AB]</code> for mixed states <code>A</code> and <code>B</code>, which corresponds to <code>|&lt;a|b&gt;|^2</code> for pure states <code>A=|a&gt;&lt;a|</code> and <code>B=|b&gt;&lt;b|</code>.</p> PARAMETER DESCRIPTION <code>other</code> <p>The other state.</p> <p> TYPE: <code>StateType</code> </p> RETURNS DESCRIPTION <code>ReturnScalarType</code> <p>The overlap between the two states.</p>"},{"location":"base_classes/#pulser.backend.state.State.sample","title":"<code>sample(*, num_shots, one_state=None, p_false_pos=0.0, p_false_neg=0.0)</code>  <code>abstractmethod</code>","text":"<p>Sample bitstrings from the state, taking into account error rates.</p> PARAMETER DESCRIPTION <code>num_shots</code> <p>How many bitstrings to sample.</p> <p> TYPE: <code>int</code> </p> <code>one_state</code> <p>The eigenstate that measures to 1. Can be left undefined if the state's eigenstates form a known eigenbasis with a defined \"one state\".</p> <p> TYPE: <code>Eigenstate | None</code> DEFAULT: <code>None</code> </p> <code>p_false_pos</code> <p>The rate at which a 0 is read as a 1.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> <code>p_false_neg</code> <p>The rate at which a 1 is read as a 0.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> RETURNS DESCRIPTION <code>Counter[str]</code> <p>The measured bitstrings, by count.</p>"},{"location":"base_classes/#staterepr","title":"StateRepr","text":"<p>               Bases: <code>State</code></p> <p>Define a backend-independent quantum state representation.</p> <p>Allows the user to define a quantum state with the usual dedicated class method <code>from_state_amplitudes</code>, which requires: - eigenstates: The basis states (e.g., ('r', 'g')). - amplitudes: A mapping between basis state combinations and     complex amplitudes (e.g., {\"rgr\": 0.5, \"grg\": 0.5}).</p> <p>The created state, supports de/serialization methods for remote backend execution.</p> <p>Example: <pre><code>eigenstates = (\"r\", \"g\")\namplitudes = {\"rgr\"=0.5, \"grg\"=0.5}\nstate = StateRepr.from_state_amplitudes(\n    eigenstates=eigenstates, amplitudes=amplitudes\n)\n</code></pre></p>"},{"location":"base_classes/#pulser.backend.state.StateRepr.n_qudits","title":"<code>n_qudits</code>  <code>property</code>","text":"<p>The number of qudits in the state.</p>"},{"location":"base_classes/#pulser.backend.state.StateRepr.overlap","title":"<code>overlap(other)</code>","text":"<p><code>overlap</code> not implemented in <code>StateRepr</code>.</p>"},{"location":"base_classes/#pulser.backend.state.StateRepr.sample","title":"<code>sample(*, num_shots, one_state=None, p_false_pos=0.0, p_false_neg=0.0)</code>","text":"<p><code>sample</code> not implemented in <code>StateRepr</code>.</p>"},{"location":"base_classes/#operator","title":"Operator","text":"<p>               Bases: <code>ABC</code>, <code>Generic[ArgScalarType, ReturnScalarType, StateType]</code></p> <p>Base class enforcing an API for quantum operator.</p> <p>Each backend will implement its own type of state and the methods below.</p> <p>Initializes an Operator.</p>"},{"location":"base_classes/#pulser.backend.operator.Operator.__add__","title":"<code>__add__(other)</code>  <code>abstractmethod</code>","text":"<p>Computes the sum of two operators.</p> PARAMETER DESCRIPTION <code>other</code> <p>The other operator.</p> <p> TYPE: <code>OperatorType</code> </p> RETURNS DESCRIPTION <code>OperatorType</code> <p>The summed operator.</p>"},{"location":"base_classes/#pulser.backend.operator.Operator.__matmul__","title":"<code>__matmul__(other)</code>  <code>abstractmethod</code>","text":"<p>Compose two operators where 'self' is applied after 'other'.</p> PARAMETER DESCRIPTION <code>other</code> <p>The operator to compose with self.</p> <p> TYPE: <code>OperatorType</code> </p> RETURNS DESCRIPTION <code>OperatorType</code> <p>The composed operator.</p>"},{"location":"base_classes/#pulser.backend.operator.Operator.__rmul__","title":"<code>__rmul__(scalar)</code>  <code>abstractmethod</code>","text":"<p>Scale the operator by a scalar factor.</p> PARAMETER DESCRIPTION <code>scalar</code> <p>The scalar factor.</p> <p> TYPE: <code>ArgScalarType</code> </p> RETURNS DESCRIPTION <code>OperatorType</code> <p>The scaled operator.</p>"},{"location":"base_classes/#pulser.backend.operator.Operator.apply_to","title":"<code>apply_to(state)</code>  <code>abstractmethod</code>","text":"<p>Apply the operator to a state.</p> PARAMETER DESCRIPTION <code>state</code> <p>The state to apply this operator to.</p> <p> TYPE: <code>StateType</code> </p> RETURNS DESCRIPTION <code>StateType</code> <p>The resulting state.</p>"},{"location":"base_classes/#pulser.backend.operator.Operator.expect","title":"<code>expect(state)</code>  <code>abstractmethod</code>","text":"<p>Compute the expectation value of self on the given state.</p> PARAMETER DESCRIPTION <code>state</code> <p>The state with which to compute.</p> <p> TYPE: <code>StateType</code> </p> RETURNS DESCRIPTION <code>ReturnScalarType</code> <p>The expectation value.</p>"},{"location":"base_classes/#pulser.backend.operator.Operator.from_operator_repr","title":"<code>from_operator_repr(*, eigenstates, n_qudits, operations)</code>  <code>classmethod</code>","text":"<p>Create an operator from the operator representation.</p> <p>Only operators constructed with this method are allowed in remote backend.</p> <p>The full operator representation (<code>FullOp</code>) is a weigthed sum of tensor operators (<code>TensorOp</code>), written as a sequence of coefficient and tensor operator pairs, ie</p> <p><code>FullOp = Sequence[tuple[ScalarType, TensorOp]]</code></p> <p>Each <code>TensorOp</code> is itself a sequence of qudit operators (<code>QuditOp</code>) applied to mutually exclusive sets of qudits (represented by their indices), ie</p> <p><code>TensorOp = Sequence[tuple[QuditOp, Collection[int]]]</code></p> <p>Qudits without an associated <code>QuditOp</code> are applied the identity operator.</p> <p>Finally, each <code>QuditOp</code> is represented as weighted sum of pre-defined single-qudit operators. It is given as a mapping between a string representation of the single-qudit operator and its respective coefficient, ie</p> <p><code>QuditOp = Mapping[str, ScalarType]</code></p> <p>By default, it identifies strings <code>\"ij\"</code> as single-qudit operators, where <code>i</code> and <code>j</code> are eigenstates that denote <code>|i&gt;&lt;j|</code>.</p> PARAMETER DESCRIPTION <code>eigenstates</code> <p>The eigenstates to use.</p> <p> TYPE: <code>Sequence[Eigenstate]</code> </p> <code>n_qudits</code> <p>How many qudits there are in the system.</p> <p> TYPE: <code>int</code> </p> <code>operations</code> <p>The full operator representation.</p> <p> TYPE: <code>FullOp[ArgScalarType]</code> </p> RETURNS DESCRIPTION <code>OperatorType</code> <p>The constructed operator.</p>"},{"location":"base_classes/#operatorrepr","title":"OperatorRepr","text":"<p>               Bases: <code>Operator</code></p> <p>Define a backend-independent quantum operator representation.</p> <p>Allows the user to define a quantum operator with the dedicated class method <code>from_operator_repr</code>, which requires: - eigenstates: The basis states (e.g., ('r', 'g')). - n_qudits: Number of qudits in the system. - operations: A sequence of tuples weight, tensor operators on each qudit,     as described in <code>from_operator_repr</code>.</p> <p>The created operator, supports de/serialization methods for remote backend execution.</p> <p>Example: <pre><code>eigenstates = (\"r\", \"g\")\nn_qudits = 4\n# define X,Y,Z\nX = {\"gr\": 1.0, \"rg\": 1.0}\nY = {\"gr\": 1.0j, \"rg\": -1.0j}\nZ = {\"rr\": 1.0, \"gg\": -1.0}\n# build for example 0.5*X0Y1X2Z3\noperations = [\n    (\n        0.5,\n        [\n            (X, [0, 2]), # acts on qudit 0 and 2\n            (Y, [1]),\n            (Z, [3]),\n        ],\n    )\n]\nop = OperatorRepr.from_operator_repr(\n    eigenstates=eigenstates,\n    n_qudits=n_qudits,\n    operations=operations\n)\n</code></pre></p>"},{"location":"base_classes/#pulser.backend.operator.OperatorRepr.__add__","title":"<code>__add__(other)</code>","text":"<p><code>__add__</code> not implemented in <code>OperatorRepr</code>.</p>"},{"location":"base_classes/#pulser.backend.operator.OperatorRepr.__matmul__","title":"<code>__matmul__(other)</code>","text":"<p><code>__matmul__</code> not implemented in <code>OperatorRepr</code>.</p>"},{"location":"base_classes/#pulser.backend.operator.OperatorRepr.__rmul__","title":"<code>__rmul__(scalar)</code>","text":"<p><code>__rmul__</code> not implemented in <code>OperatorRepr</code>.</p>"},{"location":"base_classes/#pulser.backend.operator.OperatorRepr.apply_to","title":"<code>apply_to(state)</code>","text":"<p><code>apply_to</code> not implemented in <code>OperatorRepr</code>.</p>"},{"location":"base_classes/#pulser.backend.operator.OperatorRepr.expect","title":"<code>expect(state)</code>","text":"<p><code>expect</code> not implemented in <code>OperatorRepr</code>.</p>"},{"location":"base_classes/#observable","title":"Observable","text":"<p>               Bases: <code>Callback</code></p> <p>The Observable abstract base class.</p> PARAMETER DESCRIPTION <code>evaluation_times</code> <p>The times at which to add a result to Results. If left as <code>None</code>, uses the <code>default_evaluation_times</code> of the backend's <code>EmulationConfig</code>.</p> <p> TYPE: <code>Sequence[float] | None</code> DEFAULT: <code>None</code> </p> <code>tag_suffix</code> <p>An optional suffix to append to the tag. Needed if multiple instances of the same observable are given to the same EmulationConfig.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <p>Initializes the observable.</p>"},{"location":"base_classes/#pulser.backend.observable.Observable.tag","title":"<code>tag</code>  <code>property</code>","text":"<p>Label for the observable, used to index the Results object.</p> <p>Within a Results instance, all computed observables must have different tags.</p> RETURNS DESCRIPTION <code>str</code> <p>The tag of the observable.</p>"},{"location":"base_classes/#pulser.backend.observable.Observable.__call__","title":"<code>__call__(config, t, state, hamiltonian, result)</code>","text":"<p>Specifies a call to the observable at a specific time.</p> <p>This is called after each time step performed by the emulator. By default it calls <code>apply()</code> to compute a result and put it in Results if t in self.evaluation_times. It can be overloaded to define general callbacks that don't put results in the Results object.</p> PARAMETER DESCRIPTION <code>config</code> <p>The config object passed to the backend.</p> <p> TYPE: <code>EmulationConfig</code> </p> <code>t</code> <p>The relative time as a float between 0 and 1.</p> <p> TYPE: <code>float</code> </p> <code>state</code> <p>The current state.</p> <p> TYPE: <code>State</code> </p> <code>hamiltonian</code> <p>The Hamiltonian at this time.</p> <p> TYPE: <code>Operator</code> </p> <code>result</code> <p>The Results object to store the result in.</p> <p> TYPE: <code>Results</code> </p> <code>time_tol</code> <p>Tolerance below which two time values are considered equal.</p> <p> </p>"},{"location":"base_classes/#pulser.backend.observable.Observable.apply","title":"<code>apply(*, config, state, hamiltonian)</code>  <code>abstractmethod</code>","text":"<p>Calculates the observable to store in the Results.</p> PARAMETER DESCRIPTION <code>config</code> <p>The config object passed to the backend.</p> <p> TYPE: <code>EmulationConfig</code> </p> <code>state</code> <p>The current state.</p> <p> TYPE: <code>State</code> </p> <code>hamiltonian</code> <p>The Hamiltonian at this time.</p> <p> TYPE: <code>Operator</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>The result to put in Results.</p>"},{"location":"observables/","title":"Computing observables","text":"<p>All emulators (backends) share a convenient way to define observables to be tracked during the simulation, as defined in pulser. The default available observables are listed below, together with examples for how to create them.</p> <p>Example</p> <p>How to use created observables to obtain results from an emulation is shown in the example notebooks for emu-sv and for emu-mps.</p> <p>Warning</p> <p>Please, take into account that, for performance reasons, individual emulators may overwrite the default implementation in pulser.</p>"},{"location":"observables/#stateresult","title":"StateResult","text":"<p>               Bases: <code>Observable</code></p> <p>Stores the quantum state at the evaluation times.</p> PARAMETER DESCRIPTION <code>evaluation_times</code> <p>The relative times at which to store the state. If left as <code>None</code>, uses the <code>default_evaluation_times</code> of the backend's <code>EmulationConfig</code>.</p> <p> TYPE: <code>Sequence[float] | None</code> DEFAULT: <code>None</code> </p> <code>tag_suffix</code> <p>An optional suffix to append to the tag. Needed if multiple instances of the same observable are given to the same EmulationConfig.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p>"},{"location":"observables/#pulser.backend.default_observables.StateResult.apply","title":"<code>apply(*, state, **kwargs)</code>","text":"<p>Calculates the observable to store in the Results.</p>"},{"location":"observables/#bitstrings","title":"BitStrings","text":"<p>               Bases: <code>Observable</code></p> <p>Stores bitstrings sampled from the state at the evaluation times.</p> <p>Error rates are taken from the NoiseModel passed to the backend via the EmulationConfig. The bitstrings are stored as a Counter[str].</p> PARAMETER DESCRIPTION <code>evaluation_times</code> <p>The relative times at which to sample bitstrings. If left as <code>None</code>, uses the <code>default_evaluation_times</code> of the backend's <code>EmulationConfig</code>.</p> <p> TYPE: <code>Sequence[float] | None</code> DEFAULT: <code>None</code> </p> <code>num_shots</code> <p>How many bitstrings to sample each time this observable is computed.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1000</code> </p> <code>one_state</code> <p>The eigenstate that measures to 1. Can be left undefined if the state's eigenstates form a known eigenbasis with a defined \"one state\".</p> <p> TYPE: <code>Eigenstate | None</code> DEFAULT: <code>None</code> </p> <code>tag_suffix</code> <p>An optional suffix to append to the tag. Needed if multiple instances of the same observable are given to the same EmulationConfig.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <p>Initializes the observable.</p>"},{"location":"observables/#pulser.backend.default_observables.BitStrings.apply","title":"<code>apply(*, config, state, **kwargs)</code>","text":"<p>Calculates the observable to store in the Results.</p>"},{"location":"observables/#fidelity","title":"Fidelity","text":"<p>               Bases: <code>Observable</code></p> <p>Stores the fidelity with a pure state at the evaluation times.</p> <p>The fidelity uses the overlap between the given state and the state of the system at each evaluation time. For pure states, this corresponds to <code>|&lt;\u03c8|\u03c6(t)&gt;|^2</code> for the given state <code>|\u03c8&gt;</code> and the state <code>|\u03c6(t)&gt;</code> obtained by time evolution.</p> PARAMETER DESCRIPTION <code>state</code> <p>The state <code>|\u03c8&gt;</code>. Note that this must be of an appropriate type for the backend.</p> <p> TYPE: <code>State</code> </p> <code>evaluation_times</code> <p>The relative times at which to compute the fidelity. If left as <code>None</code>, uses the <code>default_evaluation_times</code> of the backend's <code>EmulationConfig</code>.</p> <p> TYPE: <code>Sequence[float] | None</code> DEFAULT: <code>None</code> </p> <code>tag_suffix</code> <p>An optional suffix to append to the tag. Needed if multiple instances of the same observable are given to the same EmulationConfig.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <p>Initializes the observable.</p>"},{"location":"observables/#pulser.backend.default_observables.Fidelity.apply","title":"<code>apply(*, state, **kwargs)</code>","text":"<p>Calculates the observable to store in the Results.</p>"},{"location":"observables/#expectation","title":"Expectation","text":"<p>               Bases: <code>Observable</code></p> <p>Stores the expectation of the given operator on the current state.</p> PARAMETER DESCRIPTION <code>evaluation_times</code> <p>The relative times at which to compute the expectation value. If left as <code>None</code>, uses the <code>default_evaluation_times</code> of the backend's <code>EmulationConfig</code>.</p> <p> TYPE: <code>Sequence[float] | None</code> DEFAULT: <code>None</code> </p> <code>operator</code> <p>The operator to measure. Must be of the appropriate type for the backend.</p> <p> TYPE: <code>Operator</code> </p> <code>tag_suffix</code> <p>An optional suffix to append to the tag. Needed if multiple instances of the same observable are given to the same EmulationConfig.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <p>Initializes the observable.</p>"},{"location":"observables/#pulser.backend.default_observables.Expectation.apply","title":"<code>apply(*, state, **kwargs)</code>","text":"<p>Calculates the observable to store in the Results.</p>"},{"location":"observables/#correlationmatrix","title":"CorrelationMatrix","text":"<p>               Bases: <code>Observable</code></p> <p>Stores the correlation matrix for the current state.</p> <p>The correlation matrix is calculated as <code>[[&lt;\u03c6(t)|n_i n_j|\u03c6(t)&gt; for j in qubits] for i in qubits]</code> where <code>n_k = |one_state&gt;&lt;one_state|</code>.</p> PARAMETER DESCRIPTION <code>evaluation_times</code> <p>The relative times at which to compute the correlation matrix. If left as <code>None</code>, uses the <code>default_evaluation_times</code> of the backend's <code>EmulationConfig</code>.</p> <p> TYPE: <code>Sequence[float] | None</code> DEFAULT: <code>None</code> </p> <code>one_state</code> <p>The eigenstate to measure the population of in the correlation matrix. Can be left undefined if the state's eigenstates form a known eigenbasis with a defined \"one state\".</p> <p> TYPE: <code>Eigenstate | None</code> DEFAULT: <code>None</code> </p> <code>tag_suffix</code> <p>An optional suffix to append to the tag. Needed if multiple instances of the same observable are given to the same EmulationConfig.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <p>Initializes the observable.</p>"},{"location":"observables/#pulser.backend.default_observables.CorrelationMatrix.apply","title":"<code>apply(*, state, hamiltonian, **kwargs)</code>","text":"<p>Calculates the observable to store in the Results.</p>"},{"location":"observables/#qubitdensity","title":"QubitDensity","text":"<p>               Bases: <code>Observable</code></p> <p>Stores the occupation number of an eigenstate on each qudit.</p> <p>For every qudit i, calculates <code>&lt;\u03c6(t)|n_i|\u03c6(t)&gt;</code>, where <code>n_i = |one_state&gt;&lt;one_state|</code>.</p> PARAMETER DESCRIPTION <code>evaluation_times</code> <p>The relative times at which to compute the correlation matrix. If left as <code>None</code>, uses the <code>default_evaluation_times</code> of the backend's <code>EmulationConfig</code>.</p> <p> TYPE: <code>Sequence[float] | None</code> DEFAULT: <code>None</code> </p> <code>one_state</code> <p>The eigenstate to measure the population of. Can be left undefined if the state's eigenstates form a known eigenbasis with a defined \"one state\".</p> <p> TYPE: <code>Eigenstate | None</code> DEFAULT: <code>None</code> </p> <code>tag_suffix</code> <p>An optional suffix to append to the tag. Needed if multiple instances of the same observable are given to the same EmulationConfig.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <p>Initializes the observable.</p>"},{"location":"observables/#pulser.backend.default_observables.Occupation.apply","title":"<code>apply(*, state, hamiltonian, **kwargs)</code>","text":"<p>Calculates the observable to store in the Results.</p>"},{"location":"observables/#energy","title":"Energy","text":"<p>               Bases: <code>Observable</code></p> <p>Stores the energy of the system at the evaluation times.</p> <p>The energy is calculated as the expectation value of the Hamiltonian, i.e. <code>&lt;\u03c6(t)|H(t)|\u03c6(t)&gt;</code>.</p> PARAMETER DESCRIPTION <code>evaluation_times</code> <p>The relative times at which to compute the energy. If left as <code>None</code>, uses the <code>default_evaluation_times</code> of the backend's <code>EmulationConfig</code>.</p> <p> TYPE: <code>Sequence[float] | None</code> DEFAULT: <code>None</code> </p> <code>tag_suffix</code> <p>An optional suffix to append to the tag. Needed if multiple instances of the same observable are given to the same EmulationConfig.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p>"},{"location":"observables/#pulser.backend.default_observables.Energy.apply","title":"<code>apply(*, state, hamiltonian, **kwargs)</code>","text":"<p>Calculates the observable to store in the Results.</p>"},{"location":"observables/#energyvariance","title":"EnergyVariance","text":"<p>               Bases: <code>Observable</code></p> <p>Stores the variance of the Hamiltonian at the evaluation times.</p> <p>The variance of the Hamiltonian at time <code>t</code> is calculated by <code>&lt;\u03c6(t)|H(t)^2|\u03c6(t)&gt; - &lt;\u03c6(t)|H(t)|\u03c6(t)&gt;^2</code></p> PARAMETER DESCRIPTION <code>evaluation_times</code> <p>The relative times at which to compute the variance. If left as <code>None</code>, uses the <code>default_evaluation_times</code> of the backend's <code>EmulationConfig</code>.</p> <p> TYPE: <code>Sequence[float] | None</code> DEFAULT: <code>None</code> </p> <code>tag_suffix</code> <p>An optional suffix to append to the tag. Needed if multiple instances of the same observable are given to the same EmulationConfig.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p>"},{"location":"observables/#pulser.backend.default_observables.EnergyVariance.apply","title":"<code>apply(*, state, hamiltonian, **kwargs)</code>","text":"<p>Calculates the observable to store in the Results.</p>"},{"location":"observables/#secondmomentofenergy","title":"SecondMomentOfEnergy","text":"<p>               Bases: <code>Observable</code></p> <p>Stores the expectation value of <code>H(t)^2</code> at the evaluation times.</p> <p>Useful for computing the variance when averaging over many executions of the program.</p> PARAMETER DESCRIPTION <code>evaluation_times</code> <p>The relative times at which to compute the variance. If left as <code>None</code>, uses the <code>default_evaluation_times</code> of the backend's <code>EmulationConfig</code>.</p> <p> TYPE: <code>Sequence[float] | None</code> DEFAULT: <code>None</code> </p> <code>tag_suffix</code> <p>An optional suffix to append to the tag. Needed if multiple instances of the same observable are given to the same EmulationConfig.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p>"},{"location":"observables/#pulser.backend.default_observables.EnergySecondMoment.apply","title":"<code>apply(*, state, hamiltonian, **kwargs)</code>","text":"<p>Calculates the observable to store in the Results.</p>"},{"location":"observables/#defining-your-own-observable","title":"Defining your own observable","text":"<p>Most commonly desired information can be obtained using the classes documented above</p> <ul> <li>Arbitrary observables can be measured using <code>Expectation(operator, ...)</code> which requires providing a valid operator for the backend in use.</li> <li>Fidelities on arbitrary states can be computed using <code>Fidelity(state, ...)</code> which requires providing a valid state for the backend in use.</li> <li>Information about the time dependent states and Hamiltonians is available via <code>StateResult</code>, <code>Energy</code> etc.</li> </ul> <p>If additional behavior is desired (e.g. the kurtosis of the energy, or entanglement entropy), the user can subclass the <code>Observable</code> class to implement any behavior only depending on the parameters of its <code>apply</code> method (see here). Computation of the entanglement entropy, for example, cannot be done in a backend-independent manner, so it is unlikely to ever make it into the above default list. However, we do intend to define backend-specific callbacks in the future, which would belong to the API of a specific backend. Callbacks that can be implemented in a backend-independent manner can be added to the above list upon popular request.</p>"},{"location":"observables/#observables-on-remote-backend","title":"Observables on remote backend","text":"<p>In heavy simulations, the entire quantum state can easily occupy few GBs while operators, might not even fit into the available memory. For this reason, only for remote backend execution on pasaqal-cloud, and when defining a state/operator :</p> <p>Info</p> <ul> <li><code>state</code> in <code>Fidelity(state, ...)</code>, besides being a proper state for the backend, must also be defined with its <code>from_state_amplitudes()</code> class method.</li> <li><code>operator</code> in <code>Expectation(operator, ...)</code>, besides being a proper operator for the backend, must also be defined with its <code>from_operator_repr()</code> class method.</li> </ul> <p>The methods above requires the user to locally install a backend to instantiate a state or an operator class. It might not be desirable in all cases since, for example, <code>pulser-simulation</code> will install <code>qutip</code>, while <code>emu-mps/sv</code> will install <code>torch</code>. To avoid such dependency, the classes <code>StateRepr</code>, <code>OperatorRepr</code> just implements the abstract representation of such objects.</p> <p>Tip</p> <p>If the full backend is not needed, state/operator in the observable can just be defined with their abstract representation</p> <ul> <li><code>StateRepr.from_state_amplitudes()</code></li> <li><code>OperatorRepr.from_operator_repr()</code></li> </ul> <p>Moreover, the observable</p> <p>Failure</p> <p><code>StateResult</code> is not supported in pasaqal-cloud remote backend emulators.</p>"},{"location":"developer/ising_MPO/","title":"ising MPO","text":"In\u00a0[1]: Copied! <pre># import libraries\n!pip install sympy\nimport sympy as sp\nfrom sympy.physics.quantum import TensorProduct as TP\nfrom IPython.display import display, Latex\n</pre> # import libraries !pip install sympy import sympy as sp from sympy.physics.quantum import TensorProduct as TP from IPython.display import display, Latex <pre>Requirement already satisfied: sympy in /home/mauro/miniforge3/envs/pulserenv/lib/python3.12/site-packages (1.13.1)\nRequirement already satisfied: mpmath&lt;1.4,&gt;=1.1.0 in /home/mauro/miniforge3/envs/pulserenv/lib/python3.12/site-packages (from sympy) (1.3.0)\n</pre> <p>We will use Sympy for the symbolic representation of the elements in the MPO. This will help us understand which operators are applied to each site and where to place the constants that represent the interaction terms.</p> <p>In the following section, we will define functions that will assist in constructing the MPO.</p> In\u00a0[2]: Copied! <pre># creation of the identity and number operators\ndef iden_op(i:int):\n    \"\"\"Single qubit identity operator\"\"\"\n    return sp.Symbol(f\"\ud835\udfd9_{i}\", commutative=False)\n\ndef n_op(i:int):\n    \"\"\"Single qubit number operator\"\"\"\n    return sp.Symbol(f\"n_{i}\", commutative=False)\n</pre> # creation of the identity and number operators def iden_op(i:int):     \"\"\"Single qubit identity operator\"\"\"     return sp.Symbol(f\"\ud835\udfd9_{i}\", commutative=False)  def n_op(i:int):     \"\"\"Single qubit number operator\"\"\"     return sp.Symbol(f\"n_{i}\", commutative=False) In\u00a0[3]: Copied! <pre>#utility functions\ndef gate_at(d: dict[int, sp.Symbol], n: int):\n    \"\"\"Utility function for filling operators with identities.\"\"\"\n    return TP(*(\n        iden_op(i) if i not in d\n        else d[i]\n        for i in range(n)\n    ))\n\n\ndef mpo_factors_product_pairwise(a: sp.Matrix, b: sp.Matrix):\n    \"\"\"Matrix product where element-wise multiplication is the tensor product.\"\"\"\n\n    assert sp.shape(a)[1] == sp.shape(b)[0], \"Incompatible matrix dimensions\"\n\n    common_dim = sp.shape(a)[1]\n\n    res_rows = sp.shape(a)[0]\n    res_cols = sp.shape(b)[1]\n\n    res = sp.Matrix([\n            [sum(TP(a[row, k], b[k, col]).expand(tensorproduct=True) for k in range(common_dim))\n                for col in range(res_cols)\n            ]\n        for row in range(res_rows)\n    ])\n\n    if res_rows == res_cols == 1:\n        return res[0, 0]\n\n    return res\n\n\ndef mpo_factors_product(*args):\n    \"\"\"n-ary matrix product where element-wise multiplication is the tensor product.\"\"\"\n\n    assert len(args) &gt;= 2\n    if len(args) == 2:\n        return mpo_factors_product_pairwise(*args)\n    \n    return mpo_factors_product_pairwise(args[0], mpo_factors_product(*args[1:]))\n</pre> #utility functions def gate_at(d: dict[int, sp.Symbol], n: int):     \"\"\"Utility function for filling operators with identities.\"\"\"     return TP(*(         iden_op(i) if i not in d         else d[i]         for i in range(n)     ))   def mpo_factors_product_pairwise(a: sp.Matrix, b: sp.Matrix):     \"\"\"Matrix product where element-wise multiplication is the tensor product.\"\"\"      assert sp.shape(a)[1] == sp.shape(b)[0], \"Incompatible matrix dimensions\"      common_dim = sp.shape(a)[1]      res_rows = sp.shape(a)[0]     res_cols = sp.shape(b)[1]      res = sp.Matrix([             [sum(TP(a[row, k], b[k, col]).expand(tensorproduct=True) for k in range(common_dim))                 for col in range(res_cols)             ]         for row in range(res_rows)     ])      if res_rows == res_cols == 1:         return res[0, 0]      return res   def mpo_factors_product(*args):     \"\"\"n-ary matrix product where element-wise multiplication is the tensor product.\"\"\"      assert len(args) &gt;= 2     if len(args) == 2:         return mpo_factors_product_pairwise(*args)          return mpo_factors_product_pairwise(args[0], mpo_factors_product(*args[1:])) <p>$\\newcommand\\unity{1\\!\\!1}$</p> In\u00a0[4]: Copied! <pre>#implementation of S, E, Li, Rj and E\ndef _first_factor_rydberg(gate: sp.Symbol)-&gt;sp.Matrix:\n    \"\"\"\n    Creates the first Rydberg Hamiltonian factor.\n    \"\"\"\n    fac = sp.zeros(1, 3) \n    fac[0, 1] = iden_op(0)\n    fac[0, 2] = n_op(0)  # number operator\n\n    fac[0, 0] = gate\n    return fac\n\n\ndef _last_factor_rydberg(gate: sp.Symbol, scale: float | complex, num_atoms: int)-&gt;sp.Matrix:\n    \"\"\"\n    Creates the last Rydberg Hamiltonian factor.\n    \"\"\"\n    fac = sp.zeros(3, 1)\n    fac[0, 0] = iden_op(num_atoms)\n    fac[2, 0] = scale * n_op(num_atoms)\n\n    fac[1, 0] = gate\n    return fac\n\n\ndef _left_factor_rydberg(gate: sp.Symbol, scales: list[sp.Symbol], num_atom: int)-&gt;sp.Matrix:\n    \"\"\"\n    Creates the Rydberg Hamiltonian factors in the left half of the MPS, excepted the first factor.\n    \"\"\"\n    index = len(scales)\n    fac = sp.zeros(\n        index + 2,\n        index + 3,\n    )\n    for i, val in enumerate(scales):\n        fac[i + 2, 0] = val * n_op(num_atom)  # interaction with previous qubits\n    fac[1, index + 2] = n_op(num_atom)  #  interaction with next qubits\n    for i in range(index + 2):\n        fac[i, i] = iden_op(\n            num_atom\n        )  # identity matrix to carry the gates of other qubits\n\n    fac[1, 0] = gate\n    return fac\n\n\ndef _right_factor_rydberg(gate: sp.Symbol, scales: list[sp.Symbol], num_atom: int)-&gt;sp.Matrix:\n    \"\"\"\n    Creates the Rydberg Hamiltonian factors in the right half of the MPS, excepted the last factor.\n    \"\"\"\n    index = len(scales)\n    fac = sp.zeros(index + 3, index + 2)\n    for i, val in enumerate(scales):\n        fac[1, i + 2] = val * n_op(num_atom)  # XY interaction with previous qubits\n    fac[2, 0] = n_op(num_atom)  # XY interaction with next qubits\n    for i in range(2, index + 2):\n        fac[i + 1, i] = iden_op(num_atom)\n    fac[0, 0] = iden_op(\n        num_atom\n    )  # identity to carry the next gates to the previous qubits\n    fac[1, 1] = iden_op(num_atom)  # identity to carry previous gates to next qubits\n\n    fac[1, 0] = gate\n    return fac\n\n\ndef _middle_factor_rydberg(\n    gate: sp.Symbol,\n    scales_l: list[sp.Symbol],\n    scales_r: list[sp.Symbol],\n    scales_mat: list[list[sp.Symbol]],\n    num_atom:int\n)-&gt;sp.Matrix:\n    \"\"\"\n    Creates the Rydberg Hamiltonian factor at index \u230an/2\u230b of the n-qubit MPO.\n    \"\"\"\n    assert len(scales_mat) == len(scales_l)\n    assert all(len(x) == len(scales_r) for x in scales_mat)\n\n    fac = sp.zeros(\n        len(scales_l) + 2,\n        len(scales_r) + 2,\n    )\n    for i, val in enumerate(scales_r):\n        fac[1, i + 2] = val * n_op(num_atom)  # rydberg interaction with previous qubits\n    for i, val in enumerate(scales_l):\n        fac[i + 2, 0] = val * n_op(num_atom)  # rydberg interaction with next qubits\n    for i, row in enumerate(scales_mat):\n        for j, val in enumerate(row):\n            fac[i + 2, j + 2] = (\n                val * iden_op(num_atom)\n            )  # rydberg interaction of previous with next qubits\n    fac[0, 0] = iden_op(num_atom)  # identity to carry the next gates to the previous qubits\n    fac[1, 1] = iden_op(num_atom)  # identity to carry previous gates to next qubits\n\n    fac[1, 0] = gate\n    return fac\n</pre> #implementation of S, E, Li, Rj and E def _first_factor_rydberg(gate: sp.Symbol)-&gt;sp.Matrix:     \"\"\"     Creates the first Rydberg Hamiltonian factor.     \"\"\"     fac = sp.zeros(1, 3)      fac[0, 1] = iden_op(0)     fac[0, 2] = n_op(0)  # number operator      fac[0, 0] = gate     return fac   def _last_factor_rydberg(gate: sp.Symbol, scale: float | complex, num_atoms: int)-&gt;sp.Matrix:     \"\"\"     Creates the last Rydberg Hamiltonian factor.     \"\"\"     fac = sp.zeros(3, 1)     fac[0, 0] = iden_op(num_atoms)     fac[2, 0] = scale * n_op(num_atoms)      fac[1, 0] = gate     return fac   def _left_factor_rydberg(gate: sp.Symbol, scales: list[sp.Symbol], num_atom: int)-&gt;sp.Matrix:     \"\"\"     Creates the Rydberg Hamiltonian factors in the left half of the MPS, excepted the first factor.     \"\"\"     index = len(scales)     fac = sp.zeros(         index + 2,         index + 3,     )     for i, val in enumerate(scales):         fac[i + 2, 0] = val * n_op(num_atom)  # interaction with previous qubits     fac[1, index + 2] = n_op(num_atom)  #  interaction with next qubits     for i in range(index + 2):         fac[i, i] = iden_op(             num_atom         )  # identity matrix to carry the gates of other qubits      fac[1, 0] = gate     return fac   def _right_factor_rydberg(gate: sp.Symbol, scales: list[sp.Symbol], num_atom: int)-&gt;sp.Matrix:     \"\"\"     Creates the Rydberg Hamiltonian factors in the right half of the MPS, excepted the last factor.     \"\"\"     index = len(scales)     fac = sp.zeros(index + 3, index + 2)     for i, val in enumerate(scales):         fac[1, i + 2] = val * n_op(num_atom)  # XY interaction with previous qubits     fac[2, 0] = n_op(num_atom)  # XY interaction with next qubits     for i in range(2, index + 2):         fac[i + 1, i] = iden_op(num_atom)     fac[0, 0] = iden_op(         num_atom     )  # identity to carry the next gates to the previous qubits     fac[1, 1] = iden_op(num_atom)  # identity to carry previous gates to next qubits      fac[1, 0] = gate     return fac   def _middle_factor_rydberg(     gate: sp.Symbol,     scales_l: list[sp.Symbol],     scales_r: list[sp.Symbol],     scales_mat: list[list[sp.Symbol]],     num_atom:int )-&gt;sp.Matrix:     \"\"\"     Creates the Rydberg Hamiltonian factor at index \u230an/2\u230b of the n-qubit MPO.     \"\"\"     assert len(scales_mat) == len(scales_l)     assert all(len(x) == len(scales_r) for x in scales_mat)      fac = sp.zeros(         len(scales_l) + 2,         len(scales_r) + 2,     )     for i, val in enumerate(scales_r):         fac[1, i + 2] = val * n_op(num_atom)  # rydberg interaction with previous qubits     for i, val in enumerate(scales_l):         fac[i + 2, 0] = val * n_op(num_atom)  # rydberg interaction with next qubits     for i, row in enumerate(scales_mat):         for j, val in enumerate(row):             fac[i + 2, j + 2] = (                 val * iden_op(num_atom)             )  # rydberg interaction of previous with next qubits     fac[0, 0] = iden_op(num_atom)  # identity to carry the next gates to the previous qubits     fac[1, 1] = iden_op(num_atom)  # identity to carry previous gates to next qubits      fac[1, 0] = gate     return fac In\u00a0[5]: Copied! <pre>def general_make_H(interaction_matrix:list[list[sp.Symbol]],single_qubit_term:list[sp.Symbol]):\n    \"\"\"Based on make_H function of emu-mps. \n    Constains the basics functions that creates the MPO for the \n    Hamiltonian: H = SL1...La M R1 .... Rb E \"\"\"\n\n    \n    nqubits = interaction_matrix.shape[0]\n    cores = [_first_factor_rydberg(single_qubit_term[0])]\n    if nqubits &gt; 2:\n        for i in range(1, nqubits // 2):\n\n            cores.append(\n                _left_factor_rydberg(\n                    single_qubit_term[i],\n                    [interaction_matrix[j, i] for j in range(i)],\n                i)\n            )\n\n        i = nqubits // 2\n        cores.append(\n            _middle_factor_rydberg(\n                single_qubit_term[i],\n                [interaction_matrix[j, i] for j in range(i)],\n                [interaction_matrix[i, j] for j in range(i + 1, nqubits)],\n                [\n                    [interaction_matrix[k, j] for j in range(i + 1, nqubits)]\n                    for k in range(i)\n                ],\n            i)\n        )\n\n        for i in range(nqubits // 2 + 1, nqubits - 1):\n            cores.append(\n                _right_factor_rydberg(\n                    single_qubit_term[i],\n                    [interaction_matrix[i, j] for j in range(i + 1, nqubits)],\n                i)\n            )\n\n    scale = 1 # int for printing with sympy \n    if nqubits == 2:\n        scale = interaction_matrix[0, 1]\n    cores.append(\n        _last_factor_rydberg(\n            single_qubit_term[-1],\n            scale,nqubits-1\n        )\n    )\n    return cores\n</pre> def general_make_H(interaction_matrix:list[list[sp.Symbol]],single_qubit_term:list[sp.Symbol]):     \"\"\"Based on make_H function of emu-mps.      Constains the basics functions that creates the MPO for the      Hamiltonian: H = SL1...La M R1 .... Rb E \"\"\"           nqubits = interaction_matrix.shape[0]     cores = [_first_factor_rydberg(single_qubit_term[0])]     if nqubits &gt; 2:         for i in range(1, nqubits // 2):              cores.append(                 _left_factor_rydberg(                     single_qubit_term[i],                     [interaction_matrix[j, i] for j in range(i)],                 i)             )          i = nqubits // 2         cores.append(             _middle_factor_rydberg(                 single_qubit_term[i],                 [interaction_matrix[j, i] for j in range(i)],                 [interaction_matrix[i, j] for j in range(i + 1, nqubits)],                 [                     [interaction_matrix[k, j] for j in range(i + 1, nqubits)]                     for k in range(i)                 ],             i)         )          for i in range(nqubits // 2 + 1, nqubits - 1):             cores.append(                 _right_factor_rydberg(                     single_qubit_term[i],                     [interaction_matrix[i, j] for j in range(i + 1, nqubits)],                 i)             )      scale = 1 # int for printing with sympy      if nqubits == 2:         scale = interaction_matrix[0, 1]     cores.append(         _last_factor_rydberg(             single_qubit_term[-1],             scale,nqubits-1         )     )     return cores  In\u00a0[6]: Copied! <pre># declaring a symbol A for single site operator and U for the interaction coefficient\ndef A(i: int)-&gt;sp.Symbol:\n    \"\"\"Single qubit terms\"\"\"\n    return sp.Symbol(f\"A_{i}\", commutative=False)\n\ndef U(i: int, j: int)-&gt;sp.Symbol:\n    \"\"\"Interaction coefficient for i,j atoms\"\"\"\n    return sp.Symbol(f\"U_{i}{j}\")\n</pre> # declaring a symbol A for single site operator and U for the interaction coefficient def A(i: int)-&gt;sp.Symbol:     \"\"\"Single qubit terms\"\"\"     return sp.Symbol(f\"A_{i}\", commutative=False)  def U(i: int, j: int)-&gt;sp.Symbol:     \"\"\"Interaction coefficient for i,j atoms\"\"\"     return sp.Symbol(f\"U_{i}{j}\") In\u00a0[7]: Copied! <pre>#interaction matrix \ndef general_interaction_matrix(num_atoms:int)-&gt;sp.Matrix:\n    \"\"\"\" For this tutorial purpuses: generates a symmetric matrix where its elements U\u1d62\u2c7c represents the Rydberg interaction\n    between atom i and atom j.\"\"\"\n    interaction_matrix = sp.zeros(num_atoms,num_atoms)\n    for numi in range(num_atoms):\n        for numj in range(numi + 1, num_atoms):\n            interaction_matrix[numi,numj] = U(numi,numj)\n            interaction_matrix[numj, numi] = interaction_matrix[numi, numj] # for symmetry \n    return interaction_matrix\n</pre> #interaction matrix  def general_interaction_matrix(num_atoms:int)-&gt;sp.Matrix:     \"\"\"\" For this tutorial purpuses: generates a symmetric matrix where its elements U\u1d62\u2c7c represents the Rydberg interaction     between atom i and atom j.\"\"\"     interaction_matrix = sp.zeros(num_atoms,num_atoms)     for numi in range(num_atoms):         for numj in range(numi + 1, num_atoms):             interaction_matrix[numi,numj] = U(numi,numj)             interaction_matrix[numj, numi] = interaction_matrix[numi, numj] # for symmetry      return interaction_matrix In\u00a0[8]: Copied! <pre>single_terms = [A(0),A(1),A(2)]\ninter_matri = general_interaction_matrix(3)\ncores = general_make_H(inter_matri,single_terms)\nprint(\"Matrix S:\")\ndisplay(cores[0])\nprint(\"Matrix M:\")\ndisplay(cores[1])\nprint(\"Matrix E:\")\ndisplay(cores[2])\n</pre> single_terms = [A(0),A(1),A(2)] inter_matri = general_interaction_matrix(3) cores = general_make_H(inter_matri,single_terms) print(\"Matrix S:\") display(cores[0]) print(\"Matrix M:\") display(cores[1]) print(\"Matrix E:\") display(cores[2]) <pre>Matrix S:\n</pre>  $\\displaystyle \\left[\\begin{matrix}A_{0} &amp; \ud835\udfd9_{0} &amp; n_{0}\\end{matrix}\\right]$  <pre>Matrix M:\n</pre>  $\\displaystyle \\left[\\begin{matrix}\ud835\udfd9_{1} &amp; 0 &amp; 0\\\\A_{1} &amp; \ud835\udfd9_{1} &amp; U_{12} n_{1}\\\\U_{01} n_{1} &amp; 0 &amp; U_{02} \\cdot \ud835\udfd9_{1}\\end{matrix}\\right]$  <pre>Matrix E:\n</pre>  $\\displaystyle \\left[\\begin{matrix}\ud835\udfd9_{2}\\\\A_{2}\\\\n_{2}\\end{matrix}\\right]$  <p>The final Rydberg Hamiltonian with all its terms:</p> In\u00a0[9]: Copied! <pre>mpo_factors_product(*cores)\n</pre> mpo_factors_product(*cores) Out[9]:  $\\displaystyle U_{01} {n_{0}}\\otimes {{n_{1}}\\otimes {\ud835\udfd9_{2}}} + U_{02} {n_{0}}\\otimes {{\ud835\udfd9_{1}}\\otimes {n_{2}}} + U_{12} {\ud835\udfd9_{0}}\\otimes {{n_{1}}\\otimes {n_{2}}} + {A_{0}}\\otimes {{\ud835\udfd9_{1}}\\otimes {\ud835\udfd9_{2}}} + {\ud835\udfd9_{0}}\\otimes {{A_{1}}\\otimes {\ud835\udfd9_{2}}} + {\ud835\udfd9_{0}}\\otimes {{\ud835\udfd9_{1}}\\otimes {A_{2}}}$  In\u00a0[10]: Copied! <pre>def reference_hamiltonian(qubit_count: int):\n    \"\"\"For testing puruposes: creates the Rydberg Hamiltonian \"\"\"\n    result = sum(gate_at({i: A(i)}, qubit_count) for i in range(qubit_count))\n\n    result += sum(\n        U(j, i) *\n        gate_at({\n            i: n_op(i),\n            j: n_op(j)\n        }, qubit_count)\n        for i in range(qubit_count) for j in range(i)\n    )\n\n    return result\n</pre> def reference_hamiltonian(qubit_count: int):     \"\"\"For testing puruposes: creates the Rydberg Hamiltonian \"\"\"     result = sum(gate_at({i: A(i)}, qubit_count) for i in range(qubit_count))      result += sum(         U(j, i) *         gate_at({             i: n_op(i),             j: n_op(j)         }, qubit_count)         for i in range(qubit_count) for j in range(i)     )      return result In\u00a0[11]: Copied! <pre>## simple testing the MPO for 3 atoms with the reference Hamiltonian\nstr(reference_hamiltonian(3)) == str(mpo_factors_product(*cores))\n</pre> ## simple testing the MPO for 3 atoms with the reference Hamiltonian str(reference_hamiltonian(3)) == str(mpo_factors_product(*cores)) Out[11]: <pre>True</pre> In\u00a0[12]: Copied! <pre>single_terms = [A(0),A(1),A(2),A(3),A(4)]\ninter_matri = general_interaction_matrix(5)\ncores = general_make_H(inter_matri,single_terms)\nprint(\"Matrix S:\")\ndisplay(cores[0])\ndisplay(Latex(f\"Matrix $L_1$:\"))\n\ndisplay(cores[1])\nprint(\"Matrix M:\")\ndisplay(cores[2])\ndisplay(Latex(f\"Matrix $R_1$:\"))\ndisplay(cores[3])\nprint(\"Matrix E:\")\ndisplay(cores[4])\n</pre> single_terms = [A(0),A(1),A(2),A(3),A(4)] inter_matri = general_interaction_matrix(5) cores = general_make_H(inter_matri,single_terms) print(\"Matrix S:\") display(cores[0]) display(Latex(f\"Matrix $L_1$:\"))  display(cores[1]) print(\"Matrix M:\") display(cores[2]) display(Latex(f\"Matrix $R_1$:\")) display(cores[3]) print(\"Matrix E:\") display(cores[4]) <pre>Matrix S:\n</pre>  $\\displaystyle \\left[\\begin{matrix}A_{0} &amp; \ud835\udfd9_{0} &amp; n_{0}\\end{matrix}\\right]$   Matrix $L_1$:   $\\displaystyle \\left[\\begin{matrix}\ud835\udfd9_{1} &amp; 0 &amp; 0 &amp; 0\\\\A_{1} &amp; \ud835\udfd9_{1} &amp; 0 &amp; n_{1}\\\\U_{01} n_{1} &amp; 0 &amp; \ud835\udfd9_{1} &amp; 0\\end{matrix}\\right]$  <pre>Matrix M:\n</pre>  $\\displaystyle \\left[\\begin{matrix}\ud835\udfd9_{2} &amp; 0 &amp; 0 &amp; 0\\\\A_{2} &amp; \ud835\udfd9_{2} &amp; U_{23} n_{2} &amp; U_{24} n_{2}\\\\U_{02} n_{2} &amp; 0 &amp; U_{03} \\cdot \ud835\udfd9_{2} &amp; U_{04} \\cdot \ud835\udfd9_{2}\\\\U_{12} n_{2} &amp; 0 &amp; U_{13} \\cdot \ud835\udfd9_{2} &amp; U_{14} \\cdot \ud835\udfd9_{2}\\end{matrix}\\right]$   Matrix $R_1$:   $\\displaystyle \\left[\\begin{matrix}\ud835\udfd9_{3} &amp; 0 &amp; 0\\\\A_{3} &amp; \ud835\udfd9_{3} &amp; U_{34} n_{3}\\\\n_{3} &amp; 0 &amp; 0\\\\0 &amp; 0 &amp; \ud835\udfd9_{3}\\end{matrix}\\right]$  <pre>Matrix E:\n</pre>  $\\displaystyle \\left[\\begin{matrix}\ud835\udfd9_{4}\\\\A_{4}\\\\n_{4}\\end{matrix}\\right]$  <p>The final Rydberg Hamiltonian with all its terms is:</p> In\u00a0[13]: Copied! <pre>mpo_factors_product(*cores)\n</pre> mpo_factors_product(*cores) Out[13]:  $\\displaystyle U_{01} {n_{0}}\\otimes {{n_{1}}\\otimes {{\ud835\udfd9_{2}}\\otimes {{\ud835\udfd9_{3}}\\otimes {\ud835\udfd9_{4}}}}} + U_{02} {n_{0}}\\otimes {{\ud835\udfd9_{1}}\\otimes {{n_{2}}\\otimes {{\ud835\udfd9_{3}}\\otimes {\ud835\udfd9_{4}}}}} + U_{03} {n_{0}}\\otimes {{\ud835\udfd9_{1}}\\otimes {{\ud835\udfd9_{2}}\\otimes {{n_{3}}\\otimes {\ud835\udfd9_{4}}}}} + U_{04} {n_{0}}\\otimes {{\ud835\udfd9_{1}}\\otimes {{\ud835\udfd9_{2}}\\otimes {{\ud835\udfd9_{3}}\\otimes {n_{4}}}}} + U_{12} {\ud835\udfd9_{0}}\\otimes {{n_{1}}\\otimes {{n_{2}}\\otimes {{\ud835\udfd9_{3}}\\otimes {\ud835\udfd9_{4}}}}} + U_{13} {\ud835\udfd9_{0}}\\otimes {{n_{1}}\\otimes {{\ud835\udfd9_{2}}\\otimes {{n_{3}}\\otimes {\ud835\udfd9_{4}}}}} + U_{14} {\ud835\udfd9_{0}}\\otimes {{n_{1}}\\otimes {{\ud835\udfd9_{2}}\\otimes {{\ud835\udfd9_{3}}\\otimes {n_{4}}}}} + U_{23} {\ud835\udfd9_{0}}\\otimes {{\ud835\udfd9_{1}}\\otimes {{n_{2}}\\otimes {{n_{3}}\\otimes {\ud835\udfd9_{4}}}}} + U_{24} {\ud835\udfd9_{0}}\\otimes {{\ud835\udfd9_{1}}\\otimes {{n_{2}}\\otimes {{\ud835\udfd9_{3}}\\otimes {n_{4}}}}} + U_{34} {\ud835\udfd9_{0}}\\otimes {{\ud835\udfd9_{1}}\\otimes {{\ud835\udfd9_{2}}\\otimes {{n_{3}}\\otimes {n_{4}}}}} + {A_{0}}\\otimes {{\ud835\udfd9_{1}}\\otimes {{\ud835\udfd9_{2}}\\otimes {{\ud835\udfd9_{3}}\\otimes {\ud835\udfd9_{4}}}}} + {\ud835\udfd9_{0}}\\otimes {{A_{1}}\\otimes {{\ud835\udfd9_{2}}\\otimes {{\ud835\udfd9_{3}}\\otimes {\ud835\udfd9_{4}}}}} + {\ud835\udfd9_{0}}\\otimes {{\ud835\udfd9_{1}}\\otimes {{A_{2}}\\otimes {{\ud835\udfd9_{3}}\\otimes {\ud835\udfd9_{4}}}}} + {\ud835\udfd9_{0}}\\otimes {{\ud835\udfd9_{1}}\\otimes {{\ud835\udfd9_{2}}\\otimes {{A_{3}}\\otimes {\ud835\udfd9_{4}}}}} + {\ud835\udfd9_{0}}\\otimes {{\ud835\udfd9_{1}}\\otimes {{\ud835\udfd9_{2}}\\otimes {{\ud835\udfd9_{3}}\\otimes {A_{4}}}}}$  In\u00a0[14]: Copied! <pre>#simple testing the Hamiltonian generated\nstr(reference_hamiltonian(5)) == str(mpo_factors_product(*cores))\n</pre> #simple testing the Hamiltonian generated str(reference_hamiltonian(5)) == str(mpo_factors_product(*cores)) Out[14]: <pre>True</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"developer/ising_MPO/#rydberg-hamiltonian-to-mpo","title":"Rydberg Hamiltonian to MPO\u00b6","text":"<p>In this notebook, we will demostrate how to construct a Matrix Product Operator (MPO) representation of a Hamiltonian with two-body Rydberg-Rydberg interaction ,</p> <p>$$H= \\sum _{i} \\biggr(\\frac{\\Omega_i}{2} \\sigma_x - \\delta _i n_i \\biggr) + \\sum_ {i&lt;j} c_ {i,j} n_i n_j, $$</p> <p>This document is intended for developers and curious users who want to understand how to practically implement such a Hamiltonian in a Matrix Product State (MPS) emulator, like Pasqal's emu-mps.</p> <p>We will introduce the concept of operator-valued matrices, which are key to constructing the MPO. Through practical examples, we aim to clarify the procedure.</p> <p>This tutorial is organized as follows: The first section, Rydberg Hamiltonian to MPO, will cover the basic theory behind our implementation. The next section, Code Implementation, will contain the functions that generate the MPO of the Rydberg Hamiltonian. Finally, the Examples section will demonstrate the results for 3 and 5 atoms.</p>"},{"location":"developer/ising_MPO/#rydberg-hamiltonian-to-mpo","title":"Rydberg Hamiltonian to MPO\u00b6","text":"<p>We aim to represent the Rydberg Hamiltonian, given by:</p> <p>$$H= \\sum _{i} \\biggr(\\frac{\\Omega_i}{2} \\sigma_x - \\delta _i n_i \\biggr) + \\sum_ {i&lt;j} c_ {i,j} n_i n_j, $$</p> <p>where $n$ is the number operator and $\\sigma_x$ is the x pauli operator as a Matrix Product Operator or MPO</p> <p>As can be seen, we have set the phase to zero ($\\phi=0$), which cancels out the $\\sigma_y$ term in the original Hamiltonian. However, this will not affect the resulting MPO because, as we will see later, all single-gate terms will be located in a specific position within the MPO.</p> <p>To facilitate the calculations, let us express a rank-4 tensor</p> <p>as operator-valued matrices, given by  $\\begin{bmatrix}  B_{0,0} &amp; B_{0,1} &amp; \\ldots \\\\  B_{1,0} &amp; B_{1,1} &amp; \\ldots \\\\  \\ldots &amp; \\ldots &amp;\\ddots \\end{bmatrix}$</p> <p>where each $B_{i,j}$ has indices $k,l$. Additionally, we define the multiplication of the inner matrices as the Kronecker product $\\otimes$. Then, an MPO consists of a series of matrices, and performing matrix multiplication is equivalent to contracting the bonds and reshaping all physical input and output indices into a single \u201cfat\u201d index for input and output, respectively.</p>"},{"location":"developer/ising_MPO/#single-terms","title":"Single terms\u00b6","text":"<p>The sum of single-qubit terms such as: $$ A_i = \\left( \\frac{\\Omega_i}{2} \\sigma_i^x - \\delta_i n_i \\right), $$</p> <p>we can implement them with a bond dimension of 2.</p> <p>For each qubit $i$, the Hamiltonian term $A_i$\u200b is represented as a $2\\times 2$ matrix in the MPO at position $i$. Thus, the MPO takes the following structure: \\begin{bmatrix}\\unity_i &amp; 0 \\\\ A_i &amp; \\unity _i \\end{bmatrix} The overall Hamiltonian MPO for multiple qubits is constructed by taking the matrix product of these individual MPOs</p> <p>For example, let\u2019s create the MPOs for the Rydberg Hamiltonian of 3 atoms, where only single operators $A_i = X_i$ are applied to each atom:</p> <p>$$H = \\begin{bmatrix} X_1 &amp; \\unity_1 \\\\ \\end{bmatrix} \\begin{bmatrix}\\unity_2 &amp; 0 \\\\ X_2 &amp; \\unity  \\end{bmatrix}  \\begin{bmatrix}  \\unity_3 \\\\ X_3 \\end{bmatrix} $$</p> <p>$$H = \\begin{bmatrix} X_1 \\otimes  \\unity_2 + \\unity_1  \\otimes X_1 &amp; \\unity_2  \\end{bmatrix}  \\begin{bmatrix}  \\unity_3 \\\\ X_3 \\end{bmatrix}$$</p> <p>$$H = X_1 \\otimes \\unity_2 \\otimes \\unity_3 + \\unity_1 \\otimes X_2 \\otimes \\unity_3 +\\unity_1 \\otimes \\unity_2 \\otimes X_3 $$</p> <p>Thus, we can generalize any given 2x2 matrix $A_i$ for $N$ atoms as follows:</p> <p>$$H = \\begin{bmatrix} A_1 &amp; \\unity \\\\ \\end{bmatrix} \\begin{bmatrix}\\unity &amp; 0 \\\\ A_1 &amp; \\unity  \\end{bmatrix} \\ldots  \\begin{bmatrix}\\unity &amp; 0 \\\\ A_{N-1} &amp; \\unity  \\end{bmatrix} \\begin{bmatrix}  \\unity \\\\ A_N \\end{bmatrix} $$</p> <p>Note that $0$ is the zero 2x2 matrix, and $\\unity_i$ is the 2x2 identity matrix.</p> <p>In summary, the single operators will always appear in these specific positions in the MPO, regardless of the operator(s) applied.</p>"},{"location":"developer/ising_MPO/","title":"\u00b6","text":""},{"location":"developer/ising_MPO/#rydberg-hamiltonian","title":"Rydberg Hamiltonian\u00b6","text":"<p>There are various ways to obtain the MPO for the Rydberg Hamiltonian (lecture notes, L08 or check chapter 3, ) . However, the most efficient method so far, and the one we use in EMU-MPS, is as follows. The MPO of the Rydberg Hamiltonian can be expressed as a combination of matrices $S$, $L$, $M$, $R$, and $E$:</p> <p>$$H = S L_1 \\ldots L_a M R_b \\ldots R_1 E, $$</p> <p>where $a+b+3=N$, with $a=\\lfloor \\frac{N-2}{2} \\rfloor$, and $N$ is the number of atoms. The matrices are defined as follows:</p> <ul> <li><p>$S = \\begin{bmatrix} A_1 &amp; \\unity_1  &amp; n_1  \\end{bmatrix}$ is the first MPO matrix</p> </li> <li><p>$E = \\begin{bmatrix}  \\unity_N   \\\\ A_N  \\\\ n_N  \\end{bmatrix}$ unless $N=2$,  $E = \\begin{bmatrix}  \\unity_2   \\\\ A_2  \\\\ C_{12}n_2  \\end{bmatrix}$,  with $\\unity_i$ being the 2x2 identity matrix at atom $i$, $n_i$ is the number operator at atom $i$ and $E$ is always located at the end.</p> </li> </ul> <p>The left-term matrices $L_i$ are defined as:</p> <p>$L_i = \\ \\ \\overset{\\text{3+i} \\longrightarrow}{  \\stackrel{2+i \\downarrow}{}{ \\begin{bmatrix} \\unity_{i+1} &amp; \\mathbb{0} &amp; 0 &amp; \\mathbb{0} &amp; 0 &amp; 0 \\\\ A_{i+1} &amp; \\unity_{i+1} &amp;\\mathbb{0} &amp;\\dots&amp; 0 &amp;n_{i+1} \\\\ C_{1,i+1} n_{i+1} &amp; 0 &amp; \\unity_{i+1} &amp; 0 &amp; \\ldots &amp;0 \\\\  \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp;\\ldots &amp; 0 \\\\  C_{k,i+1} n_{i+1} &amp; 0&amp; 0 &amp;\\ldots &amp; \\unity_{i+1} &amp;0 \\end{bmatrix}}} $ with $k= 1,\\ldots, i$, and $C_{i,j}$ indicates the interaction between atom $i$ and $j$. $L_i$ matrices grow from left to right (until matrix $M$).</p> <p>The right-term matrices $R_i$ are given by:</p> <p>$ R_i = \\ \\ \\ \\ \\overset{\\text{2+i} \\longrightarrow}{ \\stackrel{3+i \\downarrow}{}{ \\begin{bmatrix} \\unity_k &amp; 0 &amp;0&amp;\\ldots &amp;  0 \\\\  A_k &amp; \\unity_k &amp; C_{k,k+1} n_k &amp;\\ldots &amp;C_{k,k+b}n_k \\\\ n_k &amp; 0 &amp; 0 &amp; \\dots&amp;0 \\\\ 0 &amp; 0 &amp;\\unity_k &amp;  \\ldots&amp;0\\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; 0 \\\\ 0 &amp; 0 &amp; \\dots &amp; \\ldots &amp; \\unity_k \\end{bmatrix} }} $ with $k=a+b+i+1$. The $R_i$ matrix grows from right to left (until matrix $M$)</p> <p>The middle matrix $M$ is defined as:</p> <p>$M = \\begin{bmatrix}\\unity_{a+2}  &amp; 0 &amp; 0 \\ldots &amp; 0 &amp;0 \\\\ A_{a+2} &amp; \\unity_{a+2} &amp; C_{a+2,a+3}n_{a+2} &amp; \\ldots &amp; C_{a+2,N}n_{a+2}\\\\ C_{1,a+2}n_{a+2} &amp; 0 &amp; C_{i,j} \\unity_{a+2} &amp; C_{i,j+1} \\unity_{a+2} &amp;\\ldots\\\\ \\vdots &amp; 0 &amp; C_{i+1,j} \\unity_{a+2} &amp; C_{i+1,j+1} \\unity_{a+2} &amp;\\ldots\\\\ C_{a+1,a+2} n_{a+2} &amp; 0 &amp;\\vdots &amp; \\ldots &amp;\\ddots \\end{bmatrix}$ where the Bloch of $C_{i,j} \\unity$ with $i&lt;a+2$ and $j&gt;a+2$ are the interaction terms for past and future interactions.</p> <p>These matrices are written in EMU-MPS, however, for this tutorial we are going to use a simplified version of them.</p>"},{"location":"developer/ising_MPO/#code-implementation","title":"Code Implementation\u00b6","text":"<p>In the following section, the examples will ilustrate how all these matrices forms the MPO.</p>"},{"location":"developer/ising_MPO/#examples","title":"Examples\u00b6","text":""},{"location":"developer/ising_MPO/#example-using-3-atoms","title":"Example using 3 atoms\u00b6","text":"<p>The MPO for 3 atoms should contain 3 matrices: $S, M,E$. We should feed the <code>general_make_H</code> function with 3 single operators terms like [A(0),A(1),A(2)] that act on each atom and the respective interaction matrix <code>inter_matri</code>.</p>"},{"location":"developer/ising_MPO/#for-testing-purposes","title":"For testing purposes\u00b6","text":"<p>We are going to create a Rydberg Hamiltonian and test it with our MPO implementation</p>"},{"location":"developer/ising_MPO/#example-for-5-atoms","title":"Example for 5 atoms\u00b6","text":"<p>The MPO for 5 should contain 5 matrices: $S, L_1, M, R_1,E$</p>"},{"location":"developer/optimatrix/","title":"Index","text":"# OptiMatrix   ![Code Coverage](https://img.shields.io/badge/Coverage-100%25-brightgreen.svg)   <p>OptiMatrix is a Python package designed to improve emu-mps simulations in terms of memory and therefore performance. It achieves this by improving qubit ordering, arranging them to closely resemble a 1D system. This approach ensures that the system is represented as a 1D structure with minimal long-range interactions.</p> <p>Effectively, it reduces the bandwidth of an interaction matrix \\(A_{ij}\\) in the Hamiltonian $$ H = \\sum A_{ij} n^z_i n^z_j + ..., $$ which perfectly fits to the description of the Rydberg or Ising-like systems.</p> <p>Methods used in the package are based on the Cuthill-McKee algorithm and can be further improved with integer linear programming techniques, see arxiv paper.</p>"},{"location":"developer/optimatrix/#examples","title":"Examples","text":"<ul> <li>1D open chain. Randomly shuffled qubits got sorted.\\  Before \\(\\to\\) after.</li> </ul> <ul> <li>1D periodic chain. Periodic 1D nearest neighbor interacting chain transforms into open chain with next nearest neighbor interactions.\\  Before \\(\\to\\) after</li> </ul> <ul> <li>2D system. The classical zig-zag line is optimised such that the long interactions in quasi 1D are shorter.\\  Before \\(\\to\\) after</li> </ul> <p>The interaction matrix \\(A_{ij}\\) in the Hamiltonian $$ H = \\sum A_{ij} n^z_i n^z_j $$ transforms as:</p>"},{"location":"emu_mps/","title":"Welcome to emu-mps","text":"<p>You have found the documentation for emu-mps. The emulator emu-mps is a backend for the Pulser low-level Quantum Programming toolkit that lets you run Quantum algorithms on a simulated device, using GPU acceleration if available. More in depth, emu-mps is designed to emulate the dynamics of programmable arrays of neutral atoms, with matrix product states (mps). While benchmarking is incomplete as of this writing, early results suggest that this design makes emu-mps faster and more memory-efficient than previous generations of quantum emulators at running simulations with large numbers of qubits.</p>"},{"location":"emu_mps/#supported-features","title":"Supported features","text":"<p>The following features are currently supported:</p> <ul> <li>All Pulser sequences that use only the rydberg channel</li> <li>MPS and MPO can be constructed using the abstract Pulser format.</li> <li>The following noise types:<ul> <li>SPAM</li> <li>Monte Carlo quantum jumps</li> <li>A Gaussian laser waist for the global pulse channels.</li> </ul> </li> <li>The following basis states in a sequence:<ul> <li>ground-rydberg</li> <li>XY</li> </ul> </li> <li>The following properties from a Pulser Sequence are also correctly applied:<ul> <li>hardware modulation</li> <li>SLM mask</li> <li>A complex phase for the omega parameter</li> </ul> </li> <li>Customizable output, with the folowing inbuilt options:<ul> <li>The quantum state in MPS format</li> <li>Bitstrings</li> <li>The fidelity with respect to a given state</li> <li>The expectation of a given operator</li> <li>The qubit density (magnetization)</li> <li>The correlation matrix</li> <li>The mean, second moment and variance of the energy</li> </ul> </li> <li>Specification of<ul> <li>initial state</li> <li>various precision parameters</li> <li>whether to run on cpu or gpu(s)</li> <li>the \\(U_{ij}\\) coefficients from here</li> <li>A cutoff below which \\(U_{ij}\\) are set to 0 (this makes the computation more memory efficient)</li> </ul> </li> </ul>"},{"location":"emu_mps/#planned-features","title":"Planned features","text":"<ul> <li>Parallel TDVP on multiple GPUs</li> <li>More noise:<ul> <li>the currently unsupported noises in the Pulser <code>NoiseModel</code></li> </ul> </li> <li>Differentiability</li> </ul>"},{"location":"emu_mps/#more-info","title":"More Info","text":"<p>Please see the API specification for a list of available config options (see here). Those configuration options relating to the mathematical functioning of the backend are explained in more detail in the config page (see here). For notebooks with examples for how to do various things, please see the notebooks page (see here).</p>"},{"location":"emu_mps/api/","title":"API specification","text":"<p>The emu-mps API is based on the specification here. Concretely, the classes are as follows:</p>"},{"location":"emu_mps/api/#mpsbackend","title":"MPSBackend","text":"<p>               Bases: <code>EmulatorBackend</code></p> <p>A backend for emulating Pulser sequences using Matrix Product States (MPS), aka tensor trains.</p> Source code in <code>pulser/backend/abc.py</code> <pre><code>def __init__(\n    self,\n    sequence: pulser.Sequence,\n    *,\n    config: EmulationConfig | None = None,\n    mimic_qpu: bool = False,\n) -&gt; None:\n    \"\"\"Initializes the backend.\"\"\"\n    super().__init__(sequence, mimic_qpu=mimic_qpu)\n    config = config or self.default_config\n    if not isinstance(config, EmulationConfig):\n        raise TypeError(\n            \"'config' must be an instance of 'EmulationConfig', \"\n            f\"not {type(config)}.\"\n        )\n    # See the BackendConfig definition to see why this works\n    self._config = type(self.default_config)(**config._backend_options)\n</code></pre>"},{"location":"emu_mps/api/#emu_mps.mps_backend.MPSBackend.resume","title":"<code>resume(autosave_file)</code>  <code>staticmethod</code>","text":"<p>Resume simulation from autosave file. Only resume simulations from data you trust! Unpickling of untrusted data is not safe.</p> Source code in <code>emu_mps/mps_backend.py</code> <pre><code>@staticmethod\ndef resume(autosave_file: str | pathlib.Path) -&gt; Results:\n    \"\"\"\n    Resume simulation from autosave file.\n    Only resume simulations from data you trust!\n    Unpickling of untrusted data is not safe.\n    \"\"\"\n    if isinstance(autosave_file, str):\n        autosave_file = pathlib.Path(autosave_file)\n\n    if not autosave_file.is_file():\n        raise ValueError(f\"Not a file: {autosave_file}\")\n\n    with open(autosave_file, \"rb\") as f:\n        impl: MPSBackendImpl = pickle.load(f)\n\n    impl.autosave_file = autosave_file\n    impl.last_save_time = time.time()\n    impl.config.init_logging()  # FIXME: might be best to take logger object out of config.\n\n    logging.getLogger(\"global_logger\").warning(\n        f\"Resuming simulation from file {autosave_file}\\n\"\n        f\"Saving simulation state every {impl.config.autosave_dt} seconds\"\n    )\n\n    return MPSBackend._run(impl)\n</code></pre>"},{"location":"emu_mps/api/#emu_mps.mps_backend.MPSBackend.run","title":"<code>run()</code>","text":"<p>Emulates the given sequence.</p> RETURNS DESCRIPTION <code>Results</code> <p>the simulation results</p> Source code in <code>emu_mps/mps_backend.py</code> <pre><code>def run(self) -&gt; Results:\n    \"\"\"\n    Emulates the given sequence.\n\n    Returns:\n        the simulation results\n    \"\"\"\n    assert isinstance(self._config, MPSConfig)\n\n    impl = create_impl(self._sequence, self._config)\n    impl.init()  # This is separate from the constructor for testing purposes.\n\n    results = self._run(impl)\n\n    return impl.permute_results(results, self._config.optimize_qubit_ordering)\n</code></pre>"},{"location":"emu_mps/api/#mpsconfig","title":"MPSConfig","text":"<p>               Bases: <code>EmulationConfig</code></p> <p>The configuration of the emu-mps MPSBackend. The kwargs passed to this class are passed on to the base class. See the API for that class for a list of available options.</p> PARAMETER DESCRIPTION <code>dt</code> <p>the timestep size that the solver uses. Note that observables are only calculated if the evaluation_times are divisible by dt.</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> <code>precision</code> <p>up to what precision the state is truncated</p> <p> TYPE: <code>float</code> DEFAULT: <code>1e-05</code> </p> <code>max_bond_dim</code> <p>the maximum bond dimension that the state is allowed to have.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1024</code> </p> <code>max_krylov_dim</code> <p>the size of the krylov subspace that the Lanczos algorithm maximally builds</p> <p> TYPE: <code>int</code> DEFAULT: <code>100</code> </p> <code>extra_krylov_tolerance</code> <p>the Lanczos algorithm uses this*precision as the convergence tolerance</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.001</code> </p> <code>num_gpus_to_use</code> <p>during the simulation, distribute the state over this many GPUs 0=all factors to cpu. As shown in the benchmarks, using multiple GPUs might alleviate memory pressure per GPU, but the runtime should be similar.</p> <p> TYPE: <code>int</code> DEFAULT: <code>DEVICE_COUNT</code> </p> <code>optimize_qubit_ordering</code> <p>Optimize the register ordering. Improves performance and accuracy, but disables certain features.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>interaction_cutoff</code> <p>Set interaction coefficients below this value to <code>0</code>. Potentially improves runtime and memory consumption.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> <code>log_level</code> <p>How much to log. Set to <code>logging.WARN</code> to get rid of the timestep info.</p> <p> TYPE: <code>int</code> DEFAULT: <code>INFO</code> </p> <code>log_file</code> <p>If specified, log to this file rather than stout.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> <code>autosave_prefix</code> <p>filename prefix for autosaving simulation state to file</p> <p> TYPE: <code>str</code> DEFAULT: <code>'emu_mps_save_'</code> </p> <code>autosave_dt</code> <p>minimum time interval in seconds between two autosaves. Saving the simulation state is only possible at specific times, therefore this interval is only a lower bound.</p> <p> TYPE: <code>int</code> DEFAULT: <code>600</code> </p> <code>kwargs</code> <p>arguments that are passed to the base class</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; num_gpus_to_use = 2 #use 2 gpus if available, otherwise 1 or cpu\n&gt;&gt;&gt; dt = 1 #this will impact the runtime\n&gt;&gt;&gt; precision = 1e-6 #smaller dt requires better precision, generally\n&gt;&gt;&gt; MPSConfig(num_gpus_to_use=num_gpus_to_use, dt=dt, precision=precision,\n&gt;&gt;&gt;     with_modulation=True) #the last arg is taken from the base class\n</code></pre> Source code in <code>emu_mps/mps_config.py</code> <pre><code>def __init__(\n    self,\n    *,\n    dt: int = 10,\n    precision: float = 1e-5,\n    max_bond_dim: int = 1024,\n    max_krylov_dim: int = 100,\n    extra_krylov_tolerance: float = 1e-3,\n    num_gpus_to_use: int = DEVICE_COUNT,\n    optimize_qubit_ordering: bool = False,\n    interaction_cutoff: float = 0.0,\n    log_level: int = logging.INFO,\n    log_file: pathlib.Path | None = None,\n    autosave_prefix: str = \"emu_mps_save_\",\n    autosave_dt: int = 600,  # 10 minutes\n    **kwargs: Any,\n):\n    kwargs.setdefault(\"observables\", [BitStrings(evaluation_times=[1.0])])\n    super().__init__(\n        dt=dt,\n        precision=precision,\n        max_bond_dim=max_bond_dim,\n        max_krylov_dim=max_krylov_dim,\n        extra_krylov_tolerance=extra_krylov_tolerance,\n        num_gpus_to_use=num_gpus_to_use,\n        optimize_qubit_ordering=optimize_qubit_ordering,\n        interaction_cutoff=interaction_cutoff,\n        log_level=log_level,\n        log_file=log_file,\n        autosave_prefix=autosave_prefix,\n        autosave_dt=autosave_dt,\n        **kwargs,\n    )\n    if self.optimize_qubit_ordering:\n        self.check_permutable_observables()\n\n    MIN_AUTOSAVE_DT = 10\n    assert (\n        self.autosave_dt &gt; MIN_AUTOSAVE_DT\n    ), f\"autosave_dt must be larger than {MIN_AUTOSAVE_DT} seconds\"\n\n    self.monkeypatch_observables()\n\n    self.logger = logging.getLogger(\"global_logger\")\n    if log_file is None:\n        logging.basicConfig(\n            level=log_level, format=\"%(message)s\", stream=sys.stdout, force=True\n        )  # default to stream = sys.stderr\n    else:\n        logging.basicConfig(\n            level=log_level,\n            format=\"%(message)s\",\n            filename=str(log_file),\n            filemode=\"w\",\n            force=True,\n        )\n    if (self.noise_model.runs != 1 and self.noise_model.runs is not None) or (\n        self.noise_model.samples_per_run != 1\n        and self.noise_model.samples_per_run is not None\n    ):\n        self.logger.warning(\n            \"Warning: The runs and samples_per_run values of the NoiseModel are ignored!\"\n        )\n</code></pre>"},{"location":"emu_mps/api/#mps","title":"MPS","text":"<p>               Bases: <code>State[complex, Tensor]</code></p> <p>Matrix Product State, aka tensor train.</p> <p>Each tensor has 3 dimensions ordered as such: (left bond, site, right bond).</p> <p>Only qubits are supported.</p> <p>This constructor creates a MPS directly from a list of tensors. It is for internal use only.</p> PARAMETER DESCRIPTION <code>factors</code> <p>the tensors for each site WARNING: for efficiency in a lot of use cases, this list of tensors IS NOT DEEP-COPIED. Therefore, the new MPS object is not necessarily the exclusive owner of the list and its tensors. As a consequence, beware of potential external modifications affecting the list or the tensors. You are responsible for deciding whether to pass its own exclusive copy of the data to this constructor, or some shared objects.</p> <p> TYPE: <code>List[Tensor]</code> </p> <code>orthogonality_center</code> <p>the orthogonality center of the MPS, or None (in which case it will be orthogonalized when needed)</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>config</code> <p>the emu-mps config object passed to the run method</p> <p> TYPE: <code>Optional[MPSConfig]</code> DEFAULT: <code>None</code> </p> <code>num_gpus_to_use</code> <p>distribute the factors over this many GPUs 0=all factors to cpu, None=keep the existing device assignment.</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>DEVICE_COUNT</code> </p> Source code in <code>emu_mps/mps.py</code> <pre><code>def __init__(\n    self,\n    factors: List[torch.Tensor],\n    /,\n    *,\n    orthogonality_center: Optional[int] = None,\n    config: Optional[MPSConfig] = None,\n    num_gpus_to_use: Optional[int] = DEVICE_COUNT,\n    eigenstates: Sequence[Eigenstate] = (\"r\", \"g\"),\n):\n    \"\"\"\n    This constructor creates a MPS directly from a list of tensors. It is for internal use only.\n\n    Args:\n        factors: the tensors for each site\n            WARNING: for efficiency in a lot of use cases, this list of tensors\n            IS NOT DEEP-COPIED. Therefore, the new MPS object is not necessarily\n            the exclusive owner of the list and its tensors. As a consequence,\n            beware of potential external modifications affecting the list or the tensors.\n            You are responsible for deciding whether to pass its own exclusive copy\n            of the data to this constructor, or some shared objects.\n        orthogonality_center: the orthogonality center of the MPS, or None (in which case\n            it will be orthogonalized when needed)\n        config: the emu-mps config object passed to the run method\n        num_gpus_to_use: distribute the factors over this many GPUs\n            0=all factors to cpu, None=keep the existing device assignment.\n    \"\"\"\n    super().__init__(eigenstates=eigenstates)\n    self.config = config if config is not None else MPSConfig()\n    assert all(\n        factors[i - 1].shape[2] == factors[i].shape[0] for i in range(1, len(factors))\n    ), \"The dimensions of consecutive tensors should match\"\n    assert (\n        factors[0].shape[0] == 1 and factors[-1].shape[2] == 1\n    ), \"The dimension of the left (right) link of the first (last) tensor should be 1\"\n\n    self.factors = factors\n    self.num_sites = len(factors)\n    assert self.num_sites &gt; 1  # otherwise, do state vector\n\n    assert (orthogonality_center is None) or (\n        0 &lt;= orthogonality_center &lt; self.num_sites\n    ), \"Invalid orthogonality center provided\"\n    self.orthogonality_center = orthogonality_center\n\n    if num_gpus_to_use is not None:\n        assign_devices(self.factors, min(DEVICE_COUNT, num_gpus_to_use))\n</code></pre>"},{"location":"emu_mps/api/#emu_mps.mps.MPS.n_qudits","title":"<code>n_qudits</code>  <code>property</code>","text":"<p>The number of qudits in the state.</p>"},{"location":"emu_mps/api/#emu_mps.mps.MPS.__add__","title":"<code>__add__(other)</code>","text":"<p>Returns the sum of two MPSs, computed with a direct algorithm. The resulting MPS is orthogonalized on the first site and truncated up to <code>self.config.precision</code>.</p> PARAMETER DESCRIPTION <code>other</code> <p>the other state</p> <p> TYPE: <code>State</code> </p> RETURNS DESCRIPTION <code>MPS</code> <p>the summed state</p> Source code in <code>emu_mps/mps.py</code> <pre><code>def __add__(self, other: State) -&gt; MPS:\n    \"\"\"\n    Returns the sum of two MPSs, computed with a direct algorithm.\n    The resulting MPS is orthogonalized on the first site and truncated\n    up to `self.config.precision`.\n\n    Args:\n        other: the other state\n\n    Returns:\n        the summed state\n    \"\"\"\n    assert isinstance(other, MPS), \"Other state also needs to be an MPS\"\n    assert (\n        self.eigenstates == other.eigenstates\n    ), f\"`Other` state has basis {other.eigenstates} != {self.eigenstates}\"\n    new_tt = add_factors(self.factors, other.factors)\n    result = MPS(\n        new_tt,\n        config=self.config,\n        num_gpus_to_use=None,\n        orthogonality_center=None,  # Orthogonality is lost.\n        eigenstates=self.eigenstates,\n    )\n    result.truncate()\n    return result\n</code></pre>"},{"location":"emu_mps/api/#emu_mps.mps.MPS.__rmul__","title":"<code>__rmul__(scalar)</code>","text":"<p>Multiply an MPS by a scalar.</p> PARAMETER DESCRIPTION <code>scalar</code> <p>the scale factor</p> <p> TYPE: <code>complex</code> </p> RETURNS DESCRIPTION <code>MPS</code> <p>the scaled MPS</p> Source code in <code>emu_mps/mps.py</code> <pre><code>def __rmul__(self, scalar: complex) -&gt; MPS:\n    \"\"\"\n    Multiply an MPS by a scalar.\n\n    Args:\n        scalar: the scale factor\n\n    Returns:\n        the scaled MPS\n    \"\"\"\n    which = (\n        self.orthogonality_center\n        if self.orthogonality_center is not None\n        else 0  # No need to orthogonalize for scaling.\n    )\n    factors = scale_factors(self.factors, scalar, which=which)\n    return MPS(\n        factors,\n        config=self.config,\n        num_gpus_to_use=None,\n        orthogonality_center=self.orthogonality_center,\n        eigenstates=self.eigenstates,\n    )\n</code></pre>"},{"location":"emu_mps/api/#emu_mps.mps.MPS.apply","title":"<code>apply(qubit_index, single_qubit_operator)</code>","text":"<p>Apply given single qubit operator to qubit qubit_index, leaving the MPS orthogonalized on that qubit.</p> Source code in <code>emu_mps/mps.py</code> <pre><code>def apply(self, qubit_index: int, single_qubit_operator: torch.Tensor) -&gt; None:\n    \"\"\"\n    Apply given single qubit operator to qubit qubit_index, leaving the MPS\n    orthogonalized on that qubit.\n    \"\"\"\n    self.orthogonalize(qubit_index)\n\n    self.factors[qubit_index] = (\n        single_qubit_operator.to(self.factors[qubit_index].device)\n        @ self.factors[qubit_index]\n    )\n</code></pre>"},{"location":"emu_mps/api/#emu_mps.mps.MPS.entanglement_entropy","title":"<code>entanglement_entropy(mps_site)</code>","text":"<p>Returns the Von Neumann entanglement entropy of the state <code>mps</code> at the bond between sites b and b+1 S = -\u03a3\u1d62s\u1d62\u00b2 log(s\u1d62\u00b2)), where s\u1d62 are the singular values at the chosen bond.</p> Source code in <code>emu_mps/mps.py</code> <pre><code>def entanglement_entropy(self, mps_site: int) -&gt; torch.Tensor:\n    \"\"\"\n    Returns\n    the Von Neumann entanglement entropy of the state `mps` at the bond between sites b and b+1\n    S = -\u03a3\u1d62s\u1d62\u00b2 log(s\u1d62\u00b2)),\n    where s\u1d62 are the singular values at the chosen bond.\n    \"\"\"\n    self.orthogonalize(mps_site)\n\n    # perform svd on reshaped matrix at site b\n    matrix = self.factors[mps_site].flatten(end_dim=1)\n    s = torch.linalg.svdvals(matrix)\n\n    s_e = torch.Tensor(torch.special.entr(s**2))\n    s_e = torch.sum(s_e)\n\n    self.orthogonalize(0)\n    return s_e.cpu()\n</code></pre>"},{"location":"emu_mps/api/#emu_mps.mps.MPS.expect_batch","title":"<code>expect_batch(single_qubit_operators)</code>","text":"<p>Computes expectation values for each qubit and each single qubit operator in the batched input tensor.</p> <p>Returns a tensor T such that T[q, i] is the expectation value for qubit #q and operator single_qubit_operators[i].</p> Source code in <code>emu_mps/mps.py</code> <pre><code>def expect_batch(self, single_qubit_operators: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Computes expectation values for each qubit and each single qubit operator in\n    the batched input tensor.\n\n    Returns a tensor T such that T[q, i] is the expectation value for qubit #q\n    and operator single_qubit_operators[i].\n    \"\"\"\n    orthogonality_center = (\n        self.orthogonality_center\n        if self.orthogonality_center is not None\n        else self.orthogonalize(0)\n    )\n\n    result = torch.zeros(\n        self.num_sites, single_qubit_operators.shape[0], dtype=torch.complex128\n    )\n\n    center_factor = self.factors[orthogonality_center]\n    for qubit_index in range(orthogonality_center, self.num_sites):\n        temp = torch.tensordot(center_factor.conj(), center_factor, ([0, 2], [0, 2]))\n\n        result[qubit_index] = torch.tensordot(\n            single_qubit_operators.to(temp.device), temp, dims=2\n        )\n\n        if qubit_index &lt; self.num_sites - 1:\n            _, r = torch.linalg.qr(center_factor.view(-1, center_factor.shape[2]))\n            center_factor = torch.tensordot(\n                r, self.factors[qubit_index + 1].to(r.device), dims=1\n            )\n\n    center_factor = self.factors[orthogonality_center]\n    for qubit_index in range(orthogonality_center - 1, -1, -1):\n        _, r = torch.linalg.qr(\n            center_factor.view(center_factor.shape[0], -1).mT,\n        )\n        center_factor = torch.tensordot(\n            self.factors[qubit_index],\n            r.to(self.factors[qubit_index].device),\n            ([2], [1]),\n        )\n\n        temp = torch.tensordot(center_factor.conj(), center_factor, ([0, 2], [0, 2]))\n\n        result[qubit_index] = torch.tensordot(\n            single_qubit_operators.to(temp.device), temp, dims=2\n        )\n\n    return result\n</code></pre>"},{"location":"emu_mps/api/#emu_mps.mps.MPS.get_correlation_matrix","title":"<code>get_correlation_matrix(*, operator=n_operator)</code>","text":"<p>Efficiently compute the symmetric correlation matrix     C_ij =  in basis (\"r\", \"g\"). PARAMETER DESCRIPTION <code>operator</code> <p>a 2x2 Torch tensor to use</p> <p> TYPE: <code>Tensor</code> DEFAULT: <code>n_operator</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>the corresponding correlation matrix</p> Source code in <code>emu_mps/mps.py</code> <pre><code>def get_correlation_matrix(\n    self, *, operator: torch.Tensor = n_operator\n) -&gt; torch.Tensor:\n    \"\"\"\n    Efficiently compute the symmetric correlation matrix\n        C_ij = &lt;self|operator_i operator_j|self&gt;\n    in basis (\"r\", \"g\").\n\n    Args:\n        operator: a 2x2 Torch tensor to use\n\n    Returns:\n        the corresponding correlation matrix\n    \"\"\"\n    assert operator.shape == (2, 2)\n\n    result = torch.zeros(self.num_sites, self.num_sites, dtype=torch.complex128)\n\n    for left in range(0, self.num_sites):\n        self.orthogonalize(left)\n        accumulator = torch.tensordot(\n            self.factors[left],\n            operator.to(self.factors[left].device),\n            dims=([1], [0]),\n        )\n        accumulator = torch.tensordot(\n            accumulator, self.factors[left].conj(), dims=([0, 2], [0, 1])\n        )\n        result[left, left] = accumulator.trace().item().real\n        for right in range(left + 1, self.num_sites):\n            partial = torch.tensordot(\n                accumulator.to(self.factors[right].device),\n                self.factors[right],\n                dims=([0], [0]),\n            )\n            partial = torch.tensordot(\n                partial, self.factors[right].conj(), dims=([0], [0])\n            )\n\n            result[left, right] = (\n                torch.tensordot(\n                    partial, operator.to(partial.device), dims=([0, 2], [0, 1])\n                )\n                .trace()\n                .item()\n                .real\n            )\n            result[right, left] = result[left, right]\n            accumulator = tensor_trace(partial, 0, 2)\n\n    return result\n</code></pre>"},{"location":"emu_mps/api/#emu_mps.mps.MPS.get_max_bond_dim","title":"<code>get_max_bond_dim()</code>","text":"<p>Return the max bond dimension of this MPS.</p> RETURNS DESCRIPTION <code>int</code> <p>the largest bond dimension in the state</p> Source code in <code>emu_mps/mps.py</code> <pre><code>def get_max_bond_dim(self) -&gt; int:\n    \"\"\"\n    Return the max bond dimension of this MPS.\n\n    Returns:\n        the largest bond dimension in the state\n    \"\"\"\n    return max((x.shape[2] for x in self.factors), default=0)\n</code></pre>"},{"location":"emu_mps/api/#emu_mps.mps.MPS.get_memory_footprint","title":"<code>get_memory_footprint()</code>","text":"<p>Returns the number of MBs of memory occupied to store the state</p> RETURNS DESCRIPTION <code>float</code> <p>the memory in MBs</p> Source code in <code>emu_mps/mps.py</code> <pre><code>def get_memory_footprint(self) -&gt; float:\n    \"\"\"\n    Returns the number of MBs of memory occupied to store the state\n\n    Returns:\n        the memory in MBs\n    \"\"\"\n    return (  # type: ignore[no-any-return]\n        sum(factor.element_size() * factor.numel() for factor in self.factors) * 1e-6\n    )\n</code></pre>"},{"location":"emu_mps/api/#emu_mps.mps.MPS.inner","title":"<code>inner(other)</code>","text":"<p>Compute the inner product between this state and other. Note that self is the left state in the inner product, so this function is linear in other, and anti-linear in self</p> PARAMETER DESCRIPTION <code>other</code> <p>the other state</p> <p> TYPE: <code>State</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>inner product</p> Source code in <code>emu_mps/mps.py</code> <pre><code>def inner(self, other: State) -&gt; torch.Tensor:\n    \"\"\"\n    Compute the inner product between this state and other.\n    Note that self is the left state in the inner product,\n    so this function is linear in other, and anti-linear in self\n\n    Args:\n        other: the other state\n\n    Returns:\n        inner product\n    \"\"\"\n    assert isinstance(other, MPS), \"Other state also needs to be an MPS\"\n    assert (\n        self.num_sites == other.num_sites\n    ), \"States do not have the same number of sites\"\n\n    acc = torch.ones(1, 1, dtype=self.factors[0].dtype, device=self.factors[0].device)\n\n    for i in range(self.num_sites):\n        acc = acc.to(self.factors[i].device)\n        acc = torch.tensordot(acc, other.factors[i].to(acc.device), dims=1)\n        acc = torch.tensordot(self.factors[i].conj(), acc, dims=([0, 1], [0, 1]))\n\n    return acc.view(1)[0].cpu()\n</code></pre>"},{"location":"emu_mps/api/#emu_mps.mps.MPS.make","title":"<code>make(num_sites, config=None, num_gpus_to_use=DEVICE_COUNT, eigenstates=['0', '1'])</code>  <code>classmethod</code>","text":"<p>Returns a MPS in ground state |000..0&gt;.</p> PARAMETER DESCRIPTION <code>num_sites</code> <p>the number of qubits</p> <p> TYPE: <code>int</code> </p> <code>config</code> <p>the MPSConfig</p> <p> TYPE: <code>Optional[MPSConfig]</code> DEFAULT: <code>None</code> </p> <code>num_gpus_to_use</code> <p>distribute the factors over this many GPUs 0=all factors to cpu</p> <p> TYPE: <code>int</code> DEFAULT: <code>DEVICE_COUNT</code> </p> Source code in <code>emu_mps/mps.py</code> <pre><code>@classmethod\ndef make(\n    cls,\n    num_sites: int,\n    config: Optional[MPSConfig] = None,\n    num_gpus_to_use: int = DEVICE_COUNT,\n    eigenstates: Sequence[Eigenstate] = [\"0\", \"1\"],\n) -&gt; MPS:\n    \"\"\"\n    Returns a MPS in ground state |000..0&gt;.\n\n    Args:\n        num_sites: the number of qubits\n        config: the MPSConfig\n        num_gpus_to_use: distribute the factors over this many GPUs\n            0=all factors to cpu\n    \"\"\"\n    config = config if config is not None else MPSConfig()\n\n    if num_sites &lt;= 1:\n        raise ValueError(\"For 1 qubit states, do state vector\")\n\n    return cls(\n        [\n            torch.tensor([[[1.0], [0.0]]], dtype=torch.complex128)\n            for _ in range(num_sites)\n        ],\n        config=config,\n        num_gpus_to_use=num_gpus_to_use,\n        orthogonality_center=0,  # Arbitrary: every qubit is an orthogonality center.\n        eigenstates=eigenstates,\n    )\n</code></pre>"},{"location":"emu_mps/api/#emu_mps.mps.MPS.norm","title":"<code>norm()</code>","text":"<p>Computes the norm of the MPS.</p> Source code in <code>emu_mps/mps.py</code> <pre><code>def norm(self) -&gt; torch.Tensor:\n    \"\"\"Computes the norm of the MPS.\"\"\"\n    orthogonality_center = (\n        self.orthogonality_center\n        if self.orthogonality_center is not None\n        else self.orthogonalize(0)\n    )\n    # the torch.norm function is not properly typed.\n    return self.factors[orthogonality_center].norm().cpu()  # type: ignore[no-any-return]\n</code></pre>"},{"location":"emu_mps/api/#emu_mps.mps.MPS.orthogonalize","title":"<code>orthogonalize(desired_orthogonality_center=0)</code>","text":"<p>Orthogonalize the state on the given orthogonality center.</p> <p>Returns the new orthogonality center index as an integer, this is convenient for type-checking purposes.</p> Source code in <code>emu_mps/mps.py</code> <pre><code>def orthogonalize(self, desired_orthogonality_center: int = 0) -&gt; int:\n    \"\"\"\n    Orthogonalize the state on the given orthogonality center.\n\n    Returns the new orthogonality center index as an integer,\n    this is convenient for type-checking purposes.\n    \"\"\"\n    assert (\n        0 &lt;= desired_orthogonality_center &lt; self.num_sites\n    ), f\"Cannot move orthogonality center to nonexistent qubit #{desired_orthogonality_center}\"\n\n    lr_swipe_start = (\n        self.orthogonality_center if self.orthogonality_center is not None else 0\n    )\n\n    for i in range(lr_swipe_start, desired_orthogonality_center):\n        q, r = torch.linalg.qr(self.factors[i].view(-1, self.factors[i].shape[2]))\n        self.factors[i] = q.view(self.factors[i].shape[0], 2, -1)\n        self.factors[i + 1] = torch.tensordot(\n            r.to(self.factors[i + 1].device), self.factors[i + 1], dims=1\n        )\n\n    rl_swipe_start = (\n        self.orthogonality_center\n        if self.orthogonality_center is not None\n        else (self.num_sites - 1)\n    )\n\n    for i in range(rl_swipe_start, desired_orthogonality_center, -1):\n        q, r = torch.linalg.qr(\n            self.factors[i].view(self.factors[i].shape[0], -1).mT,\n        )\n        self.factors[i] = q.mT.view(-1, 2, self.factors[i].shape[2])\n        self.factors[i - 1] = torch.tensordot(\n            self.factors[i - 1], r.to(self.factors[i - 1].device), ([2], [1])\n        )\n\n    self.orthogonality_center = desired_orthogonality_center\n\n    return desired_orthogonality_center\n</code></pre>"},{"location":"emu_mps/api/#emu_mps.mps.MPS.overlap","title":"<code>overlap(other)</code>","text":"<p>Compute the overlap of this state and other. This is defined as \\(|\\langle self | other \\rangle |^2\\)</p> Source code in <code>emu_mps/mps.py</code> <pre><code>def overlap(self, other: State, /) -&gt; torch.Tensor:\n    \"\"\"\n    Compute the overlap of this state and other. This is defined as\n    $|\\\\langle self | other \\\\rangle |^2$\n    \"\"\"\n    return torch.abs(self.inner(other)) ** 2  # type: ignore[no-any-return]\n</code></pre>"},{"location":"emu_mps/api/#emu_mps.mps.MPS.sample","title":"<code>sample(*, num_shots, one_state=None, p_false_pos=0.0, p_false_neg=0.0)</code>","text":"<p>Samples bitstrings, taking into account the specified error rates.</p> PARAMETER DESCRIPTION <code>num_shots</code> <p>how many bitstrings to sample</p> <p> TYPE: <code>int</code> </p> <code>p_false_pos</code> <p>the rate at which a 0 is read as a 1</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> <code>p_false_neg</code> <p>the rate at which a 1 is read as a 0</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> RETURNS DESCRIPTION <code>Counter[str]</code> <p>the measured bitstrings, by count</p> Source code in <code>emu_mps/mps.py</code> <pre><code>def sample(\n    self,\n    *,\n    num_shots: int,\n    one_state: Eigenstate | None = None,\n    p_false_pos: float = 0.0,\n    p_false_neg: float = 0.0,\n) -&gt; Counter[str]:\n    \"\"\"\n    Samples bitstrings, taking into account the specified error rates.\n\n    Args:\n        num_shots: how many bitstrings to sample\n        p_false_pos: the rate at which a 0 is read as a 1\n        p_false_neg: the rate at which a 1 is read as a 0\n\n    Returns:\n        the measured bitstrings, by count\n    \"\"\"\n    assert one_state in {None, \"r\", \"1\"}\n    self.orthogonalize(0)\n\n    rnd_matrix = torch.rand(num_shots, self.num_sites).to(self.factors[0].device)\n\n    bitstrings: Counter[str] = Counter()\n\n    # Shots are performed in batches.\n    # Larger max_batch_size is faster but uses more memory.\n    max_batch_size = 32\n\n    shots_done = 0\n    while shots_done &lt; num_shots:\n        batch_size = min(max_batch_size, num_shots - shots_done)\n        batched_accumulator = torch.ones(\n            batch_size, 1, dtype=torch.complex128, device=self.factors[0].device\n        )\n\n        batch_outcomes = torch.empty(batch_size, self.num_sites, dtype=torch.bool)\n\n        for qubit, factor in enumerate(self.factors):\n            batched_accumulator = torch.tensordot(\n                batched_accumulator.to(factor.device), factor, dims=1\n            )\n\n            # Probability of measuring qubit == 0 for each shot in the batch\n            probas = (\n                torch.linalg.vector_norm(batched_accumulator[:, 0, :], dim=1) ** 2\n            )\n\n            outcomes = (\n                rnd_matrix[shots_done : shots_done + batch_size, qubit].to(\n                    factor.device\n                )\n                &gt; probas\n            )\n            batch_outcomes[:, qubit] = outcomes\n\n            # Batch collapse qubit\n            tmp = torch.stack((~outcomes, outcomes), dim=1).to(dtype=torch.complex128)\n\n            batched_accumulator = (\n                torch.tensordot(batched_accumulator, tmp, dims=([1], [1]))\n                .diagonal(dim1=0, dim2=2)\n                .transpose(1, 0)\n            )\n            batched_accumulator /= torch.sqrt(\n                (~outcomes) * probas + outcomes * (1 - probas)\n            ).unsqueeze(1)\n\n        shots_done += batch_size\n\n        for outcome in batch_outcomes:\n            bitstrings.update([\"\".join(\"0\" if x == 0 else \"1\" for x in outcome)])\n\n    if p_false_neg &gt; 0 or p_false_pos &gt; 0:\n        bitstrings = apply_measurement_errors(\n            bitstrings,\n            p_false_pos=p_false_pos,\n            p_false_neg=p_false_neg,\n        )\n    return bitstrings\n</code></pre>"},{"location":"emu_mps/api/#emu_mps.mps.MPS.truncate","title":"<code>truncate()</code>","text":"<p>SVD based truncation of the state. Puts the orthogonality center at the first qubit. Calls orthogonalize on the last qubit, and then sweeps a series of SVDs right-left. Uses self.config for determining accuracy. An in-place operation.</p> Source code in <code>emu_mps/mps.py</code> <pre><code>def truncate(self) -&gt; None:\n    \"\"\"\n    SVD based truncation of the state. Puts the orthogonality center at the first qubit.\n    Calls orthogonalize on the last qubit, and then sweeps a series of SVDs right-left.\n    Uses self.config for determining accuracy.\n    An in-place operation.\n    \"\"\"\n    self.orthogonalize(self.num_sites - 1)\n    truncate_impl(self.factors, config=self.config)\n    self.orthogonality_center = 0\n</code></pre>"},{"location":"emu_mps/api/#inner","title":"inner","text":"<p>Wrapper around MPS.inner.</p> PARAMETER DESCRIPTION <code>left</code> <p>the anti-linear argument</p> <p> TYPE: <code>MPS</code> </p> <code>right</code> <p>the linear argument</p> <p> TYPE: <code>MPS</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>the inner product</p> Source code in <code>emu_mps/mps.py</code> <pre><code>def inner(left: MPS, right: MPS) -&gt; torch.Tensor:\n    \"\"\"\n    Wrapper around MPS.inner.\n\n    Args:\n        left: the anti-linear argument\n        right: the linear argument\n\n    Returns:\n        the inner product\n    \"\"\"\n    return left.inner(right)\n</code></pre>"},{"location":"emu_mps/api/#mpo","title":"MPO","text":"<p>               Bases: <code>Operator[complex, Tensor, MPS]</code></p> <p>Matrix Product Operator.</p> <p>Each tensor has 4 dimensions ordered as such: (left bond, output, input, right bond).</p> PARAMETER DESCRIPTION <code>factors</code> <p>the tensors making up the MPO</p> <p> TYPE: <code>List[Tensor]</code> </p> Source code in <code>emu_mps/mpo.py</code> <pre><code>def __init__(\n    self, factors: List[torch.Tensor], /, num_gpus_to_use: Optional[int] = None\n):\n    self.factors = factors\n    self.num_sites = len(factors)\n    if not self.num_sites &gt; 1:\n        raise ValueError(\"For 1 qubit states, do state vector\")\n    if factors[0].shape[0] != 1 or factors[-1].shape[-1] != 1:\n        raise ValueError(\n            \"The dimension of the left (right) link of the first (last) tensor should be 1\"\n        )\n    assert all(\n        factors[i - 1].shape[-1] == factors[i].shape[0]\n        for i in range(1, self.num_sites)\n    )\n\n    if num_gpus_to_use is not None:\n        assign_devices(self.factors, min(DEVICE_COUNT, num_gpus_to_use))\n</code></pre>"},{"location":"emu_mps/api/#emu_mps.mpo.MPO.__add__","title":"<code>__add__(other)</code>","text":"<p>Returns the sum of two MPOs, computed with a direct algorithm. The result is currently not truncated</p> PARAMETER DESCRIPTION <code>other</code> <p>the other operator</p> <p> TYPE: <code>MPO</code> </p> RETURNS DESCRIPTION <code>MPO</code> <p>the summed operator</p> Source code in <code>emu_mps/mpo.py</code> <pre><code>def __add__(self, other: MPO) -&gt; MPO:\n    \"\"\"\n    Returns the sum of two MPOs, computed with a direct algorithm.\n    The result is currently not truncated\n\n    Args:\n        other: the other operator\n\n    Returns:\n        the summed operator\n    \"\"\"\n    assert isinstance(other, MPO), \"MPO can only be added to another MPO\"\n    sum_factors = add_factors(self.factors, other.factors)\n    return MPO(sum_factors)\n</code></pre>"},{"location":"emu_mps/api/#emu_mps.mpo.MPO.__matmul__","title":"<code>__matmul__(other)</code>","text":"<p>Compose two operators. The ordering is that self is applied after other.</p> PARAMETER DESCRIPTION <code>other</code> <p>the operator to compose with self</p> <p> TYPE: <code>MPO</code> </p> RETURNS DESCRIPTION <code>MPO</code> <p>the composed operator</p> Source code in <code>emu_mps/mpo.py</code> <pre><code>def __matmul__(self, other: MPO) -&gt; MPO:\n    \"\"\"\n    Compose two operators. The ordering is that\n    self is applied after other.\n\n    Args:\n        other: the operator to compose with self\n\n    Returns:\n        the composed operator\n    \"\"\"\n    assert isinstance(other, MPO), \"MPO can only be applied to another MPO\"\n    factors = zip_right(self.factors, other.factors)\n    return MPO(factors)\n</code></pre>"},{"location":"emu_mps/api/#emu_mps.mpo.MPO.__rmul__","title":"<code>__rmul__(scalar)</code>","text":"<p>Multiply an MPO by scalar. Assumes the orthogonal centre is on the first factor.</p> PARAMETER DESCRIPTION <code>scalar</code> <p>the scale factor to multiply with</p> <p> TYPE: <code>complex</code> </p> RETURNS DESCRIPTION <code>MPO</code> <p>the scaled MPO</p> Source code in <code>emu_mps/mpo.py</code> <pre><code>def __rmul__(self, scalar: complex) -&gt; MPO:\n    \"\"\"\n    Multiply an MPO by scalar.\n    Assumes the orthogonal centre is on the first factor.\n\n    Args:\n        scalar: the scale factor to multiply with\n\n    Returns:\n        the scaled MPO\n    \"\"\"\n    factors = scale_factors(self.factors, scalar, which=0)\n    return MPO(factors)\n</code></pre>"},{"location":"emu_mps/api/#emu_mps.mpo.MPO.apply_to","title":"<code>apply_to(other)</code>","text":"<p>Applies this MPO to the given MPS. The returned MPS is:</p> <pre><code>- othogonal on the first site\n- truncated up to `other.precision`\n- distributed on the same devices of `other`\n</code></pre> PARAMETER DESCRIPTION <code>other</code> <p>the state to apply this operator to</p> <p> TYPE: <code>MPS</code> </p> RETURNS DESCRIPTION <code>MPS</code> <p>the resulting state</p> Source code in <code>emu_mps/mpo.py</code> <pre><code>def apply_to(self, other: MPS) -&gt; MPS:\n    \"\"\"\n    Applies this MPO to the given MPS.\n    The returned MPS is:\n\n        - othogonal on the first site\n        - truncated up to `other.precision`\n        - distributed on the same devices of `other`\n\n    Args:\n        other: the state to apply this operator to\n\n    Returns:\n        the resulting state\n    \"\"\"\n    assert isinstance(other, MPS), \"MPO can only be multiplied with MPS\"\n    factors = zip_right(\n        self.factors,\n        other.factors,\n        config=other.config,\n    )\n    return MPS(factors, orthogonality_center=0, eigenstates=other.eigenstates)\n</code></pre>"},{"location":"emu_mps/api/#emu_mps.mpo.MPO.expect","title":"<code>expect(state)</code>","text":"<p>Compute the expectation value of self on the given state.</p> PARAMETER DESCRIPTION <code>state</code> <p>the state with which to compute</p> <p> TYPE: <code>State</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>the expectation</p> Source code in <code>emu_mps/mpo.py</code> <pre><code>def expect(self, state: State) -&gt; torch.Tensor:\n    \"\"\"\n    Compute the expectation value of self on the given state.\n\n    Args:\n        state: the state with which to compute\n\n    Returns:\n        the expectation\n    \"\"\"\n    assert isinstance(\n        state, MPS\n    ), \"currently, only expectation values of MPSs are \\\n    supported\"\n    acc = torch.ones(\n        1, 1, 1, dtype=state.factors[0].dtype, device=state.factors[0].device\n    )\n    n = len(self.factors) - 1\n    for i in range(n):\n        acc = new_left_bath(acc, state.factors[i], self.factors[i]).to(\n            state.factors[i + 1].device\n        )\n    acc = new_left_bath(acc, state.factors[n], self.factors[n])\n    return acc.view(1)[0].cpu()\n</code></pre>"},{"location":"emu_mps/advanced/","title":"Advanced topics","text":"<p>You have reached the advanced topics. Links to the individual pages discussing the various topics can be found in the sidebar to the left. The content here all relates to the inner workings of emu-mps and is more conceptual in nature. You will not find information here about how to actually run a simulation, but rather</p> <ul> <li>What Hamiltonian the emulator uses for time-evolution</li> <li>Some relevant information about the MPS representation</li> <li>A summary of the TDVP algorithm</li> <li>What sources of error TDVP incurs</li> <li>A page about the Monte Carlo quantum jumps emu-mps uses for noisy simulations</li> <li>What the various configuration parameters mean mathematically</li> <li>How to determine whether your results are accurate</li> <li>How to estimate the memory consumption and the runtime of a simulation in advance</li> </ul> <p>For the experienced user, this will help get the most out of emu-mps.</p>"},{"location":"emu_mps/advanced/config/","title":"Explanation of config values","text":"<p>The following config values to emu-mps relate to the functioning of the tdvp algorithm used to evolve the quantum state in time, and will be explained in more detail below:</p> <ul> <li>dt</li> <li>precision</li> <li>max_bond_dim</li> <li>max_krylov_dim</li> <li>extra_krylov_tolerance</li> </ul>"},{"location":"emu_mps/advanced/config/#dt","title":"dt","text":"<p>Note that emu-mps assumes the Hamiltonian is piece-wise constant in time for intervals of <code>dt</code>. It then constructs the Hamiltonian by sampling the amplitude, detuning and phase of the pulse midway through the interval, and making a single Hamiltonian. The TDVP algorithm is then used to evolve the state by <code>dt</code>. There are two sources of error related to <code>dt</code>.</p> <ul> <li>The discretization of the pulse</li> <li>TDVP</li> </ul> <p>Both sources of error dictate that <code>dt</code> shall not be too small, but the functioning of TDVP also dictates that a very small <code>dt</code> requires improving the precision, as described in the next section.</p>"},{"location":"emu_mps/advanced/config/#precision","title":"precision","text":"<p>The 2-site TDVP algorithm used in emu-mps works by repeatedly time-evolving two neighbouring qubits in the MPS, and then truncating the result. Truncation is done by applying an SVD to the matrix representing the 2-qubit subsystem. The singular values give much information about the state. Denote the singular values by \\(d_i\\), and assume they are ordered in decreasing magnitude. Then the norm of the state will be \\(\\sum_i d_i^2\\) and the entanglement entropy between the left and right parts of the state will be \\(\\sum_i d_i \\log_2(d_i)\\), for example.</p> <p>The truncation mentioned above functions by throwing away the smallest singular values, until their squared sum exceeds \\(precision^2\\). The result is that the truncation procedure finds the smallest MPS whose distance is less than <code>precision</code> away from the original state. As described on the page of errors in TDVP, the error in TDVP increases with the number of timesteps, so for long sequences or small <code>dt</code>, improving the precision might be required.</p>"},{"location":"emu_mps/advanced/config/#max_bond_dim","title":"max_bond_dim","text":"<p>In addition to the above procedure, at each truncation step, no more than <code>max_bond_dim</code> singular values are kept. This parameter will impose a hard cap on the memory consumed by the quantum state, at the cost of losing control over the magnitude of the truncation errors.</p>"},{"location":"emu_mps/advanced/config/#max_krylov_dim","title":"max_krylov_dim","text":"<p>Time evolution of each qubit pair is done by the Lanczos algorithm. This algorithm works by iteratively constructing a basis in which the Hamiltonian is close to diagonal. In this basis, the time-evolution of the state can efficiently be approximated by exponentiating a truncated Hamiltonian. The algorithm will never construct more than <code>max_krylov_dim</code> basis vectors, limiting the runtime and memory consumption of the time-evolution.</p> <p>Note that the number of iterations the Lanczos algorithm needs to converge to the required tolerance depends on the <code>dt</code> parameter also present in the config (see the api specification). The default value of <code>max_krylov_dim</code> should work for most reasonable values of <code>dt</code>, so if you get a recursion error out of the Lanczos algorithm, ensure you understand how the errors in TDVP depend on <code>dt</code>.</p>"},{"location":"emu_mps/advanced/config/#extra_krylov_tolerance","title":"extra_krylov_tolerance","text":"<p>In addition to the above hard cap on the number of basis vectors, the algorithm will also attempt to estimate the error incurred by computing the matrix exponential using only the current basis vectors. In principle, it is not needed to compute the time-evolution more precisely than <code>precision</code> since extra precision will be lost in the truncation. However, in practice it turns out that existing error estimates tend to underestimate the error. <code>extra_krylov_tolerance</code> is a fudge factor for how big the desired precision should be compared to <code>precision</code>. Its default value is <code>1e-3</code>.</p>"},{"location":"emu_mps/advanced/convergence/","title":"Validating correctness of the results from a simulation","text":"<p>By limiting the bond dimension of the state, systems of arbitrary size can be simulated (memory consumption). However, when truncation of the state hits the hard cap of <code>max_bond_dim</code>, control over the error incurred by truncation is lost, and care must be taken that the results are still accurate. By setting <code>max_bond_dim = 1600</code> <code>extra_krylov_tolerance=1e-5</code> and <code>precision=1e-6</code>, we were able to run the adiabatic pulse from the benchmarks for a 7x7 grid. For an analysis of the performance, see the benchmark page. This is a pulse that creates an antiferromagnetic state for smaller grids. However, whether or not a state is still effectively adiabatic depends on the energy gap of the system, and this decreases with system size. This example is instructive because lack of antiferromagnetic structure for larger systems does not automatically mean that the simulation was not accurate. The obtained qubit density was</p> 0.87  0.47  0.62  0.56  0.62  0.47  0.87  0.47  0.43  0.41  0.42  0.41  0.43  0.47  0.62  0.41  0.47  0.45  0.47  0.41  0.62  0.56  0.42  0.45  0.45  0.45  0.42  0.56  0.62  0.41  0.47  0.45  0.47  0.41  0.62  0.47  0.43  0.41  0.42  0.41  0.43  0.47  0.87  0.47  0.62  0.56  0.62  0.47  0.87"},{"location":"emu_mps/advanced/convergence/#trusting-your-results","title":"Trusting your results","text":"<p>First let's discuss whether these results are trustworthy, and then how the values of <code>max_bond_dim</code> and <code>precision</code> were obtained iteratively.</p> <p>For verifying the validity of the results, users should vary the parameters of the emulator until the results become insensitive to their variation (see here). This is what was done to obtain the above results, and then the main question is whether long-range interactions are correctly taken into account by the TDVP algorithm. It is worth noting that TDVP is a 1-d algorithm, so that qubits that are close in physical space are not necessarily close in the MPS layout. Specifically, the register ordering we used in the MPS simply concatenates all the colums of the above grid, and uses the resulting linear ordering, so while qubit \\((1,1)\\) and \\((1,2)\\) are neighbours in the MPS, qubits \\((1,1)\\) and \\((2,1)\\) are not, and this creates an artifical long-range interaction, which TDVP handles through an effective description (see here). If the effective description of the interaction did not take the Rydberg interaction properly into account, we would expect to see different structure in the qubit densities along the horizontal axis than along the vertical one, due to the error in the effective description. This is not the case because the table of qubit densities shown above obeys the symmetries of the grid: the table can be reflected along the horizontal and vertical axis, as well as rotated by right angles (and because these tranformations form a group, reflection symmetry around the diagonals follows, etc.).</p> <p>Since the qubit density results have symmetries that we expect to be broken by the errors intrinsic in TDVP, it is likely that the above results are correct even though only weak antiferromagnetic structure is present. Instead, the lack of antiferromagnetic structure probably occurs because the pulse used is no longer effectively adiabatic for this system size.</p> <p>Now let us consider why we used the config values quoted above.</p>"},{"location":"emu_mps/advanced/convergence/#exploring-the-parameter-space","title":"exploring the parameter space","text":"<p>Since the starting point of a parameter search is always a bit arbitrary, we started by seeing with what <code>max_bond_dim</code> we could still simulate the pulse, for the default precision, on 2 gpus. This turns out to have been 1800. Then the first point of investigation was how much this result depends on bond dimension. Only in the below equations, let \\(\\psi_d\\) denote the state obtained for <code>max_bond_dim=d</code>, then we found</p> \\[ \\langle\\psi_{1800}, \\psi_{1700}\\rangle = 0.999 \\] \\[ \\langle\\psi_{1800}, \\psi_{1600}\\rangle = 0.999 \\] <p>These inner products mean the output state hardly changes, and sure enough, various observables, such as the fidelity on the antiferromagnetic state and the qubit density are also basically constant. We could probably have reduced <code>max_bond_dim</code> even further without much consequence, but <code>max_bond_dim=1600</code> was sufficient to run simulations with much better precisions, so we did not investigate further. Recall that by default <code>precision=1e-5</code>. We now ran simulations, all with <code>max_bond_dim=1600</code> but <code>precision</code> one of <code>[1e-7,2e-7,5e-7,1e-6,2e-6,5e-6]</code> and <code>extra_krylov_tolerance=1e-5</code>. The value of <code>extra_krylov_tolerance</code> was chosen so that for <code>precision=1e-7</code>, the precision in the Lanczos algorithm was the same as the default in ITensors. Only in the below equations, let \\(\\psi_p\\) denote the state obtained for <code>precision=p</code>, then we found</p> \\[ \\langle\\psi_{1e-7}, \\psi_{1e-5}\\rangle = 0.937 \\] \\[ \\langle\\psi_{2e-7}, \\psi_{1e-5}\\rangle = 0.937 \\] \\[ \\langle\\psi_{5e-7}, \\psi_{1e-5}\\rangle = 0.937 \\] \\[ \\langle\\psi_{1e-6}, \\psi_{1e-5}\\rangle = 0.938 \\] \\[ \\langle\\psi_{2e-6}, \\psi_{1e-5}\\rangle = 0.912 \\] \\[ \\langle\\psi_{5e-6}, \\psi_{1e-5}\\rangle = 0.898 \\] <p>Notice that this list of inner products stabilizes up to 3 digits for precisions better than <code>1e-6</code>. Assuming a Hermitian operator \\(A\\) and a normalized state, we can write</p> \\[ \\langle\\psi |A | \\psi \\rangle - \\langle \\phi | A | \\phi \\rangle \\leq 4 \\| A \\| (1 - abs(\\langle \\psi, \\phi \\rangle)) \\] <p>Since \\(\\|A\\| = 1\\) if \\(A\\) is a Pauli string operator, we can specifically expect the qubit density to be accurate up to the second digit for <code>precision &lt; 1e-6</code>. This is why the qubit density was only printed for two digits at the start of this page, and from the numerics, we also find the above observation holds. The above also shows that for <code>precision &gt; 1e-6</code> we can expect variations in the qubit density in the second digit, which we also observe in the numerics. Specifically, for <code>precision &gt; 1e-6</code>, the reflection and rotation symmetries of the qubit densities only hold up the first digit. Since the qubit density at the center of the grid only differs in the second digit, precisions larger that <code>1e-6</code> were not deemed sufficient to judge whether the pulse was accurately simulated.</p> <p>Since the results obtained for <code>max_bond_dim = 1600</code>, <code>extra_krylov_tolerance=1e-5</code> and <code>precision=1e-6</code> are accurate enough for the purposes of this discussion, we did not investigate the impact of varying <code>dt</code>.</p>"},{"location":"emu_mps/advanced/errors/","title":"An explanation of the sources of error in TDVP","text":"<p>Emu-mps uses a 2nd order 2-site time-dependent variational principle to compute the time evolution of the qubit registers (see here). There are four sources of error inherent in this algorithm (see here)</p> <ul> <li>effective description of long-range terms in the Hamiltonian</li> <li>looping over pairs of qubits</li> <li>iterative computation of the 2-site effective evolution</li> <li>truncation of the state</li> </ul> <p>Let us briefly explain how each of these terms introduce errors into the simulation, and let us try to estimate their size.</p>"},{"location":"emu_mps/advanced/errors/#effective-description-of-long-range-terms-in-the-hamiltonian","title":"effective description of long-range terms in the Hamiltonian","text":"<p>The rydberg Hamiltonian is long range, so when evolving 2 neighbouring qubits in one of the TDVP steps, it is necessary to approximate terms coupling these two qubits to far away qubits. Specifically, say we are evolving the pair \\((j,j+1)\\) and the Hamiltonian contains an interaction term of the form \\(A_iB_j\\) where \\(i &lt; j-1\\), so that this interaction term is not taken into account by any of the other pair evolutions (currently only the Rydberg interaction \\(n_i n_j\\) is supported, but other interaction types will be added in the future). Then as part of the effective Hamiltonian for the pair, this interaction term shows up as \\(Tr_{&lt;j}(A_iB_j)\\), where \\(Tr_{&lt;j}\\) denotes the partial trace over the left side of the system. Unless the system is in an eigenstate of \\(A_i\\), this term will only approximate the action of the interaction term, and the error is proportional to the variance \\(Var(A_i)\\).</p> <p>For example, take the term \\(\\sigma^-_i\\sigma^+_n\\) from the XY-Hamiltonian, and assume \\(|\\psi&gt; = |1&gt;_i|0&gt;_n\\otimes \\phi\\) where \\(\\phi\\) denote the state on the other qubits, that will not impact the result in the example, other than that it must be normalized. In this case we compute \\(Tr_{&lt;n}(\\sigma^-_i\\sigma^+_n) = 0\\) because \\(\\sigma^-_i|1&gt;_i \\perp |1&gt;_i\\), and the interaction term is not taken into account. The above example was chosen to be particularly bad, since \\(\\sigma^-\\) is not diagonalizable, and \\(|\\psi&gt;\\) was as far from an eigenvector as possible, for other states, the error incurred in the approximation will be smaller. For the Rydberg interaction, which is diagonalizable, the maximum error is smaller. However, this shows that when simulating systems with long-range interactions (2d systems, for example, behave like 1d systems with long-range interactions according to the above reasoning), care should be taken that the interaction terms are properly accounted for by the TDVP scheme.</p>"},{"location":"emu_mps/advanced/errors/#looping-over-pairs-of-qubits","title":"looping over pairs of qubits","text":"<p>Even if the Hamiltonian only has nearest-neighbour interactions, so that the above error is \\(0\\), we still incur an error by repeatedly evolving a 2-site subsystem, rather than the entire system at once. Take for example the interaction term \\(A_nB_{n+1}\\), in the 2-site TDVP scheme, there are 10 time evolution steps that incorporate this interaction term:</p> <ul> <li>3 2-site time evolutions evolving either qubit \\(n\\) or \\(n+1\\) during the left-right sweep</li> <li>2 1-site time evolutions evolving either qubit \\(n\\) or \\(n+1\\) during the left-right sweep</li> <li>the same 5 time evolutions durig the right-left sweep</li> </ul> <p>Similar to how for trotterization</p> \\[ e^{-i t (A + B)} = e^{-i t A}e^{-i t B} +O(t^2) = e^{-it B / 2} e^{-i t A} e^{-i t B / 2} + O(t^3) \\] <p>so also, by sweeping left-right and then right-left, the magnitude of this error reduced is reduced from \\(O(dt)\\) to \\(O(dt^2)\\). The prefactor in the order notation depends on the bond-dimension of the state, becoming smaller as the bond-dimension grows.</p>"},{"location":"emu_mps/advanced/errors/#iterative-computation-of-the-2-site-effective-evolution","title":"iterative computation of the 2-site effective evolution","text":"<p>Each 2-site time evolution corresponds to solving a Schroedinger equation for the corresponding subsystem, which is done numerically, and incurs a corresponding numerical error. We solve the Schroedinger equation by using the Lanczos algorithm to exponentiate the effective 2-site Hamiltonian directly. This algorithm computes the vector \\(e^{i t H}\\psi\\) by iteratively constructing the vectors \\(\\{\\psi, H\\psi,..., H^n\\psi\\}\\) and exponentiating \\(H\\) on this subspace. The algorithm aboards the iterations when the estimated precision for \\(e^{i t H}\\psi\\) has been obtained (this precision can be set via the config), but experience teaches that the error is underestimated. When choosing the precision high enough, this error is negligible compared the others in described here.</p>"},{"location":"emu_mps/advanced/errors/#truncation-of-the-state","title":"truncation of the state","text":"<p>After each 2-site evolution, an SvD is applied to split the vector for the 2-site subsystem back into 2 tensors for the MPS. The behaviour of this truncation is identical to that of general MPS truncation (see here).</p> <p>As explained there, each truncation finds the smallest MPS whose norm-distance is less than the precision from the original MPS. TDVP sweeps from left two right over neighbouring pairs of qubits, and back. This means that for each timestep, <code>2*(nqubits-1)</code> truncations are performed, so by the triangle inequality, TDVP will output a state whose distance is less than <code>2*(nqubits-1)*precision</code> from the state TDVP would have output without truncation. Note that the truncation errors will not all point in the same direction, so the actual error will likely be closer to <code>sqrt(2*(nqubits-1))*precision</code>, similar to the error in a gaussian random walk. The default precision is <code>1e-5</code>, meaning that each tdvp step will likely be accurate up to order <code>1e-4</code> assuming no more than order <code>1e2</code> qubits.</p> <p>Similarly, when performing multiple TDVP steps, the maximum possible error scales linearly in the number of steps, but the error is more likely to scale as the square root of the number of time steps. Notice that there is a tradeoff when decreasing the value of \\(dt\\) between the truncation error and the other errors in this list. Decreasing \\(dt\\) means applying more truncations, which means a bigger expected error. Additionally, when \\(|e^{- i t H}\\psi - \\psi| \\approx precision\\) TDVP becomes meaningless, because each time evolution step is accompanied by a truncation that perturbs the state at least as much.</p> <p>When in doubt about the convergence of the algorithm, try to improve the precision of both truncation and the Lanczos algorithm, and also make sure that <code>max_bond_dim</code> does not truncate the state too agressively. This can be done by tweaking these parameters, and checking whether output observables like the correlation matrix and energy variance change significantly. The effective 2-site Hamiltonian used to evolve each subsystem is constructed in such a way all powers of the Hamiltonian are constants of the motion. This means that any change in the moments of \\(H(t)\\) (and specifically the expectation and variance of the energy) due to the tdvp step at time \\(t\\) is due to truncation, or the precision in the Lanczos algorithm. Regarding the correlation matrix, long-range entanglement, as signified by elements of the correlation matrix far from the diagonal, contributes strongly to the bond dimension of the MPS, so the parts of the wave function creating such entanglement are likely to be truncated away when truncation is performed too agressively. As a corrolary, observables which do not strongly depend on off-diagonal elements of the correlation matrix are less sensitive to truncation. After these considerations, when still in doubt, try to reduce \\(dt\\). When still in doubt, question whether TDVP correctly takes into account long-range interactions.</p>"},{"location":"emu_mps/advanced/hamiltonian/","title":"QPU Hamiltonian","text":"<p>In all cases we will refer to \\(H\\) as being of the form</p> \\[ H = -\\sum_j\\Delta_jn_j \\ + \\ \\sum_j\\Omega_j\\sigma^x_j \\ + \\ H_{i} \\] <p>where \\(H_i\\) is the interaction term in the Hamiltonian. Values of \\(\\Omega_j\\) and \\(\\Delta_j\\) respectively represent the amplitude and the detuning of the driving field applied to the qubit \\(j\\). Avoiding technical details we will refer to eigenstates of \\(H\\) (and in particular to the ground state) as equilibrium states.</p> <p>Although the QPU currently only supports a Rydberg interaction, emu-mps supports both the Rydberg interaction term and the XY interaction.</p> <p>The Rydberg interaction reads</p> \\[ H_{rr} = \\sum_{i&gt;j} U_{ij} n_{i}n_{j} \\] <p>where</p> \\[ U_{ij} = \\frac{C_{6}}{r_{ij}^{6}}, \\] <p>and the XY interaction reads</p> \\[ H_{xy} = \\sum_{i&gt;j} U_{ij} (\\sigma^+_{i}\\sigma^-_{j} + h.c.) \\] <p>where</p> \\[ U_{ij} = \\frac{C_{3}(1-3 \\cos^2(\\theta_{ij}))}{r_{ij}^{3}}, \\] <p>In these formulas, \\(r_{ij}\\) represents the distance between qubits \\(i\\) and \\(j\\), and \\(\\theta_{ij}\\) represents a configurable angle (see here). Currently, Pasqal quantum devices only support Rydberg interactions, and different devices have different \\(C_6\\) coefficients and support for different maximum driving amplitudes \\(\\Omega\\). Intuitively, under stronger interactions (rydberg-rydberg and laser-rydberg), bond dimension will grow more quickly (see here), thus affecting performance of our tensor network based emulator. For a list of the available devices and their specifications, please refer to the Pulser documentation (see here).</p>"},{"location":"emu_mps/advanced/noise/","title":"Noise Implementation in emu-mps","text":"<p>To faithfully emulate the Pasqal QPU using emu-mps, we need to include noise effects, as these effects cannot be neglected in a real quantum system\u2014they significantly impact the performance and fidelity of the QPU.</p> <p>In open quantum many-body systems, noise is typically expressed in terms of mixed states and noise channels using a density matrix representation. Similar to a state-vector emulator, emu-mps only handles pure states. Therefore, we implement noise using a higher order Monte Carlo method (see here), where we evolve the system using an effective Hamiltonian and then apply a quantum jump at certain times. This method is probabilistic in the sense that it approximates the simulation of a mixed state using many non-deterministic pure state simulations.</p>"},{"location":"emu_mps/advanced/noise/#noise-types","title":"Noise Types","text":"<p>Our implementation supports different types of noise:</p> <ul> <li>relaxation: due to a decay from the Rydberg to the ground state. It is parameterized by relaxation_rate.</li> <li>dephasing: due to a random phase flip (Z). It is parameterized by dephazing_rate.</li> <li>depolarizing: used as a tool to test the system under a uniform combination of phase flip (Z) and bit flip (X) errors. It is parameterized by depolarizing_rate.</li> <li>eff_noise: general effective noise channel defined by the set of collapse operators eff_noise_opers and their corresponding rates eff_noise_rates.</li> <li>SPAM errors: parameterized by state_prep_error, p_false_pos and p_false_neg.</li> </ul> <p>Users can refer to the Pulser documentation for a detailed overview of the different noise models currently available. Currently, emu-mps does not support the amplitude noise, Doppler noise and leakage.</p>"},{"location":"emu_mps/advanced/noise/#effective-hamiltonian","title":"Effective Hamiltonian","text":"<p>The non-hermitian effective Hamiltonian used in noisy emu-mps simulations includes both the physical Hamiltonian \\(H_{physical}\\), which governs the noiseless evolution of the system, and a term representing noise:</p> \\[ H_{\\text{eff}} = H_{\\text{physical}} \\ - \\ \\frac{i}{2} \\sum_m L^{\\dagger}_m L_m. \\] <p>where: - \\(H_{physical}\\) is the Hamiltonian of the noiseless system. - The second term is a sum over the Lindblad operators (<code>L</code>), which represent different types of noise.</p>"},{"location":"emu_mps/advanced/noise/#time-evolution-mechanism","title":"Time Evolution Mechanism","text":"<p>The system undergoes deterministic time evolution from time \\(t\\) to \\(t + \\delta t\\) using TDVP (see here) with the effective Hamiltonian. At the end of each evolution step, the norm of the evolved quantum state \\(\\vert \\psi (t + \\delta t)\\rangle\\) is compared to a collapse threshold, which is a random number between \\(0\\) and \\(1\\):</p> <ul> <li>If the square of the norm of the evolved state is greater than the random number, the system successfully evolves under the effective Hamiltonian \\(H_{\\text{eff}}\\) to time \\(t + \\delta t\\), and proceeds to the next time step.</li> <li>If the square of the norm of the evolved state is less than the random number, a quantum jump occurs. This can be understood as a simulation of a noise event (e.g. spontaneous emission, dephasing, etc.).</li> </ul>"},{"location":"emu_mps/advanced/noise/#warning","title":"WARNING:","text":"<p>It is important to note that the norm of the state also decreases due to truncation effects. Therefore, it is recommended to choose an appropriate precision when performing Monte Carlo simulations. Additionally, computing the collapse times may become unreliable when the maximum bond dimension chosen by the user is reached, as truncation errors can become difficult to control.</p>"},{"location":"emu_mps/advanced/noise/#locating-the-quantum-jump","title":"Locating the Quantum Jump","text":"<p>To determine when a quantum jump occurs between time \\(t\\) and \\(t + \\delta t\\), the TDVP is applied multiple times (both forward and backward in time) to approximate the collapse time. During this process, the norm of the evolved state is checked and compared to the collapse threshold. This evolution procedure is repeated until the norm converges to the collapse threshold.</p>"},{"location":"emu_mps/advanced/noise/#applying-the-quantum-jump","title":"Applying the Quantum Jump","text":"<p>Once the time of collapse is located, a Lindblad operator is randomly applied to a qubit (based on the collapse weight), then the evolution of the normalized state is continued to complete the time step of size \\(\\delta t\\).</p> <p>Upon completion of the current time step, the time evolution continues with the next step.</p>"},{"location":"emu_mps/advanced/noise/#physical-interpretation-spontaneous-emission-in-the-two-level-system","title":"Physical Interpretation: Spontaneous Emission in the Two-Level System","text":"<p>To better understand how the quantum jump process describes a physical event (noise) which occurs during time evolution, let us consider a two-level system initially in the state \\(\\vert \\psi(t)\\rangle = \\alpha\\vert g\\rangle + \\beta \\vert e\\rangle\\), where \\(\\alpha\\) and \\(\\beta\\) are complex coefficients. By setting both the amplitude and detuning to zero, \\(\\Omega = \\delta = 0\\), we can then ask what happens in a single step depending on whether a spontaneously emitted photon occurs or not. For this, we examine a single quantum jump operator \\(L = \\sqrt{\\Gamma}\\vert g\\rangle\\langle e\\vert\\), and an effective Hamiltonian \\(H_{eff} = -i(\\Gamma/2)\\vert e\\rangle\\langle e\\vert\\).</p> <p>If a quantum jump occurs in a time step \\(\\delta t\\), then the state following the jump becomes $$ \\vert \\psi(t+\\delta t)\\rangle \\ = \\ \\frac{L\\vert\\psi(t)\\rangle}{\\vert\\vert L \\vert \\psi(t)\\rangle\\vert\\vert} \\ = \\ \\vert g\\rangle. $$</p> <p>In other words, when a spontaneous emission event occurs, the evolved state of the system collapses onto the ground state \\(\\vert g\\rangle\\). This demonstrates how noisy events, like spontaneous emission, can alter the dynamics of a quantum system, even in the absence of direct observation of emitted photons.</p>"},{"location":"emu_mps/advanced/resource_estimation/","title":"Estimating Memory Consumption and Runtime","text":"<p>The presence of the <code>max_bond_dim</code> and <code>max_krylov_dim</code> config parameters means an upper bound on memory consumption and the complexity of the time evolving algorithm can be estimated. By limiting the <code>max_bond_dim</code> of a simulation to make it fit in the available hardware memory, it can be guaranteed to run for arbitrary times for an arbitrary number of qubits. Of course, the sources of error described on the error page imply that limiting the memory consumption of the program will negatively impact the quality of the results once a certain threshold is exceeded. The page in this link, for example, outlines a case study to determine whether emulation results are accurate.</p>"},{"location":"emu_mps/advanced/resource_estimation/#estimating-the-memory-consumption-of-a-simulation","title":"Estimating the memory consumption of a simulation","text":"<p>In this section we outline how to estimate the memory consumption of a simulation, for a given <code>max_bond_dim</code>, a Krylov subspace of size <code>max_krylov_dim</code>, and for \\(N\\) being the number of qubits to be simulated. There are four contributions to the peak memory consumption of emu-mps that will be discussed in the next sections:</p> <ul> <li>the state</li> <li>the baths</li> <li>the Krylov space</li> <li>temporary tensors</li> </ul>"},{"location":"emu_mps/advanced/resource_estimation/#contribution-from-the-state","title":"Contribution from the state","text":"<p>The quantum state is stored in MPS format (see here). At worst, the bond dimensions of the tensors in an MPS grow exponentially inwards as</p> \\[ 2,4,8,16...,16,8,4,2 \\] <p>in which case an MPS will take more memory than a state vector. Let \\(\\chi\\) denote the value of <code>max_bond_dim</code>. When \\(\\chi&lt;2^{N/2}\\), the bond dimensions in the center all cap at that fixed value of <code>max_bond_dim</code>.  Since each tensor in the MPS has 2 bonds of size at most \\(\\chi\\), and a physical index of size \\(p=2\\), where each element in the tensor takes \\(s=16\\) bytes (2 8-byte floats to store a complex number), the memory consumption of the state reads</p> \\[ |\\psi| &lt; spN\\chi^2 = 32N\\chi^2 \\] <p>Note that this is a strict over-estimation because the outer bonds in the MPS will be much smaller than \\(\\chi\\).</p>"},{"location":"emu_mps/advanced/resource_estimation/#contribution-from-the-baths","title":"Contribution from the baths","text":"<p>For TDVP, for each qubit a left and a right bath tensor is stored. The bath tensors are used to compute an effective interaction between the 2-qubit subsystem being evolved, and the rest of the system (see here). Each of them has 3 indices. Two of them will have a size that depends on the state that is evolved, here upper bounded by the maximum allowed value \\(\\chi\\) for the bond dimension. For the third, the size \\(h\\) will depend on the interaction type. In concrete, for each qubit, \\(h\\) will be the bond dimension of the MPO representation of the Hamiltonian. In summary, for the Rydberg Hamiltonian we expect that \\(h=2+\\text{floor}(n/2)\\), and for the XY Hamiltonian that \\(h=2+2\\text{floor}(n/2)\\), where in both cases \\(n=\\text{min}(i,N-i)\\) for the bath associated with the qubit \\(i\\). The computation is slightly involved, but summing all the contributions leads to a total memory occupation of the baths:</p> \\[ |\\mathrm{bath}| &lt; Ns\\chi^2h = 4\\chi^2N(N+10) \\] <p>Note that the baths take up more memory than the state, always, and potentially much more. Furthermore, just as for the state this is a strict over-estimation, because it assumes all the bonds in the state are of size \\(\\chi\\).</p>"},{"location":"emu_mps/advanced/resource_estimation/#contribution-from-the-krylov-space","title":"Contribution from the Krylov space","text":"<p>The remainder of the memory consumption is to compute the time-evolution of qubit pairs in TDVP. This is done by contracting 2 tensors from the MPS together into a single 2-qubit tensor, and time-evolving it by applying an effective Hamiltonian constructed from the baths and the Hamiltonian MPO. Each 2-qubit tensor has a size bounded by \\(sp^2\\chi^2\\), so the memory of the Krylov vectors used in the Lanczos algorithm reads</p> \\[ |\\mathrm{krylov}| \\leq ksp^2\\chi^2 = 64k\\chi^2 \\] <p>where \\(k\\) is the value of <code>max_krylov_dim</code>. Recall that the default value of \\(k=100\\) and if the Lanczos algorithm requires more Krylov vectors to converge to the tolerance, it will error, rather than exceed the above bound.</p>"},{"location":"emu_mps/advanced/resource_estimation/#contribution-from-temporary-tensors","title":"Contribution from temporary tensors","text":"<p>Finally, to compute the above Krylov vectors, the effective two-site Hamiltonian has to be applied to the previous Krylov vector to obtain the next one. The resulting tensor network contraction cannot be done in-place, so it has to store two intermediate results that get very large. The intermediate results take the most memory at the center qubit, where the bond dimension of the Hamiltonian becomes \\(h\\), where</p> \\[ |\\mathrm{intermediate}| = 2*shp^2\\chi^2 = 128h\\chi^2 \\] <p>It should be noted that the value of \\(h\\) cited above assumes that all qubits in the system interact via a two-body term, which is technically true for the Rydberg interaction.</p>"},{"location":"emu_mps/advanced/resource_estimation/#benchmarking-memory-footprint","title":"Benchmarking memory footprint","text":"<p>Putting all of this together, for the total memory consumption \\(m\\) of the program, we can write the following bound:</p> \\[  m(N,\\chi,k) = |\\psi| + |\\mathrm{bath}| + |\\mathrm{krylov}| + |\\mathrm{intermediate}| &lt; 32N\\chi^2 + 4\\chi^2N(N+10) + 64*k*\\chi^2 + 64(N+4)\\chi^2 = 4\\chi^2[N(N+34) + 16k + 64] \\] <p>Note that this estimate is pessimistic, since not all \\(k\\) Krylov vectors are likely to be needed, and not all tensors in \\(\\psi\\) and the baths have the maximum bond dimension \\(d\\). On the other hand, the estimate for \\(|intermediate|\\) is likely to be accurate, since the bond dimension of \\(\\chi\\) is probably attained at the center qubit.</p> <p>To test the accuracy of the above memory estimations, we run the TDVP time evolution algorithm, fixing the bond dimension to a particular desired value. For different combinations of the number of atoms in a register \\(N\\) and the fixed bond dimension \\(chi\\), we collect the maximum resident size, or RSS, which is expected to capture the maximum memory needed to run the emulation. We plot the RSS in the following picture (left), as a function of the number of qubits and for different bond dimensions. Notice that, once the RSS is normalized by \\(\\chi^2\\), as suggested by our estimate above, all the points fall into the same functional dependency on the number of atoms. Moreover, as we plot the normalized function \\(m(N,\\chi,k)/\\chi^2\\), for a reasonable estimate of the size of the Krylov subspace (\\(k=30\\)), it is clear that our upper bound on memory occupation can be reasonably trusted on a wide range of qubit number and bond dimensions.</p> <p> </p> <p>Finally, having established an estimate for the memory consumption, it makes sense to explore what are the available regimes of qubits/bond dimension can be reached for a given hardware capability. Since all heavy simulations will be run on an NVIDIA A100 (on Pasqal's DGX cluster), we have 40 GB of available memory. Therefore, above, we show (right image) the contour lines of the RSS estimate \\(m(N,\\chi,k=30) &lt; 40\\) GB for particular useful values of the total memory, allowing to quickly estimate the memory footprint of an emu-mps emulation.</p>"},{"location":"emu_mps/advanced/resource_estimation/#an-example","title":"An example","text":"<p>For example, the results from the case study were obtained using \\(N=49\\) and \\(d=1600\\) on 2 GPUs. Taking the above formula, and halving the contributions from \\(\\psi\\) and \\(|\\mathrm{bath}|\\) since they are split evenly on the GPUs, we reproduce the memory consumption of the program for \\(k=13\\). Notice that the actual number of Krylov vectors required to reach convergence is likely closer to around \\(30\\), but here we underestimate it, since the contributions of \\(\\psi\\) and \\(|\\mathrm{bath}|\\) are over-estimated.</p>"},{"location":"emu_mps/advanced/resource_estimation/#estimating-the-runtime-of-a-simulation","title":"Estimating the runtime of a simulation","text":"<p>Similarly to the previous section, here, we briefly estimate the complexity of the two-site TDVP algorithm we use to time evolve the state in a single pulse sequence step. As before, the two relevant computational steps are</p> <ul> <li>Computing the baths</li> <li>Applying the effective Hamiltonian</li> </ul> <p>In both cases, it will boil down to an exercise in complexity estimation of tensor network contractions. For simplicity, as before, we will restrict to the worst case scenario in which the bond dimension \\(\\chi\\) always take the maximum allowed value. Importantly, another significant contribution to the runtime can come from computing complex observables like two-point correlation functions, which is not included here.</p>"},{"location":"emu_mps/advanced/resource_estimation/#contribution-from-the-baths_1","title":"Contribution from the baths","text":"<p>Roughly, baths computation involves the represented tensor network contraction:</p> <p></p> <p>Each of these tensor multiplication takes respectively \\(O(ph\\chi^3)\\), \\(O(p^2h^2\\chi^2)\\), and \\(O(ph\\chi^3)\\). In an all-to-all Rydberg interaction, we already argued that the bond dimension of the Hamiltonian MPO should scale as the number of atoms. Moreover, the left and right baths need to be computed roughly N times, thus the overall expected complexity is \\(O(N^2\\chi^3) + O(N^3\\chi^2)\\).</p>"},{"location":"emu_mps/advanced/resource_estimation/#contribution-from-the-effective-hamiltonian","title":"Contribution from the effective Hamiltonian","text":"<p>Applying the effective two-body Hamiltonian is slightly a more involved tensor network contraction:</p> <p></p> <p>In steps, it is composed by applying:</p> <ul> <li>the left bath: \\(O(p^2h\\chi^3)\\)</li> <li>a two-body term coming form the MPO Hamiltonian: \\(O(p^4h^2\\chi^2)\\)</li> <li>the right bath: \\(O(p^2h\\chi^3)\\)</li> </ul> <p>As before, for an all-to-all Rydberg interaction we expect \\(h\\sim N\\). Moreover, the effective Hamiltonian application needs to be done \\(k\\) times, to build the appropriate Krylov subspace, and for every pair. Finally, to complete the time evolution and bring back the tensors of the state into an MPS form, a final singular value decomposition is required. For every pair, this requires \\(O(N\\chi^3)\\) to be done. Overall, the expected complexity is thus \\(O(kN^2\\chi^3) + O(kN^3\\chi^2) + O(N\\chi^3)\\).</p>"},{"location":"emu_mps/advanced/resource_estimation/#benchmarking-runtime","title":"Benchmarking runtime","text":"<p>From the previous complexity estimations, we thus expect the complexity of the two-sites TDVP algorithm to have two main contributions</p> \\[\\Delta t_{\\text{TDVP}}(N,\\chi,k)\\sim \\alpha N^2\\chi^3 + \\beta N^3\\chi^2\\] <p>To check such estimation, as before, we run TDVP multiple times, measuring the average runtime to perform a step. Below, we show the obtained results for different number of atoms in a register \\(N\\) at fixed bond dimension \\(\\chi\\) (left), and at different fixed \\(N\\) but increasing the bond dimension (left). On top of these data points, we also plot the resulting fit of the complexity estimation presented in the equation above. Remarkably, with just two parameters \\(\\alpha\\) and \\(\\beta\\) with get good agreement.</p> <p> </p> <p>To wrap up, and to provide an useful tool for runtime estimation for emu-mps, the time to perform a single  time step in a sequence can be conveniently visualized (below) for both \\(N\\) and \\(\\chi\\) on contour lines.</p> <p></p> <p>Superimposing the 40 GB hardware constrain derived in the previous section, it is easy to see that in worst-case scenario, a TDVP step will take roughly 250 seconds to be computed.</p>"},{"location":"emu_mps/advanced/tdvp/","title":"Summary of the TDVP algorithm","text":"<p>Emu-mps uses a second order 2-site TDVP to compute the time-evolution of the system (see here for details). Briefly, the algorithm repeatedly computes the time-evolution for 2 neighbouring qubits while truncating the resulting MPS to keep the state small. It does this by</p> <ul> <li>evolving qubit 1 and 2 forwards in time by \\(dt/2\\)</li> <li>evolving qubit 2 backwards by \\(dt/2\\)</li> <li>evolving qubit 2 and 3 forwards in time by \\(dt/2\\)</li> </ul> <p>...</p> <ul> <li>evolving qubit \\(n-1\\) and \\(n\\) forward in time by \\(dt\\)</li> <li>evolving qubit \\(n-1\\) backwards in time by \\(dt/2\\)</li> <li>evolving qubit \\(n-2\\) and \\(n-1\\) forward in time by \\(dt/2\\)</li> </ul> <p>...</p> <ul> <li>evolving qubit 1 and 2 forwards in time by \\(dt/2\\)</li> </ul> <p>The fact that we sweep left-right and the right-left with timesteps of \\(dt/2\\) makes this a second-order TDVP.</p>"},{"location":"emu_mps/advanced/mps/","title":"The MPS representation of a state","text":"<p>As opposed to state vector solvers (of the Master/Schr\u00f6dinger equation), tensor network based approaches use adaptive data structures, which in the case of emu-mps are called matrix product state/operator (MPS/MPO). They are adaptive in the sense that the memory used to store such a state/operator does not only depend on the dimension of the state space, but also on the specific state you're trying to represent. In many relevant use cases, this makes representation more memory-efficient, which allows pushing for higher number of qubits compared to state vector solvers. However, it has the drawback that the cost of the simulation is less predictable since there is no a priori method to know how much information is going to be relevant at the next step of the solver. The are configurable hard caps on memory consumption built into emu-mps (see here), but when these are hit it becomes necessary to check for validity of the results (see here).</p> <p>The take-home message is that a reasonable way to assess emu-mps performance is by benchmarking relevant and meaningful sequences/use-cases (see here).</p>"},{"location":"emu_mps/advanced/mps/#bond-dimension","title":"Bond dimension","text":"<p>Please, have a look at http://tensornetwork.org/mps/ for a more general introduction to matrix product states.</p> <p>The MPS is the best understood factorization of an arbitrary tensor, for which many efficient algorithms have been developed. For a quick understanding, in tensor diagram notation, let's consider the wavefunction of \\(N\\) qubits:</p> <p></p> <p>Alternatively, the MPS of the state can be expressed in traditional notation as</p> \\[ |s_1 s_2\\dots s_N\\rangle = \\sum_{\\{\\alpha\\}}A^{s_1}_{\\alpha_1}A^{s_2}_{\\alpha_1\\alpha_2}\\dots A^{s_N}_{\\alpha_N} \\] <p>The state is therefore is represented as a product of tensors. The contracted (or summed over) indices \\(\\{\\alpha\\}\\) are called bond indices and their dimension (the bond dimension) can vary from bond to bond.</p> <p>The bond dimension required to perfectly represent a state depends on its entanglement (roughly, how much quantum information is stored in it). Up to this limit, a higher bond dimension will mean that the state is represented more faithfully. However, a higher bond dimension also implies that size of the state will be bigger, thus making the emulation more expensive.</p> <p>As a consequence, the real power of the MPS representation is that the bond dimension, \\(\\chi= dim(\\alpha)\\), gives us an additional knob to control how much information about the state we want to capture. Many relevant states can already be represented faithfully using less memory than a state vector, but by restricting \\(\\chi\\) further, additional memory savings are possible, potentially without loss of simulation quality (see here).</p>"},{"location":"emu_mps/advanced/mps/#truncation-of-the-state","title":"Truncation of the state","text":"<p>After each 2-site evolution (see here), an SvD is applied to split the state vector for the 2-site subsystem back into two tensors for the MPS. The number of singular values give the dimension of the bond connecting the 2 qubits in the MPS. To keep the memory consumption of the state in check, the set of singular values is truncated as per the <code>precision</code> and <code>max_bond_dim</code> arguments in the config.</p> <p>Of these two parameters, <code>precision</code> is the most physically relevant. Whenever truncation occurs, the smallest singular values are thrown away until doing so would increase the norm distance between the original and truncated states above <code>precision</code>. Notice that this does not give any guarantees on the state size after truncation. However, for a given <code>precision</code>, clear bounds can be given on the truncation error incurred by the simulation (see here) in terms of norm distance. This in turn can be used to derive upper bounds on the error incurred in various observables outputted by the simulation.</p> <p>The <code>max_bond_dim</code> argument, on the other hand gives strong memory consumption guaranteed. Whenever truncation occurs, the smallest singular values are thrown away until at most <code>max_bond_dim</code> values remain, even if this would cause the norm distance between the original and truncated states to exceed the <code>precision</code>. This means the <code>max_bond_dim</code> takes precedence over <code>precision</code> and imposes a hard cap on the memory consumption of the program. Since all the matrices involved in the simulation are also constrained in size, lowering <code>max_bond_dim</code> also benefits the runtime fo a simulation. The drawback is that the error cannot be estimated anymore a priori, so when the <code>max_bond_dim</code> is hit by the simulation, extra care needs to be taken that the simulation results are still accurate.</p>"},{"location":"emu_mps/benchmarks/","title":"emu-mps benchmarks","text":"<p>All the benchmarks are run on a single NVIDIA A100 GPU of Pasqal's DGX-cluster and for best performance on heavy workloads we recommend using a similar setup. There, users should expect emu-mps to emulate up to</p> <ul> <li>30 atoms for quenches</li> <li>50 atoms for adiabatic sequences</li> </ul> <p>for 2D systems and for realistic pulse sequences (~\u03bcs) that can be run on the QPU. For these relevant hard use-cases, described in more detail in the next section, the bond dimension is let to grow free to achieve the desired precision.</p> <p>In all other scenarios, for specific combinations of number of qubits \\(N\\) and bond dimension \\(\\chi\\), the resources needed to emulate a sequence can be estimated by providing some upper bounds to:</p> <ul> <li>RSS: the resident set size, i.e. the maximum needed memory</li> <li>\\(\\langle\\Delta t\\rangle\\): GPU time to do a single step in the time evolution</li> </ul> <p>These quantities are represented, in the following plots:</p> <p> </p> <p>The RSS plot (left) shows the peak memory cost of the emulation. It is expected to stay constant at fixed bond dimension and thus represent the total memory occupation of the emulation of a sequence. As evident, the emulator is mostly limited by the available memory (40 GB on NVIDIA A100), as it restricts the maximum number of qubits/bond dimension pair allowed. To get the total estimated runtime instead, one should simply multiply the time estimate in the timing plot (right) by the number of steps in the emulated sequence. Finally, given the technical nature of these estimates, they rely on some previous knowledge about matrix product states and the TDVP algorithm. We encourage anyone who might be interested into the derivation, to have a look at the resource estimation page in advanced topic section of this documentation.</p> <p>While the simple resource estimation provided above allows to upper bound the memory/time cost of an emulation, a final very important remark has to be made. If during an emulation, the bond dimension reach a user-set maximum value (with the <code>max_bond_dim</code> argument), the accuracy of the subsequent results of the time evolution cannot be guaranteed anymore, as discussed here.</p> <p>Having sketched up the expected performance, in the next section, we make those statements more concrete by providing more details about use-cases benchmarks. Concretely, we will discuss the relevant register/ pulse sequences and the performance metrics of choice.</p>"},{"location":"emu_mps/benchmarks/#use-case-benchmarks","title":"Use-case benchmarks","text":"<p>Benchmark efforts, documented here, are meant to provide insights for emu-mps users about</p> <ul> <li>Performance: runtime, memory usage, bond dimension as a function of qubit number (see here)</li> <li>Accuracy: different precision levels as compared to state vector solvers</li> </ul> <p>given a set of meaningful sequences of interest (quench, adiabatic and use-case sequences) that we are going to introduce case by case. Finally, we will only focus on 2D atomic registers as they represent the most numerically challenging and interesting case to study.</p> <p>The benchmarks are ordered in subpages by general topic.</p> <ul> <li>Accuracy</li> <li>Performance</li> <li>Noise</li> </ul> <p>The accuracy benchmarks compare results between emulators to create confidence in the results emu-mps generates. The performance benchmarks exist to exhibit the runtime and memory consumption characteristics of emu-mps. Based on these, the reader should get a feel for what kind of parameters would be required to be able to run a given sequence in a given time. Note that this is independent of whether the emulation results are actually accurate (see here). Finally, the noise page presents benchmarks regarding noisy simulations, focusing on effects specific to noise that are not already covered in the other pages.</p>"},{"location":"emu_mps/benchmarks/#sequences-used","title":"Sequences used","text":"<ul> <li>Adiabatic evolution: Here at each time step, the evolution of the driving \\(\\Omega, \\Delta\\) is slow enough to guarantee that the evolved state is still an equilibrium state of \\(H\\). Note that the adiabaticity of a sequence is dependent on the energy gaps in the Hamiltonian, and since these gaps decrease with qubit number, most sequences are only adiabatic up to a given qubit number.</li> </ul> <pre><code># from https://pulser.readthedocs.io/en/stable/tutorials/afm_prep.html\n# parameters in rad/\u00b5s and ns\nOmega_max = 2.0 * 2 * np.pi\nU = Omega_max / 2.0\ndelta_0 = -6 * U\ndelta_f = 2 * U\nt_rise = 500\nt_fall = 1000\nt_sweep = (delta_f - delta_0) / (2 * np.pi * 10) * 3000\nR_interatomic = MockDevice.rydberg_blockade_radius(U)\nreg = Register.rectangle(rows, columns, R_interatomic, prefix=\"q\")\nif perm_map:\n    reg_coords = reg._coords\n    reg = Register.from_coordinates([reg_coords[i] for i in perm_map])\nrise = Pulse.ConstantDetuning(RampWaveform(t_rise, 0.0, Omega_max), delta_0, 0.0)\nsweep = Pulse.ConstantAmplitude(\n    Omega_max, RampWaveform(t_sweep, delta_0, delta_f), 0.0\n)\nfall = Pulse.ConstantDetuning(RampWaveform(t_fall, Omega_max, 0.0), delta_f, 0.0)\nseq = Sequence(reg, MockDevice)\nseq.declare_channel(\"ising\", \"rydberg_global\")\nseq.add(rise, \"ising\")\nseq.add(sweep, \"ising\")\nseq.add(fall, \"ising\")\n</code></pre> <ul> <li>Quench: One of the most fundamental protocols to drive a system out of equilibrium, it is realized here as follows: at time \\(t=0\\) the system is prepared in the ground state \\(|\\psi_0\\rangle\\) of \\(H_0\\). The driving field is then suddenly turned on (\\(\\Omega\\neq0\\)) and the system is evolved for \\(t &gt; 0\\), as \\(|\\psi\\rangle=e^{-iHt}|\\psi_0\\rangle\\).</li> </ul> <pre><code>hx = 1.5  # hx/J_max\nhz = 0  # hz/J_max\nt = 1.5  # t/J_max\n# Set up Pulser simulations\nR = 7  # \u03bcm\nreg = Register.rectangle(nx, ny, R, prefix=\"q\")\n# Conversion from Rydberg Hamiltonian to Ising model\nU = AnalogDevice.interaction_coeff / R**6  # U_ij\nNN_coeff = U / 4\nomega = 2 * hx * NN_coeff\ndelta = -2 * hz * NN_coeff + 2 * U\nT = np.round(1000 * t / NN_coeff)\nseq = Sequence(reg, MockDevice) #circumvent the register spacing constraints\nseq.declare_channel(\"ising\", \"rydberg_global\")\n# Add the main pulse to the pulse sequence\nsimple_pulse = Pulse.ConstantPulse(T, omega, delta, 0)\nseq.add(simple_pulse, \"ising\")\n</code></pre> <p>These two types of driving typically complement each other. Since the matrix product state approach in emu-mps strives to minimize the stored information, keeping track of a single equilibrium state in adiabatic time evolution is typically easier. While this single state can be a complicated object itself, quenches, driving the system out of equilibrium, involve taking into account multiple excited states, and are typically computationally harder to emulate.</p>"},{"location":"emu_mps/benchmarks/#cpugpu-hardware","title":"CPU/GPU hardware","text":"<p>Emu-mps is built on top of pytorch. Thus, it can run on most available CPUs and GPUs, from a laptop to a cluster. The presented benchmarks are run on an NVIDIA DGX cluster node, requesting the following resources</p> <ul> <li>GPU: 1 NVIDIA A100 (40 GB)</li> <li>CPU: a benchmark-dependent number of cores on an AMD EPYC 7742</li> </ul> <p>Of course, performance will vary depending on the hardware. For this reason, if at any point of your work, performance becomes critical, we always recommend to use Pasqal's DGX cluster. If you intend to run emu-mps on your laptop, for example, please be aware that the suggestion to use a GPU for heavier workloads might not be valid. In such case it is always good to check performance on a couple of runs, changing the emu-mps config default values as documented in the API. In particular <code>num_gpus_to_use = 0</code> will run the emulation on CPU, while <code>num_gpus_to_use \u2265 1</code> on GPU/s.</p>"},{"location":"emu_mps/benchmarks/accuracy/","title":"Accuracy","text":"<p>Here we discuss the emulator accuracy, as compared to Pulser state vector solver backend, but in the future we might directly compare with QPU results. Accuracy, here, specifically refers to observables:</p> <ul> <li>Energy: \\(E = \\langle\\psi|H|\\psi\\rangle\\)</li> <li>Energy variance: \\(\\Delta E = \\langle\\psi|H^2|\\psi\\rangle-E^2\\)</li> <li>Magnetization: \\(\\langle P_{0}^j\\rangle\\) where \\(P_{0}^j\\) projects qubit \\(j\\) onto the \\(|0\\rangle\\) state</li> </ul> <p>The emulated sequences are going to be the same as before, an adiabatic and a quench. In both cases, 9 qubits arrayed in a 3x3 grid are used, so that the results can also be simulated in Pulser. We will check accuracy against two main tunable parameters in emu-mps:</p> <ul> <li><code>precision</code><sup>[1]</sup>: at each step, throw away components of the state whose sum weighs less that the specified precision.</li> <li><code>dt</code>: sampling time step of the sequence.</li> </ul> <p>The goal is to show that for qubit numbers accessible to Pulser, the results are identical up to good precision.</p> <p> </p> <p>Both sequences are emulated multiple times by varying both the precision and time step. Notice that any deviations from Pulser for the adiabatic sequence are impossible to detect at the scale of the graph for a wide range of emulation parameters. For larger qubit numbers, such as the 7x7 grid, the question of convergence is much subtler (see here). Rather, what is interesting there, is that even for a 2d system, emu-mps correctly treats the Rydberg interaction, regardless of the effective description of long-range interaction terms that emu-mps uses.</p> <p>For the quench sequence, agreement with Pulser is still good for all shown parameter combinations, with the possible exception of the yellow curve, which has a deviation of 1%. For the quench sequence, the energy and energy variance are conserved quantities, meaning that all variation therein come from errors. Even though the relative errors are small, it's instructive to analyze the sources of these errors. For example, we see that emu-mps incurs the biggest error at the start of the emulation, when the bond dimension is still small (the bond dimension starts at 1, and increases from there). For a time-constant Hamiltonian, all deviations in the mean and variance of the energy come from truncation, and as expected, improving the precision reduces the error in the energy variance (see here). Finally, as explained in error sources in TDVP (see here), we see that reducing \\(dt\\) below a threshold (somewhere in the range of 1-5) causes a quick growth of the truncation errors, which requires improving the precision.</p> <p>The errors incurred by emu-mps can be contrasted with Pulser, which uses a generic ODE solver backend that does not take into account constants of the motion. Both the mean and variance of the energy exhibit a deviation from their initial value that is linear in the number of time-steps taken by the solver.</p>"},{"location":"emu_mps/benchmarks/accuracy/#effect-of-qubit-ordering","title":"effect of qubit ordering","text":"<p>On the performance benchmarks page, we show how a good qubit ordering can improve performance. Here we will show that a good qubit ordering also improves the accuracy of emu-mps significantly. For the purposes of the demonstration, we use a custom 12-qubit pulse as follows:</p> <pre><code>mock_device = AnalogDevice\nduration = 6000\namplitude_maximum = np.pi\ndelta = np.pi\nreg = pulser.register.Register.rectangle(3, 4, spacing=5)\nseq = Sequence(reg, mock_device)\nseq.declare_channel(\"ryd_glob\", \"rydberg_global\")\nrise_duration = duration / 3\nfall_duration = duration / 3\nsweep_duration = duration - rise_duration - fall_duration\nrise = pulser.Pulse.ConstantDetuning(\n    RampWaveform(rise_duration, 0.0, amplitude_maximum), -delta, 0.0\n)\nsweep = pulser.Pulse.ConstantAmplitude(\n    amplitude_maximum, RampWaveform(sweep_duration, -delta, delta), 0.0\n)\nfall = pulser.Pulse.ConstantDetuning(\n    RampWaveform(fall_duration, amplitude_maximum, 0.0), delta, 0.0\n)\namp = CompositeWaveform(rise.amplitude, sweep.amplitude, fall.amplitude)\ndet = CompositeWaveform(rise.detuning, sweep.detuning, fall.detuning)\npulse = pulser.Pulse(amp, det, 0)\nseq.add(\n    pulse,\n    \"ryd_glob\",\n    protocol=\"no-delay\",\n)\n</code></pre> <p>The register spacing is immaterial because we run the sequence twice with a custom interaction matrix. We will plot the difference between the two corralation matrices at the end of the sequence for various parameters. The two interaction matrices contain only <code>0</code> and <code>1</code>, where the ones are between qubit pairs</p> <p><code>[(6, 7), (8, 9), (10, 11), (7, 0), (7, 3), (9, 1), (9, 5), (11, 3), (11, 5), (6, 1), (6, 2), (8, 0), (8, 4), (10, 2), (10, 4)]</code></p> <p>and</p> <p><code>[(6, 7), (8, 9), (10, 11), (7, 1), (7, 3), (9, 1), (9, 5), (11, 3), (11, 5), (6, 0), (6, 2), (8, 0), (8, 4), (10, 2), (10, 4)]</code></p> <p>respectively. As can be seen, only two of the interaction terms are different <code>(6,1) -&gt; (6,0)</code> and <code>(7,0) -&gt; (7,1)</code>, causing the correlation matrices to be extremely similar, requiring good accuracy for the simulation. Furthermore, since the two differing terms are \"long range\", these form a good stress test for emu-mps, which uses an effective description of such long-range terms. The results are as follows:</p> <p>Emu-sv is used as a source of truth. The most salient feature is that the shown difference is largest on the  <code>(6,1)</code>, <code>(6,0)</code>, <code>(7,0)</code> and <code>(7,1)</code> terms which are precisely the terms in the interaction matrix that have been changed. The checkerboard pattern is explained because while one interaction term is added, the other is removed, causing opposite signs in the difference. Then, to subleading order, you can see repeats of this effect as the changed interaction matrix causes further differences in the correlation structure. It can be seen that for a precision of <code>1e-7</code> emu-mps is not able to capture the differences in correlation at all without reordering: the difference between the two correlation matrices is essentially zero (see top right in the figure). As explained above, terms in the interaction matrix far from the diagonal are difficult to capture for emu-mps. Notice that qubit reordering alleviates this problem, and although agreement with emu-sv is not exact, the fundamental structure of the problem is visible. The same is true for a precision <code>1e-6</code> but the errors in emu-mps will be somewhat larger. Setting the precision to <code>1e-8</code> causes emu-mps to capture the long-range correlations more accurately, even without qubit reordering. It should be noted that in this case, qubit reordering still has positive effects. Firstly, the bond dimension required to accurately describe the quantum state will be lower, decreasing the runtime. Secondly, the results with qubit ordering are much more stable than those without. For example, when running the simulation without qubit ordering the results are hardware dependent: there is a noise of a similar magnitude as for precision <code>1e-7</code> without reordering, which just happens to be negligible on the AMD EPYC 7742 where this graph was generated. This problem vanishes when qubit reordering is used, and demonstrates the fundamental instability of TDVP in the presence of long-range interactions.</p>"},{"location":"emu_mps/benchmarks/noise/","title":"Noise","text":"<p>Here, we analyze the time evolution of a quantum state using the adiabatic sequence <sup>[1]</sup> under the influence of depolarizing noise. Typically, quantum systems are affected by interactions with their surrounding environment, making them open systems. To model the dynamics of such noisy quantum systems, one typically solves the Lindblad \"Master\" equation, which governs the time evolution of the density matrix, \\(\\rho\\).</p> <p>The following plot illustrates the time evolution of the initial state under the adiabatic \\(2\\text{D}\\) sequence. This is done by tracking the evolution of the energy (top left), variance (bottom left), and magnetization (top and bottom right) in the presence of depolarizing noise for a \\((2\\times2)\\) qubit register (\\(4\\) qubits). Specifically, we compare results from two different methods:</p> <ul> <li> <p>Pulser: explicitly solves the Lindblad Master equation, obtaining full information about the noise in the system through its probability distribution in phase space, as given by the density matrix</p> </li> <li> <p>emu-mps: uses a Monte Carlo (MC) method to probe the noise by obtaining sample statistics from its underlying probability distribution (see noise.md for further details).</p> </li> </ul> <p>The goal of this study is to demonstrate that the results obtained using the Monte Carlo method implemented in emu-mps are qualitatively similar to those found by solving the Lindblad master equation in Pulser.</p> <p></p> <p>The key advantage of the Monte Carlo method, if the Hilbert space of \\(N\\) qubits has dimension \\(dim(H) = d^N\\)\u200b, then propagating the density matrix using the Lindblad equation requires handling an object of size \\([dim(H)]^2\\)\u200b. In contrast, the stochastic sampling of states with emu-mps involves the propagation of state vectors of size \\(dim(H)\\) only. This drastically reduces the memory cost of the simulation, especially when the number of qubits is large. In return, the Monte Carlo method requires performing many runs if sample statistics are desired.</p>"},{"location":"emu_mps/benchmarks/noise/#accuracy-of-the-method","title":"Accuracy of the method","text":"<p>In this study, we consider two different depolarization noise rates: \\(0.2\\) and \\(0.5\\). These represent different levels of interaction with the environment, with \\(0.5\\) introducing stronger noise effects than \\(0.2\\). For the emu-mps simulations, the following parameters are used:</p> <ul> <li> <p>Monte Carlo runs: 100</p> </li> <li> <p>Precision: \\(10^{-6}\\), which is better than the default value (\\(10^{-5}\\)), as recommended in the warning found here.</p> </li> </ul> <p>Since the Monte Carlo method in emu-mps relies on stochastic sampling, the number of Monte Carlo runs chosen by the user determines the accuracy of the simulation. Each data point (e.g., in the energy plot) in the emu-mps results represents the statistical average observable value across all Monte Carlo runs at a given time \\(t\\). The plots demonstrate that with \\(100\\) Monte Carlo runs, emu-mps already yields qualitative agreement with Pulser. We expect that, increasing the number of Monte Carlo runs should smoothen the emu-mps curves further, leading to even closer agreement with the Pulser method.</p> <p>The overall energy of the system initially rises due to the presence of depolarizing noise, which introduces interactions between the system and the environment. This interaction reduces even further the strength of the spin correlations in the paramagnetic state. The system with higher noise rate (\\(0.5\\)) experiences stronger interaction effects, leading to a more pronounced increase in both the energy and energy fluctuations \\(\\Delta E\\). However, as the system continues to evolve, it begins to move toward an antiferromagnetic (AFM) correlated state, causing the energy and fluctuations to decrease. During this middle phase, the spin correlations become more meaningful, and the state grows gradually ordered. Eventually, the system undergoes a quantum phase transition at \\(t \\approx 3000\\) ns, moving from a paramagnetic state, where the spins are randomly aligned, to a true AFM state with well-defined spin ordering. This transition is reflected in the further reduction of energy fluctuations as the state becomes antiferromagnetic.</p>"},{"location":"emu_mps/benchmarks/noise/#performance","title":"Performance","text":"<p>Above we discussed the behaviour of an average over a larger number of noisy runs. Now, let us discuss the performance characteristics of a single run in more detail.</p> <p>In the following graph we show the performance characteristics of a single run of the above sequence, as a function of the time step, and as a function of qubit number. Do note that we have used the default precision of \\(10^{-5}\\), because that makes the parameters the same as the noiseless adiabatic benchmark here. This allows us to discuss the effect of adding Lindbladian noise to simulations on the performance characteristics.</p> <p></p> <p>One thing we immediately see is that all the bond dimensions are larger than in the noiseless case. As discussed above, the depolarizing noise pumps energy into the system, causing more high-energy states to be excited. When averaged over many runs, this causes correlations in the system to decrease, but during a single run, this means many highly-entangled states are excited by the quantum jumps, leading to a stark rise in the bond-dimension. Most of the difference in memory usage and runtime can be attributed to the fact that the quantum state being simulated is more complex than in the noiseless case. However, two effects particular to the simulation of noisy systems are visible in the graph:</p> <ul> <li>The peaks in the \\(\\Delta t\\) graph correspond to the occurence of a quantum jump</li> <li>In the absence of a quantum jump, the time for a single step is still longer.</li> </ul> <p>Regarding the first item, on the cluster you will occasionally see spikes in the time required for a single step even in the noiseless case. In that case, it is caused by load on the hardware from other jobs and more subtle factors. When doing quantum jumps, it is actually a feature of the algorithm. When doing a timestep according to the config parameter <code>dt</code>, the time evolution generally overshoots the time when a jump needs to occur. A numerical root-finding algorithm is employed to evolve the state to the actual jump time, after which the quantum jump is performed and the system is evolved again to complete the timestep of length <code>dt</code>. This means that a minimum of three time evolutions have to be performed when a quantum jump occurs in the middle of a <code>dt</code> interval. Looking at the height of the peaks in runtime, we see that they are mostly 3 or 4 times the height of the baseline, meaning that the root-finding algorithm converges to the collapse point in 1 or 2 steps the majority of the time, which is good performance. Note that the number of quantum jumps in the graph is quite large, because the depolarizing rate is <code>0.5</code>, which is much bigger than any of the noise rates in the physical device.</p> <p>Regarding the second point above, the effective Hamiltonian used to evolve the system is no longer Hermitian (see here), and our time-evolution algorithm is more expensive on non-Hermitian matrices. The overhead is dependent on the bond-dimension of the system. At the start, when the bond-dimension is close to 1, we see an overhead of about 10% runtime per step, but as the bond-dimension increases to 1000, it grows to around 50%.</p> <p>Since the runtime and memory required to compute a single time step depend polynomially on the bond-dimension, the most important question in determining the effect of noise on the performance of the simulation is how the bond-dimension of the state will be affected by said noise. In the example presented here, we used an adiabatic sequence for anti-ferromagnetic state preparation, and the noise can be seen to negatively impact adiabaticity of the sequence close to the quantum phase transition, just as if the qubit number increases<sup>[1]</sup>. This, in turn, means that for this specific pulse sequence, noise negatively impacts the size of the system that can still be simulated. The degree to which this effect manifests will depend on the sequence being simulated, and the type of noise under consideration.</p>"},{"location":"emu_mps/benchmarks/performance/","title":"Performance","text":"<p>Here, as anticipated in the introduction page of the benchmarks, we will track several relevant metrics associated with runtime, memory usage and bond dimension:</p> <ul> <li>Bond dimension \\(\\chi\\): the maximum internal link dimension of the MPS representation of the time evolved state (see here).</li> <li>State size \\(|\\psi|\\): memory footprint of the state (in MB).</li> <li>RSS: peak memory allocated by the emulation.</li> <li>\\(\\Delta t\\): CPU/GPU time to complete a time step.</li> </ul> <p>We will give information about these metrics for various values of N, the qubit number, to give an idea of how performance scales.</p>"},{"location":"emu_mps/benchmarks/performance/#adiabatic-sequence","title":"Adiabatic sequence","text":"<p>We run an adiabatic sequence to make an antiferromagnetic (AFM) state, as taken from Pulser documentation, for a 2D register of atoms in a grid.</p> <p>Performance metrics, for the defined sequence and for the biggest register (7x7) are shown below, in the left column of the figures, for CPU and GPU workloads. From the plots it is easy to understand that all the metrics heavily correlate with each other. Specifically a higher bond dimension will translate to higher memory footprint and longer runtimes (see here).</p> <p> </p> <p>In the right column (both CPU and GPU figure), we explore the available register size. Simply increasing the number of atoms by \\(N=N_x\\times N_y\\), and extracting the maximum metric and the total runtime for each run, the user can get a feeling on how much memory and time a specific sequence is going to take to emulate. Note that all qubit numbers which are not a square show up twice, since the rectangles making up this qubit number can be oriented two ways. The reason why orientation matters is explained by the results in the benchmark on qubit shuffling. Note that it's possible to simulate larger systems than done in this benchmark. For example, by tuning the config parameters, it's possible to accurately simulate the above pulse for a 7x7 grid (see here).</p>"},{"location":"emu_mps/benchmarks/performance/#performance-for-a-7x7-grid","title":"Performance for a 7x7 grid","text":"<p>Let us now analyze the performance of the simulation for a much larger system. We show results for the adiabatic sequence with 49 qubits arranged in a 7x7 grid. The parameters of the simulation were <code>max_bond_dim = 1600</code>, <code>extra_krylov_tolerance=1e-5</code> and <code>precision=1e-6</code>, and we ran the simulation on 2 GPUs. The maximum bond dimension of the state, its size in memory, the total memory consumption of the program on GPU 1, and the time taken per emulation time step (there are 390 time steps of <code>dt=10 ns</code> each) are shown in the graph below.</p> <p>First off, note that the peak memory consumption on GPU 1 reaches almost 30 GB at the end of the simulation and the memory profile on GPU 2 will be very similar. Note that this memory consumption can be estimated (see here), and that the simulation would not have fit on a single GPU. Next, the memory consumption stops increasing as quickly when the maximum bond dimension plateaus, but it does not stop increasing entirely. This is because when the maximum bond dimension reaches the cutoff value of <code>1600</code>, most of the tensors in the MPS will not have reached maximum size yet. However, the rate of memory consumption growth will decrease as more of the tensors reach this maximum size.</p> <p>Finally, it can be seen that the time taken per time step scales roughly linearly with the memory consumption of the quantum state. This proposes an obvious method for speeding up the simulation. We've mentioned above, that the qubit density results were insensitive to changes in <code>max_bond_dim</code>, and that a value of <code>max_bond_dim</code> smaller than <code>1600</code> would likely still generate good results. As a consequence of the above graph, we ran the simulation with <code>max_bond_dim=1000</code> and all other parameters the same, and indeed, the qubit density was identical up to the 2 digits of precision used above. As can be read off from the above graph, this corresponds to a final time per step of <code>100s</code>, yielding a significant reduction in simulation time while keeping the results at the desired precision.</p>"},{"location":"emu_mps/benchmarks/performance/#quench","title":"Quench","text":"<p>Here, we explore performance in the very same way as before, but for the quench sequence discussed in the introduction. The overall metrics, as before, both for a single run (left) and for multiple runs varying the register size (right, \\(N=N_x\\times N_y\\)) are presented below:</p> <p> </p> <p>As expected, a quench requires significantly more memory to run than the adiabatic sequence (see here).</p>"},{"location":"emu_mps/benchmarks/performance/#qubit-shuffling","title":"Qubit shuffling","text":"<p>A seemingly innocuous operation like reordering the register labels can actually affect the performance, as a consequence of the MPS representation (see here). In simple terms, the additional memory cost, and thus performance decrease, comes from representing two strongly interacting atoms in two far apart tensors in the MPS, since all the intermediate tensors in the chain have to somehow pass that information between them.</p> <p>To be more quantitative, in the following benchmark case, we run the same AFM sequence from before, but shuffling the qubit labeling order.</p> <p>The unshuffled register ordering is that given by <code>Register.rectangle</code> as used in the above two sequences. For the 3x3 grid used in this benchmark, that means a register ordering of</p> 1  2  3  4  5  6  7  8  9  <p>Compare this with the shuffled register, which was constructed to put qubits that are close in physical space far away in index space</p>  2  7  4   5  1  9   8  3  6  <p>The left column of the image shows no accuracy degradation from the qubit shuffling, returning equivalent observables. That is expected since both runs were able to converge to the desired precision.</p> <p>However, performance metrics (allocations and runtime) of the shuffled case significantly worsen, because shuffling the qubits introduces artificial long-range entanglement into the system, increasing the bond dimension. This larger bond dimension means the matrices involved in the computations are bigger, requiring more memory and compute time.</p> <p>In the future we plan to apply register ordering strategies by default, but for the moment, the take-home message is that a good register embedding is important. Ideally, one should keep strongly interactive pairs or atoms the closest possible when enumerating them in the register.</p>"},{"location":"emu_mps/notebooks/","title":"Example Notebooks","text":"<p>You have found the base page for all our example notebooks. Here you find rendered web versions of the notebooks, the originals are available in the repo (see here).</p>"},{"location":"emu_mps/notebooks/getting_started/","title":"Getting started with emu-mps","text":"<p>Let's first import all the needed libraries.</p> In\u00a0[2]: Copied! <pre>import matplotlib.pyplot as plt\nfrom emu_mps import (\n    MPS,\n    MPSConfig,\n    MPSBackend,\n    BitStrings,\n    Fidelity,\n    Occupation,\n)\nfrom utils_examples import afm_sequence_from_register, square_perimeter_points\n\nimport pulser\nfrom pulser.devices import AnalogDevice\nimport numpy as np\n</pre> import matplotlib.pyplot as plt from emu_mps import (     MPS,     MPSConfig,     MPSBackend,     BitStrings,     Fidelity,     Occupation, ) from utils_examples import afm_sequence_from_register, square_perimeter_points  import pulser from pulser.devices import AnalogDevice import numpy as np <p>To make this tutorial focused on the backend functionalities we use two auxiliary functions to quickly create the Pulser object.</p> <p>The function <code>square_perimeter_points</code> calculates the coordinates of the atoms located on the perimeter of a square. The qubits will be labeled starting from the bottom-left corner and moving counter-clockwise around the square. Please, notice that the measured bitstrings will depend on the order chosen for the atom locations.</p> <p>The function <code>afm_sequence_from_register</code> creates the pulse sequence for the AFM state for the specified register. The sequence will consist of three phases: a rise, a sweep, and a fall where the sweep time is proportional to the rise and fall times.</p> <p>We start by defining the main physical quantities needed to prepare the system. For the reader's conveninence we recall here their meaining:</p> <ul> <li><code>Omega_max</code> is the peak laser amplitude used in the pulse sequence</li> <li><code>delta_0</code> is the initial detuning used in the pulse</li> <li><code>delta_f</code> is the final detuning used in the pulse</li> <li><code>t_rise</code> is the duration of the rise phase</li> <li><code>t_fall</code> is the duraction of the fall phase</li> <li><code>sweep_factor</code> is a scale factor expressing the duration of the sweep phase in terms of <code>delta_f - delta_0</code> Note that we make the interatomic distance depend on <code>Omega_max</code> so that the interaction strength in the system is relative to the pulse parameters.</li> </ul> In\u00a0[3]: Copied! <pre>Omega_max = 2 * 2 * np.pi\ndelta_0 = -6 * Omega_max / 2\ndelta_f = 1 * Omega_max / 2\nt_rise = 500\nt_fall = 1500\nsweep_factor = 2\n\nsquare_length = 3\nR_interatomic = AnalogDevice.rydberg_blockade_radius(Omega_max / 2)\n</pre> Omega_max = 2 * 2 * np.pi delta_0 = -6 * Omega_max / 2 delta_f = 1 * Omega_max / 2 t_rise = 500 t_fall = 1500 sweep_factor = 2  square_length = 3 R_interatomic = AnalogDevice.rydberg_blockade_radius(Omega_max / 2) <p>We can now create the register consisting of 8 atom locations.</p> In\u00a0[4]: Copied! <pre>coords = R_interatomic * square_perimeter_points(square_length)\nreg = pulser.Register.from_coordinates(coords)\nreg.draw(blockade_radius=R_interatomic, draw_graph=True, draw_half_radius=True)\n</pre> coords = R_interatomic * square_perimeter_points(square_length) reg = pulser.Register.from_coordinates(coords) reg.draw(blockade_radius=R_interatomic, draw_graph=True, draw_half_radius=True) <p>And finally the pulse sequence that will realize the AFM state:</p> In\u00a0[5]: Copied! <pre>seq = afm_sequence_from_register(\n    reg, Omega_max, delta_0, delta_f, t_rise, t_fall, sweep_factor, AnalogDevice\n)\nseq.draw(\"input\")\n</pre> seq = afm_sequence_from_register(     reg, Omega_max, delta_0, delta_f, t_rise, t_fall, sweep_factor, AnalogDevice ) seq.draw(\"input\") In\u00a0[\u00a0]: Copied! <pre>dt = 100\neval_times = [1.0]\n\nbasis = (\"r\",\"g\")\n</pre> dt = 100 eval_times = [1.0]  basis = (\"r\",\"g\") In\u00a0[7]: Copied! <pre>sampling_times = 1000\nbitstrings = BitStrings(evaluation_times=eval_times, num_shots=sampling_times)\n</pre> sampling_times = 1000 bitstrings = BitStrings(evaluation_times=eval_times, num_shots=sampling_times) In\u00a0[\u00a0]: Copied! <pre>nqubits = len(seq.register.qubit_ids)\n\nafm_string_pure = {\"rgrgrgrg\": 1.0}\n\nafm_mps_state = MPS.from_state_amplitudes(\n    eigenstates=basis, amplitudes=afm_string_pure\n)\nfidelity_mps_pure = Fidelity(evaluation_times=eval_times, state=afm_mps_state)\n</pre> nqubits = len(seq.register.qubit_ids)  afm_string_pure = {\"rgrgrgrg\": 1.0}  afm_mps_state = MPS.from_state_amplitudes(     eigenstates=basis, amplitudes=afm_string_pure ) fidelity_mps_pure = Fidelity(evaluation_times=eval_times, state=afm_mps_state) In\u00a0[9]: Copied! <pre>density = Occupation(\n    evaluation_times=[x/seq.get_duration() for x in range(0, seq.get_duration(), dt)]\n)\n</pre> density = Occupation(     evaluation_times=[x/seq.get_duration() for x in range(0, seq.get_duration(), dt)] ) In\u00a0[10]: Copied! <pre>mpsconfig = MPSConfig(\n    dt=dt,\n    observables=[\n        bitstrings,\n        fidelity_mps_pure,\n        density,\n    ],\n)\n</pre> mpsconfig = MPSConfig(     dt=dt,     observables=[         bitstrings,         fidelity_mps_pure,         density,     ], ) In\u00a0[11]: Copied! <pre>sim = MPSBackend(seq, config=mpsconfig)\nresults = sim.run()\n</pre> sim = MPSBackend(seq, config=mpsconfig) results = sim.run() <pre>step = 1/34, \u03c7 = 2, |\u03c8| = 0.001 MB, RSS = 11.707 MB, \u0394t = 0.157 s\n</pre> <pre>step = 2/34, \u03c7 = 2, |\u03c8| = 0.001 MB, RSS = 11.707 MB, \u0394t = 0.150 s\nstep = 3/34, \u03c7 = 3, |\u03c8| = 0.002 MB, RSS = 11.710 MB, \u0394t = 0.156 s\nstep = 4/34, \u03c7 = 4, |\u03c8| = 0.002 MB, RSS = 11.710 MB, \u0394t = 0.184 s\nstep = 5/34, \u03c7 = 4, |\u03c8| = 0.002 MB, RSS = 11.710 MB, \u0394t = 0.186 s\nstep = 6/34, \u03c7 = 5, |\u03c8| = 0.003 MB, RSS = 11.714 MB, \u0394t = 0.189 s\nstep = 7/34, \u03c7 = 5, |\u03c8| = 0.003 MB, RSS = 11.714 MB, \u0394t = 0.202 s\nstep = 8/34, \u03c7 = 5, |\u03c8| = 0.003 MB, RSS = 11.715 MB, \u0394t = 0.199 s\nstep = 9/34, \u03c7 = 5, |\u03c8| = 0.004 MB, RSS = 11.715 MB, \u0394t = 0.204 s\nstep = 10/34, \u03c7 = 5, |\u03c8| = 0.004 MB, RSS = 11.715 MB, \u0394t = 0.197 s\nstep = 11/34, \u03c7 = 5, |\u03c8| = 0.004 MB, RSS = 11.715 MB, \u0394t = 0.193 s\nstep = 12/34, \u03c7 = 6, |\u03c8| = 0.004 MB, RSS = 11.718 MB, \u0394t = 0.185 s\nstep = 13/34, \u03c7 = 6, |\u03c8| = 0.004 MB, RSS = 11.718 MB, \u0394t = 0.183 s\nstep = 14/34, \u03c7 = 7, |\u03c8| = 0.005 MB, RSS = 11.719 MB, \u0394t = 0.180 s\nstep = 15/34, \u03c7 = 8, |\u03c8| = 0.006 MB, RSS = 11.724 MB, \u0394t = 0.170 s\nstep = 16/34, \u03c7 = 9, |\u03c8| = 0.006 MB, RSS = 11.726 MB, \u0394t = 0.168 s\nstep = 17/34, \u03c7 = 10, |\u03c8| = 0.007 MB, RSS = 11.729 MB, \u0394t = 0.166 s\nstep = 18/34, \u03c7 = 10, |\u03c8| = 0.008 MB, RSS = 11.730 MB, \u0394t = 0.166 s\nstep = 19/34, \u03c7 = 11, |\u03c8| = 0.008 MB, RSS = 11.733 MB, \u0394t = 0.167 s\nstep = 20/34, \u03c7 = 11, |\u03c8| = 0.008 MB, RSS = 11.733 MB, \u0394t = 0.165 s\nstep = 21/34, \u03c7 = 11, |\u03c8| = 0.008 MB, RSS = 11.733 MB, \u0394t = 0.165 s\nstep = 22/34, \u03c7 = 12, |\u03c8| = 0.009 MB, RSS = 11.735 MB, \u0394t = 0.158 s\nstep = 23/34, \u03c7 = 12, |\u03c8| = 0.009 MB, RSS = 11.735 MB, \u0394t = 0.153 s\nstep = 24/34, \u03c7 = 12, |\u03c8| = 0.009 MB, RSS = 11.735 MB, \u0394t = 0.153 s\nstep = 25/34, \u03c7 = 13, |\u03c8| = 0.009 MB, RSS = 11.739 MB, \u0394t = 0.155 s\nstep = 26/34, \u03c7 = 13, |\u03c8| = 0.009 MB, RSS = 11.739 MB, \u0394t = 0.153 s\nstep = 27/34, \u03c7 = 13, |\u03c8| = 0.009 MB, RSS = 11.739 MB, \u0394t = 0.149 s\nstep = 28/34, \u03c7 = 13, |\u03c8| = 0.009 MB, RSS = 11.739 MB, \u0394t = 0.147 s\nstep = 29/34, \u03c7 = 13, |\u03c8| = 0.009 MB, RSS = 11.739 MB, \u0394t = 0.146 s\nstep = 30/34, \u03c7 = 14, |\u03c8| = 0.010 MB, RSS = 11.741 MB, \u0394t = 0.138 s\nstep = 31/34, \u03c7 = 14, |\u03c8| = 0.010 MB, RSS = 11.741 MB, \u0394t = 0.138 s\nstep = 32/34, \u03c7 = 14, |\u03c8| = 0.010 MB, RSS = 11.741 MB, \u0394t = 0.144 s\nstep = 33/34, \u03c7 = 14, |\u03c8| = 0.010 MB, RSS = 11.741 MB, \u0394t = 0.140 s\nstep = 34/34, \u03c7 = 14, |\u03c8| = 0.010 MB, RSS = 11.741 MB, \u0394t = 0.302 s\n</pre> <p>During simulation time one has access to the following information:</p> <ul> <li>step: the whole sequence is discretized by dt and this generates a number of steps.</li> <li>$\\chi$ : is the bond dimension</li> <li>$|\\Psi|$: memory footprint</li> <li>RSS: max memory allocation</li> <li>$\\triangle t$: time that the step took to run</li> </ul> In\u00a0[12]: Copied! <pre>results.get_result_tags()\n</pre> results.get_result_tags() Out[12]: <pre>['occupation', 'statistics', 'bitstrings', 'fidelity']</pre> <p>Notice that the fidelity name contains an index, because it is possible to create several fidelities on different states, and the names must be unique.</p> In\u00a0[13]: Copied! <pre>results.get_result_times(bitstrings)\nbitstrings_final = results.get_result(bitstrings, 1.0)\n\nmax_val = max(bitstrings_final.values())  # max number of counts in the bitstring\nmax_string = [key for key, value in bitstrings_final.items() if value == max_val]\nprint(\n    \"The most frequent bitstring is {} which was sampled {} times\".format(\n        max_string, max_val\n    )\n)\n\nfiltered_counts = [count for count in bitstrings_final.values() if count &gt; 20]\nfiltered_bitstrings = [\n    bitstring for bitstring, count in bitstrings_final.items() if count &gt; 20\n]\nx_labels = range(len(filtered_bitstrings))\nwith plt.style.context(\"seaborn-v0_8-darkgrid\"):\n    fig, ax = plt.subplots()\n    ax.bar(x_labels, filtered_counts, color=\"teal\", alpha=0.8)\n    ax.set_xlabel(\"Bitstrings\")\n    ax.set_ylabel(\"Counts\")\n    ax.set_title(\"Histogram of Bitstring Counts (Counts &gt; 20)\")\n    ax.set_xticks(x_labels)\n    ax.set_xticklabels(filtered_bitstrings, rotation=\"vertical\")\n    ax.spines[\"top\"].set_visible(False)\n    ax.spines[\"right\"].set_visible(False)\n    plt.tight_layout()\n    plt.show()\n</pre> results.get_result_times(bitstrings) bitstrings_final = results.get_result(bitstrings, 1.0)  max_val = max(bitstrings_final.values())  # max number of counts in the bitstring max_string = [key for key, value in bitstrings_final.items() if value == max_val] print(     \"The most frequent bitstring is {} which was sampled {} times\".format(         max_string, max_val     ) )  filtered_counts = [count for count in bitstrings_final.values() if count &gt; 20] filtered_bitstrings = [     bitstring for bitstring, count in bitstrings_final.items() if count &gt; 20 ] x_labels = range(len(filtered_bitstrings)) with plt.style.context(\"seaborn-v0_8-darkgrid\"):     fig, ax = plt.subplots()     ax.bar(x_labels, filtered_counts, color=\"teal\", alpha=0.8)     ax.set_xlabel(\"Bitstrings\")     ax.set_ylabel(\"Counts\")     ax.set_title(\"Histogram of Bitstring Counts (Counts &gt; 20)\")     ax.set_xticks(x_labels)     ax.set_xticklabels(filtered_bitstrings, rotation=\"vertical\")     ax.spines[\"top\"].set_visible(False)     ax.spines[\"right\"].set_visible(False)     plt.tight_layout()     plt.show() <pre>The most frequent bitstring is ['10101010'] which was sampled 238 times\n</pre> In\u00a0[14]: Copied! <pre>fidelity_pure = results.get_result(fidelity_mps_pure,1.0)\n\nprint(\n    \"The fidelity computed for the system final state against the pure state |rgrgrgr&gt; is {}.\\nThe probability of the system being in that sate is equal to {} \".format(\n        fidelity_pure, abs(fidelity_pure) ** 2\n    )\n)\n</pre> fidelity_pure = results.get_result(fidelity_mps_pure,1.0)  print(     \"The fidelity computed for the system final state against the pure state |rgrgrgr&gt; is {}.\\nThe probability of the system being in that sate is equal to {} \".format(         fidelity_pure, abs(fidelity_pure) ** 2     ) ) <pre>The fidelity computed for the system final state against the pure state |rgrgrgr&gt; is 0.25445735168596245.\nThe probability of the system being in that sate is equal to 0.06474854382703357 \n</pre> In\u00a0[15]: Copied! <pre>magnetization_values = np.array(list(results.occupation))\nmagnetization_times = results.get_result_times(density)\n</pre> magnetization_values = np.array(list(results.occupation)) magnetization_times = results.get_result_times(density) In\u00a0[16]: Copied! <pre>fig, ax = plt.subplots(figsize=(8, 4), layout=\"constrained\")\n\nnum_time_points, positions = magnetization_values.shape\nx, y = np.meshgrid(np.arange(num_time_points), np.arange(1, positions + 1))\nim = plt.pcolormesh(magnetization_times, y, magnetization_values.T, shading=\"auto\")\nax.set_xlabel(\"Time [ns]\")\nax.set_ylabel(\"Qubit\")\nax.set_title(\"State Density\")\nax.set_yticks(np.arange(1, positions + 1))\ncb = fig.colorbar(im, ax=ax)\n</pre> fig, ax = plt.subplots(figsize=(8, 4), layout=\"constrained\")  num_time_points, positions = magnetization_values.shape x, y = np.meshgrid(np.arange(num_time_points), np.arange(1, positions + 1)) im = plt.pcolormesh(magnetization_times, y, magnetization_values.T, shading=\"auto\") ax.set_xlabel(\"Time [ns]\") ax.set_ylabel(\"Qubit\") ax.set_title(\"State Density\") ax.set_yticks(np.arange(1, positions + 1)) cb = fig.colorbar(im, ax=ax)"},{"location":"emu_mps/notebooks/getting_started/#getting-started-with-emu-mps","title":"Getting started with emu-mps\u00b6","text":"<p>The aim of this tutorial is to show how emu-mps can be used as a Pulser backend to run a pulse sequence and how to extract the most important information of the system via observables such as magnetization and few more. In this tutorial we show how to emulate step-by-step an antiferromagnetic (AFM) state with a 1D ring of atoms. For more information about this specific pulse sequence, please refer to the Pulser tutorial dedicated to such experiment.</p>"},{"location":"emu_mps/notebooks/getting_started/#pulser-and-emu-mps","title":"Pulser and emu-mps\u00b6","text":"<p>Emu-mps is a Pulser backend, designed to Emulate the dynamics of programmable arrays of neutral atoms. It works in a very intuitive way: the main method is called <code>run</code> which is used to run the simulation. This method requires as argument a Pulser sequence and a configuration file.</p> <p>Here are the steps that we will go through in the following:</p> <ol> <li>using Pulser we will create first the atomic Register</li> <li>again with Pulser we will then generate the Pulse sequence that produce the AFM state for the created register</li> <li>we create the configuration object (<code>MPSConfig</code>) and we fill it with the needed observables and time step</li> <li>we instantiate the backend class (<code>MPSBackend</code>) and run the simulation</li> <li>we inspect the results obtained</li> </ol>"},{"location":"emu_mps/notebooks/getting_started/#register-and-sequence-creation","title":"Register and Sequence creation\u00b6","text":""},{"location":"emu_mps/notebooks/getting_started/#using-emu-mps-as-backend","title":"Using emu-mps as backend\u00b6","text":"<p>As mentioned earlier, to run a simulation with the emu-mps backend we need to provide as input a Pulse sequence - which we have just created - and a configuration object.</p> <p>We still have to create the configuration for the emu-mps backend. This is done via an instantiation of the configuration class <code>MPSConfig</code> which contains all the observables that we wish to measure and the time step chosen for the simulation, along with various algorithm specific parameters that are explained in the documentation.</p> <p>We start by setting a bigger discretization time than the default one provided ($dt=10$) and enforcing that the times at which we compute the observables are an integer multiple of $dt$. For simplicity, we will measure the observables only at the final time of the simulation.</p> <p>We also fix the basis along which the measurements will be done. For the details regarding the conventions used we refer to the Pulser documentation.</p>"},{"location":"emu_mps/notebooks/getting_started/#bitstring-counts","title":"BitString counts\u00b6","text":"<p>It samples at desired time steps the evolved state, returning the bitStrings in a counter.</p>"},{"location":"emu_mps/notebooks/getting_started/#fidelity","title":"Fidelity\u00b6","text":"<p>The fidelity is computed as $\\langle \\psi_{evolved} | \\phi_{given} \\rangle$ where</p> <ul> <li>$\\psi_{evolved}$ is the system state at desired steps</li> <li>$\\phi_{given}$ is the state in which we want to project the state system.</li> </ul> <p>In this tutorial we will compute the fidelity against the dominant of the two antiferromagnetic states $\\phi_{given} = |rgrgrgrg&gt;$</p>"},{"location":"emu_mps/notebooks/getting_started/#qubit-density","title":"Qubit Density\u00b6","text":"<p>It is computed as $\\langle \\psi_{evolved} |\\frac{(1+Z_i)}{2}|\\psi_{evolved}\\rangle$ and often informally referred to as the magnetization at each atom site.</p>"},{"location":"emu_mps/notebooks/getting_started/#configuration-object-for-emu-mps","title":"Configuration object for emu-mps\u00b6","text":""},{"location":"emu_mps/notebooks/getting_started/#finally-we-run","title":"Finally we run\u00b6","text":"<p>We instantiate the backend class <code>MPSBackend</code> and use its <code>run</code> method where we pass as argument the <code>sequence</code> and the <code>backend configuration</code> objects.</p>"},{"location":"emu_mps/notebooks/getting_started/#inspecting-the-result-object","title":"Inspecting the result object\u00b6","text":"<p>In the following lines, we are going to give a brief code examples of how you can get the information from the results object</p>"},{"location":"emu_mps/notebooks/getting_started/#bitstrings-analysis","title":"Bitstrings analysis\u00b6","text":"<p>Below, we retrieve the bistrings computed. We observe that they were indeed computed only at a single time $ns = 3400$, and we find those that were sampled the highest number of times with their relative counting.</p>"},{"location":"emu_mps/notebooks/getting_started/#fidelity-analysis","title":"Fidelity analysis\u00b6","text":"<p>Here we compute the fidelity of the system against the two different AFM state realizations defined above.</p>"},{"location":"emu_mps/notebooks/getting_started/#evolution-of-the-state-in-time","title":"Evolution of the state in time\u00b6","text":"<p>Here, we plot the time evolution of the magnetization of the system sites, and we observe how the system slowly reaches the AFM state.</p>"},{"location":"emu_mps/notebooks/noise/","title":"Running noisy simulations","text":"In\u00a0[16]: Copied! <pre>import pulser\nimport emu_mps\nimport numpy as np\nimport logging #used to turn of logging in emu_mps\n</pre> import pulser import emu_mps import numpy as np import logging #used to turn of logging in emu_mps <p>Next we define the registers. Since we will turn off interactions, the qubit positions are arbitrarily chosen based on my number of fingers.</p> In\u00a0[17]: Copied! <pre>reg = pulser.Register.from_coordinates([[0,0],[10,0]])\nreg.draw(blockade_radius=1e-10, draw_graph=True, draw_half_radius=True) #draw blockade radius as 0, since we will mask interactions in the MPSConfig\n</pre> reg = pulser.Register.from_coordinates([[0,0],[10,0]]) reg.draw(blockade_radius=1e-10, draw_graph=True, draw_half_radius=True) #draw blockade radius as 0, since we will mask interactions in the MPSConfig <p>Next we define the <code>Sequence</code>. It consists of one constant pulse on the Rydberg channel with no amplitude and detuning. The duration of the pulse is taken as <code>t=1000</code> since it makes the graphs a nice length. It also has to be a multiple of whatever <code>dt</code> we choose below, which we keep at the default <code>dt=10</code>.</p> In\u00a0[18]: Copied! <pre>seq = pulser.Sequence(reg, pulser.devices.MockDevice)\nt = 1000\npulse = pulser.Pulse.ConstantAmplitude(\n        0., pulser.waveforms.ConstantWaveform(t, 0.), 0.0\n    )\nseq.declare_channel(\"ising_global\", \"rydberg_global\")\nseq.add(pulse, \"ising_global\")\n</pre> seq = pulser.Sequence(reg, pulser.devices.MockDevice) t = 1000 pulse = pulser.Pulse.ConstantAmplitude(         0., pulser.waveforms.ConstantWaveform(t, 0.), 0.0     ) seq.declare_channel(\"ising_global\", \"rydberg_global\") seq.add(pulse, \"ising_global\") <p>We define the noise model to contain both a relaxation and a dephasing. For the system in question, dephasing has no actual influence on the dynamics since the system is always in an eigenstate of the dephasing jump operator. It's interesting to see that the correct relaxation rate still appears in the graphs though, which is why we are adding it. We're putting the rates to <code>1.</code> so that all the scaling of the graphs is in <code>t</code></p> In\u00a0[19]: Copied! <pre>noise = pulser.NoiseModel(relaxation_rate=1, dephasing_rate=1.)\n</pre> noise = pulser.NoiseModel(relaxation_rate=1, dephasing_rate=1.) <p>We'll measure the qubit density after each time step. Since we keep the default value of <code>dt=10</code> this means the measurements are at each multiple of <code>10ns</code>, as defined in <code>times</code> below.</p> In\u00a0[20]: Copied! <pre>times = np.arange(10., 1000.+1e-8, 10) #need to include 1000.\ntimes /= seq.get_duration()\nbasis = (\"r\", \"g\")\nmagnetization = emu_mps.Occupation(evaluation_times=times)\n</pre> times = np.arange(10., 1000.+1e-8, 10) #need to include 1000. times /= seq.get_duration() basis = (\"r\", \"g\") magnetization = emu_mps.Occupation(evaluation_times=times) <p>As described at the start of the notebook, we start from the <code>11</code> state.</p> In\u00a0[21]: Copied! <pre>#define initial state\ninitial_state = emu_mps.MPS.from_state_amplitudes(amplitudes={\"rr\":1.},eigenstates=basis)\n</pre> #define initial state initial_state = emu_mps.MPS.from_state_amplitudes(amplitudes={\"rr\":1.},eigenstates=basis) <p>Now we create the <code>MPSConfig</code> and <code>MPSBackend</code> for the above.</p> In\u00a0[22]: Copied! <pre>#define config and backend\nconfig = emu_mps.MPSConfig(\n    noise_model=noise,\n    num_gpus_to_use=0, #small systems are faster on cpu\n    interaction_cutoff=1e10, #this will put all interactions to 0, regardless of spacing\n    initial_state=initial_state,\n    observables=[magnetization],\n    log_level = logging.WARN #don't print stuff for the many runs\n)\nbackend = emu_mps.MPSBackend(seq, config=config)\n</pre> #define config and backend config = emu_mps.MPSConfig(     noise_model=noise,     num_gpus_to_use=0, #small systems are faster on cpu     interaction_cutoff=1e10, #this will put all interactions to 0, regardless of spacing     initial_state=initial_state,     observables=[magnetization],     log_level = logging.WARN #don't print stuff for the many runs ) backend = emu_mps.MPSBackend(seq, config=config) <p>The way to handle results for many runs, is to store all the <code>Results</code> objects separately, and compute aggregated statistics from them afterwards.</p> In\u00a0[23]: Copied! <pre>results = []\nnruns = 500 #0.125 seconds per run on my machine\nfor _ in range(nruns):\n    results.append(backend.run())\n</pre> results = [] nruns = 500 #0.125 seconds per run on my machine for _ in range(nruns):     results.append(backend.run()) <p>Let's compute the average magnetization of qubit 0 over all the simulation results for each time. This can be done automatically by the <code>Results</code> class and its <code>aggregate</code> static factory method. For a given callback, the <code>Callback.default_aggregation_type</code> attribute indicates how <code>aggregate</code> processes the values from different runs. This is only a go-to setting that isn't always available, and can be overriden by the user for specific cases.</p> In\u00a0[24]: Copied! <pre>#this is temporarily not available pending a move of the aggregation functionality to pulser\n#this is currently under discussion\n#magnetization.default_aggregation_type\n</pre> #this is temporarily not available pending a move of the aggregation functionality to pulser #this is currently under discussion #magnetization.default_aggregation_type <p>Here we get <code>AggregationType.MEAN</code> which indicates that qubit densities are averaged by default. To actually perform this aggregation over all results:</p> In\u00a0[25]: Copied! <pre>#this api will be subject to change when the aggregation functionality moves to pulser.\naggregated_results = emu_mps.aggregate(results)\naggregated_results.get_result(magnetization, 100/seq.get_duration())[0] # average magnetization of qubit 0 at time 100ns\n</pre> #this api will be subject to change when the aggregation functionality moves to pulser. aggregated_results = emu_mps.aggregate(results) aggregated_results.get_result(magnetization, 100/seq.get_duration())[0] # average magnetization of qubit 0 at time 100ns <pre>Skipping aggregation of `statistics`\n</pre> Out[25]: <pre>tensor(0.9240, dtype=torch.float64)</pre> <p>If we were instead to be interested in the median qubit density over the <code>nruns</code>, we would have to define our own aggregation method. It would look like below. Note that magnetization values are given as list of lists, where each individual list corresponds to the magnetization values for qubits of a single run, and aggregation needs to happen over all those runs for each qubit separately.</p> In\u00a0[26]: Copied! <pre>import statistics\n\ndef median_qubit_density(qubit_density_values: list[list[float]]):\n    return [statistics.median(qubit_density[qubit_index] for qubit_density in qubit_density_values) for qubit_index in range(2)]\n\n# API for kwargs of `Results.aggregate` is `callback_name=callable_aggregator`\naggregated_median_qubit_density = emu_mps.aggregate(results, occupation=median_qubit_density)\naggregated_median_qubit_density.get_result(magnetization, 100/seq.get_duration())[0] # median magnetization of qubit 0 at time 100ns\n</pre> import statistics  def median_qubit_density(qubit_density_values: list[list[float]]):     return [statistics.median(qubit_density[qubit_index] for qubit_density in qubit_density_values) for qubit_index in range(2)]  # API for kwargs of `Results.aggregate` is `callback_name=callable_aggregator` aggregated_median_qubit_density = emu_mps.aggregate(results, occupation=median_qubit_density) aggregated_median_qubit_density.get_result(magnetization, 100/seq.get_duration())[0] # median magnetization of qubit 0 at time 100ns <pre>Skipping aggregation of `statistics`\n</pre> Out[26]: <pre>tensor(1., dtype=torch.float64)</pre> <p>The median of the magnetization at time 100ns is 1. This can be a bit surprising, but is in fact perfectly natural given how the Monte Carlo simulation works: in a single run, qubit density is not continuous but randomly jumps from 1 to 0. We can check that e.g. by turning lists of magnetization values into Python sets with only 2 elements 0 and 1:</p> In\u00a0[27]: Copied! <pre>def set_density(qubit_density_values: list[list[float]]):\n    return [set(qubit_density[qubit_index] for qubit_density in qubit_density_values) for qubit_index in range(2)]\n\naggregated_set_qubit_density = emu_mps.aggregate(results, occupation=set_density)\naggregated_median_qubit_density.get_result(magnetization, 100/seq.get_duration())[0]\n# The extra 0.999 value comes from floating-point maths, Monte-Carlo logic and state renormalization.\n</pre> def set_density(qubit_density_values: list[list[float]]):     return [set(qubit_density[qubit_index] for qubit_density in qubit_density_values) for qubit_index in range(2)]  aggregated_set_qubit_density = emu_mps.aggregate(results, occupation=set_density) aggregated_median_qubit_density.get_result(magnetization, 100/seq.get_duration())[0] # The extra 0.999 value comes from floating-point maths, Monte-Carlo logic and state renormalization. <pre>Skipping aggregation of `statistics`\n</pre> Out[27]: <pre>tensor(1., dtype=torch.float64)</pre> <p>To show the convergence of that quantity as the number of runs grows, we can aggregate only the first <code>n &lt;= nruns</code> results. Here's a utility function doing that:</p> In\u00a0[28]: Copied! <pre>def densities(results, n):\n    return [density[0] for density in emu_mps.aggregate(results[:n]).occupation]\n</pre> def densities(results, n):     return [density[0] for density in emu_mps.aggregate(results[:n]).occupation] <p>Define the true mean of the magnetization towards which the sample statistics should converge as <code>nruns -&gt; inf</code></p> In\u00a0[29]: Copied! <pre>expected = [np.exp(-1*t*seq.get_duration()/1000) for t in times]\n</pre> expected = [np.exp(-1*t*seq.get_duration()/1000) for t in times] <p>Plot the magnetization. Here we see good agreement with the limit at <code>n=200</code> already, but if you're unlucky, even for <code>n=500</code> results can differ.</p> In\u00a0[30]: Copied! <pre>import matplotlib.pyplot as pl\npl.plot(times, expected, label=\"expected\")\nfor n in [100, 200, 500]:\n    pl.plot(times, densities(results, n), label=f\"n = {n}\")\npl.legend(loc=\"upper right\")\n</pre> import matplotlib.pyplot as pl pl.plot(times, expected, label=\"expected\") for n in [100, 200, 500]:     pl.plot(times, densities(results, n), label=f\"n = {n}\") pl.legend(loc=\"upper right\") <pre>Skipping aggregation of `statistics`\nSkipping aggregation of `statistics`\nSkipping aggregation of `statistics`\n</pre> Out[30]: <pre>&lt;matplotlib.legend.Legend at 0x7f6ca3e25ba0&gt;</pre>"},{"location":"emu_mps/notebooks/noise/#running-noisy-simulations","title":"Running noisy simulations\u00b6","text":"<p>The aim of this notebook is to show how to do Monte Carlo simulations of noisy systems in emu-mps. The focus is on demonstrating the API, for information about the algorithm used, runtime and memory characteristics and potential pitfalls, please refer to the documentation.</p> <p>We will run a sequence without driving or interactions, starting from the <code>11</code> state, with dephasing and spontaneous emission noise, and show that when enough Monte Carlo runs are performed, the probability to find the first qubit in the <code>1</code> state decays with the spontaneous emission rate, as expected. It is impossible to run the simulation for a single qubit, since emu-mps does not support this edge case.</p> <p>First we import the required packages</p>"},{"location":"emu_mps/notebooks/utils_examples/__init__/","title":"init","text":"In\u00a0[\u00a0]: Copied! <pre>from .afm_state_ring_reg import afm_sequence_from_register\nfrom .square_perimeter_reg import square_perimeter_points\n</pre> from .afm_state_ring_reg import afm_sequence_from_register from .square_perimeter_reg import square_perimeter_points In\u00a0[\u00a0]: Copied! <pre>__all__ = [\"afm_sequence_from_register\", \"square_perimeter_points\"]\n</pre> __all__ = [\"afm_sequence_from_register\", \"square_perimeter_points\"]"},{"location":"emu_mps/notebooks/utils_examples/afm_state_ring_reg/","title":"Afm state ring reg","text":"In\u00a0[\u00a0]: Copied! <pre>import pulser\nimport numpy as np\n</pre> import pulser import numpy as np In\u00a0[\u00a0]: Copied! <pre>def afm_sequence_from_register(\n    reg: pulser.Register,\n    Omega_max: float,\n    delta_0: float,\n    delta_f: float,\n    t_rise: float,\n    t_fall: float,\n    factor_sweep: int,\n    device: pulser.devices = pulser.devices.MockDevice,\n) -&gt; pulser.Sequence:\n    \"\"\"Sequence that creates AntiFerromagnetic State (AFM) for 1d chain of atoms using pulser.\n    This function constructs a sequence of pulses to transition a system of qubits\n    distributed in a 1d chain (represented by `reg`) into an AFM state using a specified device.\n    The sequence consists of three phases: a rise, a sweep, and a fall.\n    For more information, check Pulser\n    [tutorial](https://pulser.readthedocs.io/en/stable/tutorials/afm_prep.html).\"\"\"\n\n    t_sweep = (delta_f - delta_0) / (2 * np.pi * 10) * 1000 * factor_sweep\n    rise = pulser.Pulse.ConstantDetuning(\n        pulser.waveforms.RampWaveform(t_rise, 0.0, Omega_max), delta_0, 0.0\n    )\n    sweep = pulser.Pulse.ConstantAmplitude(\n        Omega_max, pulser.waveforms.RampWaveform(t_sweep, delta_0, delta_f), 0.0\n    )\n    fall = pulser.Pulse.ConstantDetuning(\n        pulser.waveforms.RampWaveform(t_fall, Omega_max, 0.0), delta_f, 0.0\n    )\n\n    seq = pulser.Sequence(reg, device)\n    seq.declare_channel(\"ising_global\", \"rydberg_global\")\n    seq.add(rise, \"ising_global\")\n    seq.add(sweep, \"ising_global\")\n    seq.add(fall, \"ising_global\")\n\n    return seq\n</pre> def afm_sequence_from_register(     reg: pulser.Register,     Omega_max: float,     delta_0: float,     delta_f: float,     t_rise: float,     t_fall: float,     factor_sweep: int,     device: pulser.devices = pulser.devices.MockDevice, ) -&gt; pulser.Sequence:     \"\"\"Sequence that creates AntiFerromagnetic State (AFM) for 1d chain of atoms using pulser.     This function constructs a sequence of pulses to transition a system of qubits     distributed in a 1d chain (represented by `reg`) into an AFM state using a specified device.     The sequence consists of three phases: a rise, a sweep, and a fall.     For more information, check Pulser     [tutorial](https://pulser.readthedocs.io/en/stable/tutorials/afm_prep.html).\"\"\"      t_sweep = (delta_f - delta_0) / (2 * np.pi * 10) * 1000 * factor_sweep     rise = pulser.Pulse.ConstantDetuning(         pulser.waveforms.RampWaveform(t_rise, 0.0, Omega_max), delta_0, 0.0     )     sweep = pulser.Pulse.ConstantAmplitude(         Omega_max, pulser.waveforms.RampWaveform(t_sweep, delta_0, delta_f), 0.0     )     fall = pulser.Pulse.ConstantDetuning(         pulser.waveforms.RampWaveform(t_fall, Omega_max, 0.0), delta_f, 0.0     )      seq = pulser.Sequence(reg, device)     seq.declare_channel(\"ising_global\", \"rydberg_global\")     seq.add(rise, \"ising_global\")     seq.add(sweep, \"ising_global\")     seq.add(fall, \"ising_global\")      return seq"},{"location":"emu_mps/notebooks/utils_examples/square_perimeter_reg/","title":"Square perimeter reg","text":"In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport math\n</pre> import numpy as np import math In\u00a0[\u00a0]: Copied! <pre>def square_perimeter_points(L: int) -&gt; np.ndarray:\n    \"\"\"\n    Calculate the coordinates of the points located on the perimeter of a square of size L.\n    The square is centered at the origin (0, 0) with sides parallel to the axes.\n    The points are ordered starting from the bottom-left corner and moving\n    counter-clockwise around the square. The order is important when measuare the bitstrings\n\n    Args:\n        L (int): The length of the side of the square. L should be a positive integer.\n\n    Returns:\n        np.ndarray: An array of shape (4*L-4, 2) containing the coordinates of the perimeter points.\n\n    Example:\n        &gt;&gt;&gt; square_perimeter_points(3)\n        array([[-1, -1],\n               [-1,  0],\n               [-1,  1],\n               [ 0,  1],\n               [ 1,  1],\n               [ 1,  0],\n               [ 1, -1],\n               [ 0, -1]])\n    \"\"\"\n    pairOrodd = L % 2\n    toGrid = int(math.floor(L / 2))\n    if pairOrodd == 0:\n        axis = list(range(-toGrid, toGrid, 1))\n    else:\n        axis = list(range(-toGrid, toGrid + 1, 1))\n    coord = []\n    for i in axis:  # from left, first column of the perimeter\n        coord.append([axis[0], i])\n\n    for i in axis[1:-1]:\n        coord.append([i, axis[-1]])\n\n    for i in reversed(axis):\n        coord.append([axis[-1], i])\n\n    for i in reversed(axis[1:-1]):\n        coord.append([i, axis[0]])\n\n    return np.array(coord)\n</pre> def square_perimeter_points(L: int) -&gt; np.ndarray:     \"\"\"     Calculate the coordinates of the points located on the perimeter of a square of size L.     The square is centered at the origin (0, 0) with sides parallel to the axes.     The points are ordered starting from the bottom-left corner and moving     counter-clockwise around the square. The order is important when measuare the bitstrings      Args:         L (int): The length of the side of the square. L should be a positive integer.      Returns:         np.ndarray: An array of shape (4*L-4, 2) containing the coordinates of the perimeter points.      Example:         &gt;&gt;&gt; square_perimeter_points(3)         array([[-1, -1],                [-1,  0],                [-1,  1],                [ 0,  1],                [ 1,  1],                [ 1,  0],                [ 1, -1],                [ 0, -1]])     \"\"\"     pairOrodd = L % 2     toGrid = int(math.floor(L / 2))     if pairOrodd == 0:         axis = list(range(-toGrid, toGrid, 1))     else:         axis = list(range(-toGrid, toGrid + 1, 1))     coord = []     for i in axis:  # from left, first column of the perimeter         coord.append([axis[0], i])      for i in axis[1:-1]:         coord.append([i, axis[-1]])      for i in reversed(axis):         coord.append([axis[-1], i])      for i in reversed(axis[1:-1]):         coord.append([i, axis[0]])      return np.array(coord)"},{"location":"emu_sv/","title":"Welcome to emu-sv","text":"<p>You have found the documentation for emu-sv. The emulator emu-sv is a backend for the Pulser low-level Quantum Programming toolkit that lets you run quantum algorithms on a simulated device, using GPU acceleration if available. More in depth, emu-sv is designed to emulate the dynamics of programmable arrays of neutral atoms, using the state vector representation. While benchmarking is incomplete as of this writing, early results suggest that emu-sv is faster and more accurate than tensor-network based emulators up to ~20 qubits.</p>"},{"location":"emu_sv/#supported-features","title":"Supported features","text":"<p>The following features are currently supported:</p> <ul> <li>All Pulser sequences that use only the rydberg channel without complex phase</li> <li>States and Operators can be constructed using the abstract Pulser format.</li> <li>The following noise types:<ul> <li>None currently</li> </ul> </li> <li>The following basis states in a sequence:<ul> <li>ground-rydberg</li> </ul> </li> <li>The following properties from a Pulser Sequence are also correctly applied:<ul> <li>hardware modulation</li> <li>SLM mask</li> </ul> </li> <li>Customizable output, with the following inbuilt options:<ul> <li>The quantum state in state vector format</li> <li>Bitstrings</li> <li>The fidelity with respect to a given state</li> <li>The expectation of a given operator</li> <li>The qubit density (magnetization)</li> <li>The correlation matrix</li> <li>The mean, second moment and variance of the energy</li> </ul> </li> <li>Specification of<ul> <li>initial state</li> <li>various precision parameters</li> <li>whether to run on cpu or gpu(s)</li> </ul> </li> </ul>"},{"location":"emu_sv/#planned-features","title":"Planned features","text":"<ul> <li>The noises from the pulser <code>NoiseModel</code> using the density matrix formalism</li> <li>Differentiability</li> <li>Complex phases in the pulse.</li> <li>Overriding the interaction matrix</li> </ul>"},{"location":"emu_sv/#more-info","title":"More Info","text":"<p>Please see the API specification for a list of available config options (see here). For notebooks with examples for how to do various things, please see the notebooks page (see here).</p>"},{"location":"emu_sv/api/","title":"API specification","text":"<p>The emu-sv API is based on the specification here. Concretely, the classes are as follows:</p>"},{"location":"emu_sv/api/#svbackend","title":"SVBackend","text":"<p>               Bases: <code>EmulatorBackend</code></p> <p>A backend for emulating Pulser sequences using state vectors and sparse matrices. Noisy simulation is supported by solving the Lindblad equation and using effective noise channel or jump operators</p> Source code in <code>pulser/backend/abc.py</code> <pre><code>def __init__(\n    self,\n    sequence: pulser.Sequence,\n    *,\n    config: EmulationConfig | None = None,\n    mimic_qpu: bool = False,\n) -&gt; None:\n    \"\"\"Initializes the backend.\"\"\"\n    super().__init__(sequence, mimic_qpu=mimic_qpu)\n    config = config or self.default_config\n    if not isinstance(config, EmulationConfig):\n        raise TypeError(\n            \"'config' must be an instance of 'EmulationConfig', \"\n            f\"not {type(config)}.\"\n        )\n    # See the BackendConfig definition to see why this works\n    self._config = type(self.default_config)(**config._backend_options)\n</code></pre>"},{"location":"emu_sv/api/#emu_sv.sv_backend.SVBackend.run","title":"<code>run()</code>","text":"<p>Emulates the given sequence.</p> RETURNS DESCRIPTION <code>Results</code> <p>the simulation results</p> Source code in <code>emu_sv/sv_backend.py</code> <pre><code>def run(self) -&gt; Results:\n    \"\"\"\n    Emulates the given sequence.\n\n    Returns:\n        the simulation results\n    \"\"\"\n    assert isinstance(self._config, SVConfig)\n\n    impl = create_impl(self._sequence, self._config)\n    return impl._run()\n</code></pre>"},{"location":"emu_sv/api/#svconfig","title":"SVConfig","text":"<p>               Bases: <code>EmulationConfig</code></p> <p>The configuration of the emu-sv SVBackend. The kwargs passed to this class are passed on to the base class. See the API for that class for a list of available options.</p> PARAMETER DESCRIPTION <code>dt</code> <p>the timestep size that the solver uses. Note that observables are only calculated if the evaluation_times are divisible by dt.</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> <code>max_krylov_dim</code> <p>the size of the krylov subspace that the Lanczos algorithm maximally builds</p> <p> TYPE: <code>int</code> DEFAULT: <code>100</code> </p> <code>krylov_tolerance</code> <p>the Lanczos algorithm uses this as the convergence tolerance</p> <p> TYPE: <code>float</code> DEFAULT: <code>1e-10</code> </p> <code>gpu</code> <p>Use 1 gpu if True, and a GPU is available, otherwise, cpu. Will cause errors if True when a gpu is not available</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>interaction_cutoff</code> <p>Set interaction coefficients below this value to <code>0</code>. Potentially improves runtime and memory consumption.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> <code>log_level</code> <p>How much to log. Set to <code>logging.WARN</code> to get rid of the timestep info.</p> <p> TYPE: <code>int</code> DEFAULT: <code>INFO</code> </p> <code>log_file</code> <p>If specified, log to this file rather than stout.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>arguments that are passed to the base class</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; gpu = True\n&gt;&gt;&gt; dt = 1 #this will impact the runtime\n&gt;&gt;&gt; krylov_tolerance = 1e-8 #the simulation will be faster, but less accurate\n&gt;&gt;&gt; SVConfig(gpu=gpu, dt=dt, krylov_tolerance=krylov_tolerance,\n&gt;&gt;&gt;     with_modulation=True) #the last arg is taken from the base class\n</code></pre> Source code in <code>emu_sv/sv_config.py</code> <pre><code>def __init__(\n    self,\n    *,\n    dt: int = 10,\n    max_krylov_dim: int = 100,\n    krylov_tolerance: float = 1e-10,\n    gpu: bool = True,\n    interaction_cutoff: float = 0.0,\n    log_level: int = logging.INFO,\n    log_file: pathlib.Path | None = None,\n    **kwargs: Any,\n):\n    kwargs.setdefault(\"observables\", [BitStrings(evaluation_times=[1.0])])\n    super().__init__(\n        dt=dt,\n        max_krylov_dim=max_krylov_dim,\n        gpu=gpu,\n        krylov_tolerance=krylov_tolerance,\n        interaction_cutoff=interaction_cutoff,\n        log_level=log_level,\n        log_file=log_file,\n        **kwargs,\n    )\n\n    self.monkeypatch_observables()\n\n    self.logger = logging.getLogger(\"global_logger\")\n    if log_file is None:\n        logging.basicConfig(\n            level=log_level, format=\"%(message)s\", stream=sys.stdout, force=True\n        )  # default to stream = sys.stderr\n    else:\n        logging.basicConfig(\n            level=log_level,\n            format=\"%(message)s\",\n            filename=str(log_file),\n            filemode=\"w\",\n            force=True,\n        )\n    if (self.noise_model.runs != 1 and self.noise_model.runs is not None) or (\n        self.noise_model.samples_per_run != 1\n        and self.noise_model.samples_per_run is not None\n    ):\n        self.logger.warning(\n            \"Warning: The runs and samples_per_run \"\n            \"values of the NoiseModel are ignored!\"\n        )\n</code></pre>"},{"location":"emu_sv/api/#statevector","title":"StateVector","text":"<p>               Bases: <code>State[complex, Tensor]</code></p> <p>Represents a quantum state vector in a computational basis.</p> <p>This class extends the <code>State</code> class to handle state vectors, providing various utilities for initialization, normalization, manipulation, and measurement. The state vector must have a length that is a power of 2, representing 2\u207f basis states for n qubits.</p> ATTRIBUTE DESCRIPTION <code>vector</code> <p>1D tensor representation of a state vector.</p> <p> </p> <code>gpu</code> <p>store the vector on GPU if True, otherwise on CPU</p> <p> </p> Source code in <code>emu_sv/state_vector.py</code> <pre><code>def __init__(\n    self,\n    vector: torch.Tensor,\n    *,\n    gpu: bool = True,\n    eigenstates: Sequence[Eigenstate] = (\"r\", \"g\"),\n):\n    # NOTE: this accepts also zero vectors.\n\n    assert math.log2(\n        len(vector)\n    ).is_integer(), \"The number of elements in the vector should be power of 2\"\n\n    super().__init__(eigenstates=eigenstates)\n    device = \"cuda\" if gpu and DEVICE_COUNT &gt; 0 else \"cpu\"\n    self.vector = vector.to(dtype=dtype, device=device)\n</code></pre>"},{"location":"emu_sv/api/#emu_sv.state_vector.StateVector.n_qudits","title":"<code>n_qudits</code>  <code>property</code>","text":"<p>The number of qudits in the state.</p>"},{"location":"emu_sv/api/#emu_sv.state_vector.StateVector.__add__","title":"<code>__add__(other)</code>","text":"<p>Sum of two state vectors</p> PARAMETER DESCRIPTION <code>other</code> <p>the vector to add to this vector</p> <p> TYPE: <code>State</code> </p> RETURNS DESCRIPTION <code>StateVector</code> <p>The summed state</p> Source code in <code>emu_sv/state_vector.py</code> <pre><code>def __add__(self, other: State) -&gt; StateVector:\n    \"\"\"Sum of two state vectors\n\n    Args:\n        other: the vector to add to this vector\n\n    Returns:\n        The summed state\n    \"\"\"\n    assert isinstance(other, StateVector), \"`Other` state can only be a StateVector\"\n    assert (\n        self.eigenstates == other.eigenstates\n    ), f\"`Other` state has basis {other.eigenstates} != {self.eigenstates}\"\n    return StateVector(\n        self.vector + other.vector,\n        gpu=self.vector.is_cuda,\n        eigenstates=self.eigenstates,\n    )\n</code></pre>"},{"location":"emu_sv/api/#emu_sv.state_vector.StateVector.__rmul__","title":"<code>__rmul__(scalar)</code>","text":"<p>Scalar multiplication</p> PARAMETER DESCRIPTION <code>scalar</code> <p>the scalar to multiply with</p> <p> TYPE: <code>complex</code> </p> RETURNS DESCRIPTION <code>StateVector</code> <p>The scaled state</p> Source code in <code>emu_sv/state_vector.py</code> <pre><code>def __rmul__(self, scalar: complex) -&gt; StateVector:\n    \"\"\"Scalar multiplication\n\n    Args:\n        scalar: the scalar to multiply with\n\n    Returns:\n        The scaled state\n    \"\"\"\n    return StateVector(\n        scalar * self.vector,\n        gpu=self.vector.is_cuda,\n        eigenstates=self.eigenstates,\n    )\n</code></pre>"},{"location":"emu_sv/api/#emu_sv.state_vector.StateVector.inner","title":"<code>inner(other)</code>","text":"<p>Compute . The type of other must be StateVector. PARAMETER DESCRIPTION <code>other</code> <p>the other state</p> <p> TYPE: <code>State</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>the inner product</p> Source code in <code>emu_sv/state_vector.py</code> <pre><code>def inner(self, other: State) -&gt; torch.Tensor:\n    \"\"\"\n    Compute &lt;self|other&gt;. The type of other must be StateVector.\n\n    Args:\n        other: the other state\n\n    Returns:\n        the inner product\n    \"\"\"\n    assert isinstance(other, StateVector), \"Other state must be a StateVector\"\n    assert (\n        self.vector.shape == other.vector.shape\n    ), \"States do not have the same shape\"\n\n    # by our internal convention inner and norm return to cpu\n    return torch.vdot(self.vector, other.vector).cpu()\n</code></pre>"},{"location":"emu_sv/api/#emu_sv.state_vector.StateVector.make","title":"<code>make(num_sites, gpu=True)</code>  <code>classmethod</code>","text":"<p>Returns a State vector in the ground state |00..0&gt;.</p> PARAMETER DESCRIPTION <code>num_sites</code> <p>the number of qubits</p> <p> TYPE: <code>int</code> </p> <code>gpu</code> <p>whether gpu or cpu</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>StateVector</code> <p>The described state</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; StateVector.make(2,gpu=False)\ntensor([1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j], dtype=torch.complex128)\n</code></pre> Source code in <code>emu_sv/state_vector.py</code> <pre><code>@classmethod\ndef make(cls, num_sites: int, gpu: bool = True) -&gt; StateVector:\n    \"\"\"\n    Returns a State vector in the ground state |00..0&gt;.\n\n    Args:\n        num_sites: the number of qubits\n        gpu: whether gpu or cpu\n\n    Returns:\n        The described state\n\n    Examples:\n        &gt;&gt;&gt; StateVector.make(2,gpu=False)\n        tensor([1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j], dtype=torch.complex128)\n\n\n    \"\"\"\n\n    result = cls.zero(num_sites=num_sites, gpu=gpu)\n    result.vector[0] = 1.0\n    return result\n</code></pre>"},{"location":"emu_sv/api/#emu_sv.state_vector.StateVector.norm","title":"<code>norm()</code>","text":"<p>Returns the norm of the state</p> RETURNS DESCRIPTION <code>Tensor</code> <p>the norm of the state</p> Source code in <code>emu_sv/state_vector.py</code> <pre><code>def norm(self) -&gt; torch.Tensor:\n    \"\"\"Returns the norm of the state\n\n    Returns:\n        the norm of the state\n    \"\"\"\n    nrm: torch.Tensor = torch.linalg.vector_norm(self.vector).cpu()\n    return nrm\n</code></pre>"},{"location":"emu_sv/api/#emu_sv.state_vector.StateVector.sample","title":"<code>sample(*, num_shots=1000, one_state=None, p_false_pos=0.0, p_false_neg=0.0)</code>","text":"<p>Samples bitstrings, taking into account the specified error rates.</p> PARAMETER DESCRIPTION <code>num_shots</code> <p>how many bitstrings to sample</p> <p> TYPE: <code>int</code> DEFAULT: <code>1000</code> </p> <code>p_false_pos</code> <p>the rate at which a 0 is read as a 1</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> <code>p_false_neg</code> <p>teh rate at which a 1 is read as a 0</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> RETURNS DESCRIPTION <code>Counter[str]</code> <p>the measured bitstrings, by count</p> Source code in <code>emu_sv/state_vector.py</code> <pre><code>def sample(\n    self,\n    *,\n    num_shots: int = 1000,\n    one_state: Eigenstate | None = None,\n    p_false_pos: float = 0.0,\n    p_false_neg: float = 0.0,\n) -&gt; Counter[str]:\n    \"\"\"\n    Samples bitstrings, taking into account the specified error rates.\n\n    Args:\n        num_shots: how many bitstrings to sample\n        p_false_pos: the rate at which a 0 is read as a 1\n        p_false_neg: teh rate at which a 1 is read as a 0\n\n    Returns:\n        the measured bitstrings, by count\n    \"\"\"\n\n    probabilities = torch.abs(self.vector) ** 2\n\n    outcomes = torch.multinomial(probabilities, num_shots, replacement=True)\n\n    # Convert outcomes to bitstrings and count occurrences\n    counts = Counter(\n        [index_to_bitstring(self.n_qudits, outcome) for outcome in outcomes]\n    )\n\n    if p_false_neg &gt; 0 or p_false_pos &gt; 0:\n        counts = apply_measurement_errors(\n            counts,\n            p_false_pos=p_false_pos,\n            p_false_neg=p_false_neg,\n        )\n    return counts\n</code></pre>"},{"location":"emu_sv/api/#emu_sv.state_vector.StateVector.zero","title":"<code>zero(num_sites, gpu=True, eigenstates=('r', 'g'))</code>  <code>classmethod</code>","text":"<p>Returns a zero uninitialized \"state\" vector. Warning, this has no physical meaning as-is!</p> PARAMETER DESCRIPTION <code>num_sites</code> <p>the number of qubits</p> <p> TYPE: <code>int</code> </p> <code>gpu</code> <p>whether gpu or cpu</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>StateVector</code> <p>The zero state</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; StateVector.zero(2,gpu=False)\ntensor([0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j], dtype=torch.complex128)\n</code></pre> Source code in <code>emu_sv/state_vector.py</code> <pre><code>@classmethod\ndef zero(\n    cls,\n    num_sites: int,\n    gpu: bool = True,\n    eigenstates: Sequence[Eigenstate] = (\"r\", \"g\"),\n) -&gt; StateVector:\n    \"\"\"\n    Returns a zero uninitialized \"state\" vector. Warning, this has no physical meaning as-is!\n\n    Args:\n        num_sites: the number of qubits\n        gpu: whether gpu or cpu\n\n    Returns:\n        The zero state\n\n    Examples:\n        &gt;&gt;&gt; StateVector.zero(2,gpu=False)\n        tensor([0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j], dtype=torch.complex128)\n    \"\"\"\n\n    device = \"cuda\" if gpu and DEVICE_COUNT &gt; 0 else \"cpu\"\n    vector = torch.zeros(2**num_sites, dtype=dtype, device=device)\n    return cls(vector, gpu=gpu, eigenstates=eigenstates)\n</code></pre>"},{"location":"emu_sv/api/#inner","title":"inner","text":"<p>Wrapper around StateVector.inner.</p> PARAMETER DESCRIPTION <code>left</code> <p>StateVector argument</p> <p> TYPE: <code>StateVector</code> </p> <code>right</code> <p>StateVector argument</p> <p> TYPE: <code>StateVector</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>the inner product</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; factor = math.sqrt(2.0)\n&gt;&gt;&gt; basis = (\"r\",\"g\")\n&gt;&gt;&gt; string_state1 = {\"gg\":1.0,\"rr\":1.0}\n&gt;&gt;&gt; state1 = StateVector.from_state_string(basis=basis,\n    ... nqubits=nqubits,strings=string_state1)\n&gt;&gt;&gt; string_state2 = {\"gr\":1.0/factor,\"rr\":1.0/factor}\n&gt;&gt;&gt; state2 = StateVector.from_state_string(basis=basis,\n    ... nqubits=nqubits,strings=string_state2)\n</code></pre> <pre><code>&gt;&gt;&gt; state1 = StateVector.from_state_amplitudes(eigenstates=basis,\n...     amplitudes=string_state1)\n&gt;&gt;&gt; string_state2 = {\"gr\":1.0/factor,\"rr\":1.0/factor}\n&gt;&gt;&gt; state2 = StateVector.from_state_amplitudes(eigenstates=basis,\n...     amplitudes=string_state2)\n&gt;&gt;&gt; inner(state1,state2).item()\n(0.49999999144286444+0j)\n</code></pre> Source code in <code>emu_sv/state_vector.py</code> <pre><code>def inner(left: StateVector, right: StateVector) -&gt; torch.Tensor:\n    \"\"\"\n    Wrapper around StateVector.inner.\n\n    Args:\n        left:  StateVector argument\n        right: StateVector argument\n\n    Returns:\n        the inner product\n\n    Examples:\n        &gt;&gt;&gt; factor = math.sqrt(2.0)\n        &gt;&gt;&gt; basis = (\"r\",\"g\")\n        &gt;&gt;&gt; string_state1 = {\"gg\":1.0,\"rr\":1.0}\n        &gt;&gt;&gt; state1 = StateVector.from_state_string(basis=basis,\n            ... nqubits=nqubits,strings=string_state1)\n        &gt;&gt;&gt; string_state2 = {\"gr\":1.0/factor,\"rr\":1.0/factor}\n        &gt;&gt;&gt; state2 = StateVector.from_state_string(basis=basis,\n            ... nqubits=nqubits,strings=string_state2)\n\n        &gt;&gt;&gt; state1 = StateVector.from_state_amplitudes(eigenstates=basis,\n        ...     amplitudes=string_state1)\n        &gt;&gt;&gt; string_state2 = {\"gr\":1.0/factor,\"rr\":1.0/factor}\n        &gt;&gt;&gt; state2 = StateVector.from_state_amplitudes(eigenstates=basis,\n        ...     amplitudes=string_state2)\n        &gt;&gt;&gt; inner(state1,state2).item()\n        (0.49999999144286444+0j)\n    \"\"\"\n\n    assert (left.vector.shape == right.vector.shape) and (left.vector.dim() == 1), (\n        \"Shape of left.vector and right.vector should be\",\n        \" the same and both need to be 1D tesnor\",\n    )\n    return left.inner(right)\n</code></pre>"},{"location":"emu_sv/api/#denseoperator","title":"DenseOperator","text":"<p>               Bases: <code>Operator[complex, Tensor, StateVector]</code></p> <p>DenseOperator in EMU-SV use dense matrices</p> Source code in <code>emu_sv/dense_operator.py</code> <pre><code>def __init__(\n    self,\n    matrix: torch.Tensor,\n    *,\n    gpu: bool = True,\n):\n    device = \"cuda\" if gpu and DEVICE_COUNT &gt; 0 else \"cpu\"\n    self.matrix = matrix.to(dtype=dtype, device=device)\n</code></pre>"},{"location":"emu_sv/api/#emu_sv.dense_operator.DenseOperator.__add__","title":"<code>__add__(other)</code>","text":"<p>Element-wise addition of two DenseOperators.</p> PARAMETER DESCRIPTION <code>other</code> <p>a DenseOperator instance.</p> <p> TYPE: <code>Operator</code> </p> RETURNS DESCRIPTION <code>DenseOperator</code> <p>A new DenseOperator representing the sum.</p> Source code in <code>emu_sv/dense_operator.py</code> <pre><code>def __add__(self, other: Operator) -&gt; DenseOperator:\n    \"\"\"\n    Element-wise addition of two DenseOperators.\n\n    Args:\n        other: a DenseOperator instance.\n\n    Returns:\n        A new DenseOperator representing the sum.\n    \"\"\"\n    assert isinstance(\n        other, DenseOperator\n    ), \"DenseOperator can only be added to another DenseOperator.\"\n    return DenseOperator(self.matrix + other.matrix)\n</code></pre>"},{"location":"emu_sv/api/#emu_sv.dense_operator.DenseOperator.__matmul__","title":"<code>__matmul__(other)</code>","text":"<p>Compose two DenseOperators via matrix multiplication.</p> PARAMETER DESCRIPTION <code>other</code> <p>a DenseOperator instance.</p> <p> TYPE: <code>Operator</code> </p> RETURNS DESCRIPTION <code>DenseOperator</code> <p>A new DenseOperator representing the product <code>self @ other</code>.</p> Source code in <code>emu_sv/dense_operator.py</code> <pre><code>def __matmul__(self, other: Operator) -&gt; DenseOperator:\n    \"\"\"\n    Compose two DenseOperators via matrix multiplication.\n\n    Args:\n        other: a DenseOperator instance.\n\n    Returns:\n        A new DenseOperator representing the product `self @ other`.\n    \"\"\"\n    assert isinstance(\n        other, DenseOperator\n    ), \"DenseOperator can only be multiplied with a DenseOperator.\"\n    return DenseOperator(self.matrix @ other.matrix)\n</code></pre>"},{"location":"emu_sv/api/#emu_sv.dense_operator.DenseOperator.__rmul__","title":"<code>__rmul__(scalar)</code>","text":"<p>Scalar multiplication of the DenseOperator.</p> PARAMETER DESCRIPTION <code>scalar</code> <p>a number to scale the operator.</p> <p> TYPE: <code>complex</code> </p> RETURNS DESCRIPTION <code>DenseOperator</code> <p>A new DenseOperator scaled by the given scalar.</p> Source code in <code>emu_sv/dense_operator.py</code> <pre><code>def __rmul__(self, scalar: complex) -&gt; DenseOperator:\n    \"\"\"\n    Scalar multiplication of the DenseOperator.\n\n    Args:\n        scalar: a number to scale the operator.\n\n    Returns:\n        A new DenseOperator scaled by the given scalar.\n    \"\"\"\n\n    return DenseOperator(scalar * self.matrix)\n</code></pre>"},{"location":"emu_sv/api/#emu_sv.dense_operator.DenseOperator.apply_to","title":"<code>apply_to(other)</code>","text":"<p>Apply the DenseOperator to a given StateVector.</p> PARAMETER DESCRIPTION <code>other</code> <p>a StateVector instance.</p> <p> TYPE: <code>State</code> </p> RETURNS DESCRIPTION <code>StateVector</code> <p>A new StateVector after applying the operator.</p> Source code in <code>emu_sv/dense_operator.py</code> <pre><code>def apply_to(self, other: State) -&gt; StateVector:\n    \"\"\"\n    Apply the DenseOperator to a given StateVector.\n\n    Args:\n        other: a StateVector instance.\n\n    Returns:\n        A new StateVector after applying the operator.\n    \"\"\"\n    assert isinstance(\n        other, StateVector\n    ), \"DenseOperator can only be applied to a StateVector.\"\n\n    return StateVector(self.matrix @ other.vector)\n</code></pre>"},{"location":"emu_sv/api/#emu_sv.dense_operator.DenseOperator.expect","title":"<code>expect(state)</code>","text":"<p>Compute the expectation value of the operator with respect to a state.</p> PARAMETER DESCRIPTION <code>state</code> <p>a StateVector instance.</p> <p> TYPE: <code>State</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>The expectation value as a float or complex number.</p> Source code in <code>emu_sv/dense_operator.py</code> <pre><code>def expect(self, state: State) -&gt; torch.Tensor:\n    \"\"\"\n    Compute the expectation value of the operator with respect to a state.\n\n    Args:\n        state: a StateVector instance.\n\n    Returns:\n        The expectation value as a float or complex number.\n    \"\"\"\n    assert isinstance(\n        state, StateVector\n    ), \"Only expectation values of StateVectors are supported.\"\n\n    return torch.vdot(state.vector, self.apply_to(state).vector).cpu()\n</code></pre>"},{"location":"emu_sv/benchmarks/","title":"emu-sv benchmarks","text":"<p>All the benchmarks are run on a single NVIDIA A100 GPU of Pasqal's DGX-cluster and for best performance on heavy workloads we recommend using a similar setup. There, users should expect emu-sv to emulate up to 25 qubits, regardless of the pulse sequence. However, close to this limit, performance will decrease exponentially in the qubit number, and emu-mps is likely to be faster.</p>"},{"location":"emu_sv/benchmarks/#use-case-benchmarks","title":"Use-case benchmarks","text":"<p>Benchmark efforts, documented here, are meant to provide insights for emu-sv users about</p> <ul> <li>Performance: runtime</li> <li>Accuracy: different precision levels as compared to pulser-simulation</li> </ul> <p>given a set of meaningful sequences of interest (quench, adiabatic and use-case sequences) that we are going to introduce case by case. Finally, we will only focus on 2D atomic registers as they represent the most numerically challenging and interesting case to study.</p> <p>The benchmarks are ordered in subpages by general topic.</p> <ul> <li>Accuracy</li> <li>Performance</li> </ul> <p>The accuracy benchmarks compare results between emulators to create confidence in the results emu-sv generates. The performance benchmarks exist to exhibit the runtime characteristics of emu-sv. Based on these, the reader should get a feel for what kind of parameters would be required to be able to run a given sequence in a given time.</p>"},{"location":"emu_sv/benchmarks/#sequences-used","title":"Sequences used","text":"<ul> <li>Adiabatic evolution: Here at each time step, the evolution of the driving \\(\\Omega, \\Delta\\) is slow enough to guarantee that the evolved state is still an equilibrium state of \\(H\\). Note that the adiabaticity of a sequence is dependent on the energy gaps in the Hamiltonian, and since these gaps decrease with qubit number, most sequences are only adiabatic up to a given qubit number.</li> </ul> <pre><code># from https://pulser.readthedocs.io/en/stable/tutorials/afm_prep.html\n# parameters in rad/\u00b5s and ns\nOmega_max = 2.0 * 2 * np.pi\nU = Omega_max / 2.0\ndelta_0 = -6 * U\ndelta_f = 2 * U\nt_rise = 500\nt_fall = 1000\nt_sweep = (delta_f - delta_0) / (2 * np.pi * 10) * 3000\nR_interatomic = MockDevice.rydberg_blockade_radius(U)\nreg = Register.rectangle(rows, columns, R_interatomic, prefix=\"q\")\nif perm_map:\n    reg_coords = reg._coords\n    reg = Register.from_coordinates([reg_coords[i] for i in perm_map])\nrise = Pulse.ConstantDetuning(RampWaveform(t_rise, 0.0, Omega_max), delta_0, 0.0)\nsweep = Pulse.ConstantAmplitude(\n    Omega_max, RampWaveform(t_sweep, delta_0, delta_f), 0.0\n)\nfall = Pulse.ConstantDetuning(RampWaveform(t_fall, Omega_max, 0.0), delta_f, 0.0)\nseq = Sequence(reg, MockDevice)\nseq.declare_channel(\"ising\", \"rydberg_global\")\nseq.add(rise, \"ising\")\nseq.add(sweep, \"ising\")\nseq.add(fall, \"ising\")\n</code></pre> <ul> <li>Quench: One of the most fundamental protocols to drive a system out of equilibrium, it is realized here as follows: at time \\(t=0\\) the system is prepared in the ground state \\(|\\psi_0\\rangle\\) of \\(H_0\\). The driving field is then suddenly turned on (\\(\\Omega\\neq0\\)) and the system is evolved for \\(t &gt; 0\\), as \\(|\\psi\\rangle=e^{-iHt}|\\psi_0\\rangle\\).</li> </ul> <pre><code>hx = 1.5  # hx/J_max\nhz = 0  # hz/J_max\nt = 1.5  # t/J_max\n# Set up Pulser simulations\nR = 7  # \u03bcm\nreg = Register.rectangle(nx, ny, R, prefix=\"q\")\n# Conversion from Rydberg Hamiltonian to Ising model\nU = AnalogDevice.interaction_coeff / R**6  # U_ij\nNN_coeff = U / 4\nomega = 2 * hx * NN_coeff\ndelta = -2 * hz * NN_coeff + 2 * U\nT = np.round(1000 * t / NN_coeff)\nseq = Sequence(reg, MockDevice) #circumvent the register spacing constraints\nseq.declare_channel(\"ising\", \"rydberg_global\")\n# Add the main pulse to the pulse sequence\nsimple_pulse = Pulse.ConstantPulse(T, omega, delta, 0)\nseq.add(simple_pulse, \"ising\")\n</code></pre> <p>For emu-sv the relevant difference between the two is that the adiabatic sequence is (weakly) time-dependent, and the quench is not time-dependent at all. This has an effect on the accuracy with which they're simulated (see the accuracy page).</p>"},{"location":"emu_sv/benchmarks/#cpugpu-hardware","title":"CPU/GPU hardware","text":"<p>Emu-sv is built on top of pytorch. Thus, it can run on most available CPUs and GPUs, from a laptop to a cluster. The presented benchmarks are run on an NVIDIA DGX cluster node, requesting the following resources</p> <ul> <li>GPU: 1 NVIDIA A100 (40 GB)</li> <li>CPU: a benchmark-dependent number of cores on an AMD EPYC 7742</li> </ul> <p>Of course, performance will vary depending on the hardware. For this reason, if at any point of your work, performance becomes critical, we always recommend to use Pasqal's DGX cluster. If you intend to run emu-sv on your laptop, for example, please be aware that the suggestion to use a GPU for heavier workloads might not be valid. In such case it is always good to check performance on a couple of runs, changing the emu-sv config default values as documented in the API. In particular <code>gpu = False</code> will run the emulation on CPU, while <code>gpu = True</code> will run it on GPU.</p>"},{"location":"emu_sv/benchmarks/accuracy/","title":"Accuracy","text":"<p>Here we discuss the emulator accuracy, as compared to Pulser state vector solver backend, but in the future we might directly compare with QPU results. Accuracy, here, specifically refers to observables:</p> <ul> <li>Energy: \\(E = \\langle\\psi|H|\\psi\\rangle\\)</li> <li>Energy variance: \\(\\Delta E = \\langle\\psi|H^2|\\psi\\rangle-E^2\\)</li> <li>Magnetization: \\(\\langle P_{0}^j\\rangle\\) where \\(P_{0}^j\\) projects qubit \\(j\\) onto the \\(|0\\rangle\\) state</li> </ul> <p>The emulated sequences are going to be the same as before, an adiabatic and a quench. In both cases, 9 qubits arrayed in a 3x3 grid are used, so that the results can also be simulated in Pulser. We will check accuracy against two main tunable parameters in emu-sv:</p> <ul> <li><code>krylov_tolerance</code>: the convergence tolerance when exponentiating the Hamiltonian in each time-step.</li> <li><code>dt</code>: sampling time step of the sequence.</li> </ul> <p>The goal is to show that for qubit numbers accessible to Pulser, the results are identical up to good precision.</p> <p> </p> <p>It is worth noting that for the quench sequence (where the Hamiltonian is constant in time), emu-sv is more accurate. The evolution method used by emu-sv, evolving the system by assuming the Hamiltonian is constant for intervals of length <code>dt</code> is exact in this case. The <code>krylov_tolerance</code> is an estimate of the error incurred in each time-step, which experimentally overestimates the error for values &lt; <code>1e-8</code>, and the deviation with pulser is an order of magnitude larger. This is consistent with the accuracy settings used by pulser-simulation internally.</p> <p>This is interesting to contrast with the results for the adiabatic sequence, where the emu-sv solver shows deviations from pulser-simulation due to the assumption of piecewise-constant Hamiltonian. The difference between pulser-simulation and emu-sv decreases with decreasing <code>dt</code>, as the step-function used by emu-sv more closely resembles the qubic interpolation done by pulser-simulation. Which emulator should be considered closer to the truth depends on what is desired. When hardware modulation is taken into account, response times in the QPU hardware make the actual time-dependent Hamiltonian smooth as a function of time, and the qubic interpolation in pulser-simulation is closer to the truth. When ignoring hardware modulation, one assumes a model of the hardware where the laser is piecewise constant, and switches discretely at the device resolution. This implies emu-sv models the abstract ideal device more closely. That said, agreement between pulser-simulation and emu-sv is likely to be good enough for most applications.</p>"},{"location":"emu_sv/benchmarks/performance/","title":"Performance","text":"<p>Here, as anticipated in the introduction page of the benchmarks, we will track the runtime of emu-sv by comparing runs on GPU vs CPU, and CPU vs pulser-simulation (which is cpu only).</p>"},{"location":"emu_sv/benchmarks/performance/#adiabatic-sequence","title":"Adiabatic sequence","text":"<p>We run an adiabatic sequence to make an antiferromagnetic (AFM) state, as taken from Pulser documentation, for a line of atoms. In contrast to emu-mps, the performance of emu-sv does not depend on the type of sequence, other than through its duration, so there is no real benefit to showing results for the adiabatic and the quench sequence separately.</p> <p>First, let us compare emu-sv with pulser:</p> <p>Runtimes are shown for two different values of <code>dt</code> which shows that halving <code>dt</code> almost doubles the runtime. Halving <code>dt</code> doubles the number of timesteps taken by the program, but the algorithm for computing a single timestep converges faster, leading to a sublinear scaling of the runtime in terms of the number of timesteps. For larger values of <code>dt</code> emu-sv can be seen to outperform pulser for 8 qubits and up on the cluster, while for the smallest possible <code>dt = 1</code>, it will be faster starting at <code>9</code> qubits.</p> <p>Next, let us compare runs of emu-sv between CPU and GPU:</p> <p>There is a marginal runtime difference between CPU and GPU for smaller qubit numbers, which is mostly coincidental, since neither hardware is saturated with computations yet, and exponential scaling of the runtime has not yet set in. When comparing the runtimes between 19 and 20 qubits, they can be seen to roughly double for both CPU and GPU, as expected by exponential scaling. This shows that for larger qubit numbers, the GPU is about 4 times faster than CPU. Contrast this with the benchmarks of emu-mps, which show a relative factor of about 20 for larger bond-dimensions, a number much closer to the theoretical ratio of computational power. This suggests there are improvements to be made in the performance of emu-sv on gpu at least.</p>"},{"location":"emu_sv/notebooks/","title":"Example Notebooks","text":"<p>You have found the base page for all our example notebooks. Here you find rendered web versions of the notebooks, the originals are available in the repo (see here).</p>"},{"location":"emu_sv/notebooks/getting_started/","title":"Emulation of sequences: AFM state sequence","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport pulser\n</pre> import numpy as np import matplotlib.pyplot as plt import pulser In\u00a0[2]: Copied! <pre># Setup\nL = 10\n\nOmega_max = 2.3 * 2 * np.pi\nU = Omega_max / 2.3\n\ndelta_0 = -3 * U\ndelta_f = 1 * U\n\nt_rise = 2000\nt_fall = 2000\nt_sweep = (delta_f - delta_0) / (2 * np.pi * 10) * 5000\n\n# Define a ring of atoms distanced by a blockade radius distance:\nR_interatomic = pulser.MockDevice.rydberg_blockade_radius(U)\ncoords = (\n    R_interatomic\n    / (2 * np.sin(np.pi / L))\n    * np.array(\n        [\n            (np.cos(theta * 2 * np.pi / L), np.sin(theta * 2 * np.pi / L))\n            for theta in range(L)\n        ]\n    )\n)\n\n# ring, periodic register\nreg = pulser.Register.from_coordinates(coords, prefix=\"q\")\n# or try open boundaries\n#reg = pulser.Register.rectangle(1,L,spacing=R_interatomic/1.2, prefix=\"q\")\n\nreg.draw(blockade_radius=R_interatomic, draw_half_radius=True, draw_graph=True)\n</pre> # Setup L = 10  Omega_max = 2.3 * 2 * np.pi U = Omega_max / 2.3  delta_0 = -3 * U delta_f = 1 * U  t_rise = 2000 t_fall = 2000 t_sweep = (delta_f - delta_0) / (2 * np.pi * 10) * 5000  # Define a ring of atoms distanced by a blockade radius distance: R_interatomic = pulser.MockDevice.rydberg_blockade_radius(U) coords = (     R_interatomic     / (2 * np.sin(np.pi / L))     * np.array(         [             (np.cos(theta * 2 * np.pi / L), np.sin(theta * 2 * np.pi / L))             for theta in range(L)         ]     ) )  # ring, periodic register reg = pulser.Register.from_coordinates(coords, prefix=\"q\") # or try open boundaries #reg = pulser.Register.rectangle(1,L,spacing=R_interatomic/1.2, prefix=\"q\")  reg.draw(blockade_radius=R_interatomic, draw_half_radius=True, draw_graph=True) <p>We use the drawing capabilities of the Register class to highlight the area half the blockade radius away from each atom, which makes it so that overlapping circles correspond to interacting atoms. This is further fleshed out by the graph edges drawn using the draw_graph option.</p> <p>In this register, we shall act with the following <code>pulser.Sequence</code>, which is designed to reach a state with antiferromagnetic order:</p> In\u00a0[3]: Copied! <pre>rise = pulser.Pulse.ConstantDetuning(\n    pulser.RampWaveform(t_rise, 0.0, Omega_max), delta_0, 0.0\n)\nsweep = pulser.Pulse.ConstantAmplitude(\n    Omega_max, pulser.RampWaveform(t_sweep, delta_0, delta_f), 0.0\n)\nfall = pulser.Pulse.ConstantDetuning(\n    pulser.RampWaveform(t_fall, Omega_max, 0.0), delta_f, 0.0\n)\n\nseq = pulser.Sequence(reg, pulser.MockDevice)\nseq.declare_channel(\"global\", \"rydberg_global\")\n\nseq.add(rise, \"global\")\nseq.add(sweep, \"global\")\nseq.add(fall, \"global\")\n\nseq.draw()\n</pre> rise = pulser.Pulse.ConstantDetuning(     pulser.RampWaveform(t_rise, 0.0, Omega_max), delta_0, 0.0 ) sweep = pulser.Pulse.ConstantAmplitude(     Omega_max, pulser.RampWaveform(t_sweep, delta_0, delta_f), 0.0 ) fall = pulser.Pulse.ConstantDetuning(     pulser.RampWaveform(t_fall, Omega_max, 0.0), delta_f, 0.0 )  seq = pulser.Sequence(reg, pulser.MockDevice) seq.declare_channel(\"global\", \"rydberg_global\")  seq.add(rise, \"global\") seq.add(sweep, \"global\") seq.add(fall, \"global\")  seq.draw() <p>First, we need to initialize the desired observables, their evaluation times, and the basis. In this example we chose the final state and the occupation $\\langle n_i \\rangle$ profile.</p> In\u00a0[4]: Copied! <pre>from emu_sv import StateResult, SVConfig, Occupation\n\ndt = 10  # timestep in ns\nseq_duration = seq.get_duration()\n\neval_times = [t/seq_duration for t in range(dt, seq_duration, dt)]\nfinal_time = eval_times[-1]\n\ndensity = Occupation(evaluation_times=eval_times)\nstate = StateResult(evaluation_times=[final_time])  # get the state at final time\n\nconfig = SVConfig(dt=dt, observables = [density, state], log_level=2000)\n</pre> from emu_sv import StateResult, SVConfig, Occupation  dt = 10  # timestep in ns seq_duration = seq.get_duration()  eval_times = [t/seq_duration for t in range(dt, seq_duration, dt)] final_time = eval_times[-1]  density = Occupation(evaluation_times=eval_times) state = StateResult(evaluation_times=[final_time])  # get the state at final time  config = SVConfig(dt=dt, observables = [density, state], log_level=2000)  <p>As a next step, we initialize the state vector backend.</p> <p>To run the simulation we simply use the method <code>run()</code> of the backend, passing the sequence we wish to emulate and the config file. It returns a <code>Results</code> object, which will allow the study or post-processing of the states for each time step in our simulation.</p> In\u00a0[5]: Copied! <pre>from emu_sv import SVBackend\n\nbknd = SVBackend(seq, config=config)\nresults = bknd.run()\n</pre> from emu_sv import SVBackend  bknd = SVBackend(seq, config=config) results = bknd.run() In\u00a0[6]: Copied! <pre>last_elem = -1\nresults.state[last_elem].vector[:10]\n</pre> last_elem = -1 results.state[last_elem].vector[:10] Out[6]: <pre>tensor([-2.2128e-05+0.0002j,  8.0325e-04-0.0002j,  8.0325e-04-0.0002j,\n        -7.4170e-04+0.0004j,  8.0325e-04-0.0002j, -1.6267e-03-0.0034j,\n        -7.4170e-04+0.0004j,  7.1285e-04-0.0003j,  8.0325e-04-0.0002j,\n        -2.7328e-03-0.0029j], device='cuda:0', dtype=torch.complex128)</pre> <p>We can sample the final state directly, using its <code>sample()</code> method from the <code>Results</code> object. For example, we sample it and discard the less frequent bitstrings:</p> In\u00a0[7]: Copied! <pre>last_elem = -1\nfinal_state = results.state[last_elem]\n\ncounts = final_state.sample(num_shots=1000)\n\nlarge_counts = {k: v for k, v in counts.items() if v &gt; 5}\n\nplt.figure(figsize=(15, 4))\nplt.xticks(rotation=90, fontsize=14)\nplt.title(\"Most frequent observations\")\nplt.bar(large_counts.keys(), large_counts.values())\n</pre> last_elem = -1 final_state = results.state[last_elem]  counts = final_state.sample(num_shots=1000)  large_counts = {k: v for k, v in counts.items() if v &gt; 5}  plt.figure(figsize=(15, 4)) plt.xticks(rotation=90, fontsize=14) plt.title(\"Most frequent observations\") plt.bar(large_counts.keys(), large_counts.values()) Out[7]: <pre>&lt;BarContainer object of 62 artists&gt;</pre> <p>Notice how the most frequent bitstrings correspond to the antiferromagnetic order states.</p> <p>We can also get the expectation values of operators for the states in the evolution. Since we asked for the occupation number $\\langle n_i \\rangle$ (the Rydberg state population) in the config, we can plot its time evolution on each atom.</p> In\u00a0[8]: Copied! <pre>times = np.array(eval_times)*seq.get_duration()\n#\narray_of_occup = [np.array(results.occupation[i])  for i, t in enumerate(times)]\noccup = np.stack(array_of_occup, axis=1)\n\nfig, axs = plt.subplots(1,2, figsize=(8,4))\n\nfor i in range(L):\n    axs[0].plot(times[0:], occup[i,:])\naxs[0].set_xlabel(\"time [ns]\")\naxs[0].set_ylabel(r\"$\\langle n_i\\rangle$\")\n\npc = axs[1].pcolor(times, range(L), occup)\naxs[1].set_xlabel(\"time [ns]\")\naxs[1].set_ylabel(\"qubit\")\nfig.colorbar(pc, ax=axs[1], label = r\"$\\langle Z_i\\rangle$\")\n</pre> times = np.array(eval_times)*seq.get_duration() # array_of_occup = [np.array(results.occupation[i])  for i, t in enumerate(times)] occup = np.stack(array_of_occup, axis=1)  fig, axs = plt.subplots(1,2, figsize=(8,4))  for i in range(L):     axs[0].plot(times[0:], occup[i,:]) axs[0].set_xlabel(\"time [ns]\") axs[0].set_ylabel(r\"$\\langle n_i\\rangle$\")  pc = axs[1].pcolor(times, range(L), occup) axs[1].set_xlabel(\"time [ns]\") axs[1].set_ylabel(\"qubit\") fig.colorbar(pc, ax=axs[1], label = r\"$\\langle Z_i\\rangle$\") Out[8]: <pre>&lt;matplotlib.colorbar.Colorbar at 0x73b869e0e410&gt;</pre> <p>Notice how the local occupation $\\langle n_i \\rangle$ on each atom goes in the same way from 0 (which corresponds to the ground state) to 1/2. This is expected since as we saw above, the state after the evolution has antiferromagnetic-order, so at each site, there is a compensation of occupation. The parity (even) and the boundary conditions (periodic) allow for two lowest-energy states, whose superposition is similar to that of the perfectly antiferromagnetic state: $\\left( |rgrg\\dots\\rangle+|grgr\\dots\\rangle \\right)/\\sqrt{2}$</p>"},{"location":"emu_sv/notebooks/getting_started/#emulation-of-sequences-afm-state-sequence","title":"Emulation of sequences: AFM state sequence\u00b6","text":"<p>This example is taken from Pulser documentation.</p> <p>To illustrate the simulation of sequences, let us study a simple one-dimensional system with periodic boundary conditions (a ring of atoms):</p>"},{"location":"emu_sv/notebooks/getting_started/#1-running-an-emulation","title":"1. Running an emulation\u00b6","text":""},{"location":"emu_sv/notebooks/getting_started/#2-using-the-results","title":"2. Using the <code>Results</code>\u00b6","text":"<p>The <code>Results</code> object returned at the end of an emulation run, is a dictionary that contains the observables defined above, at each time step. We can access them using their name and time. The <code>Results</code> object that we created contains the final quantum state for example:</p>"}]}