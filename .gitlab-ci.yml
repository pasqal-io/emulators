# Change pip's cache directory to be inside the project directory since we can
# only cache local items.
variables:
  PACKAGE: "emu-ct"
  PIP_CACHE_DIR: "$CI_PROJECT_DIR/.cache/pip"
  REPOSITORY_BASE_URL: 9ygszqk0.gra7.container-registry.ovh.net
  REPOSITORY_NAME: $REPOSITORY_BASE_URL/emulators/emu-mps
  HATCH_INDEX_USER: $PYPI_USERNAME
  HATCH_INDEX_AUTH: $PYPI_PASSWORD
  HATCH_INDEX_REPO: $PYPI_URL
  PROTECT: "slurm"

default:
  interruptible: true

# The rules are from Workflows/MergeRequest-Pipelines.gitlab-ci.yml
# but we can't extend the template so they are duplicated here.
workflow:
  rules:
    - if: $CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS && $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_REF_PROTECTED != "true"
      when: never
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_TAG
      variables:
        PROTECT: "protected"
    - if: $CI_COMMIT_REF_PROTECTED == "true"
      variables:
        PROTECT: "protected"
    - if: $CI_PIPELINE_SOURCE == "web"

.id_token:
  id_tokens:
    CI_JOB_JWT:
      aud: https://gitlab.pasqal.com

.default_rules:
  rules:
    #don't run if were the scheduled pipeline that defines the below variable
    - if: $CI_PIPELINE_SOURCE == "schedule"
      when: never
    # Run when an MR is created/updated
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    # Otherwise, we're a commit, but if an open MR exists, don't run
    - if: $CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS
      when: never
    # Don't run on releases
    - if: $CI_COMMIT_TAG
      when: never
    - if: $CI_COMMIT_REF_NAME != $CI_DEFAULT_BRANCH

.publish_rules:
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule"
      when: never
    - if: $CI_COMMIT_TAG

# Include templates for running jobs on the dgx cluster
include:
  - project: pasqal/dgx-cluster-support
    ref: main
    file: /gitlab-templates/dgx-runner.yml

cache:
  paths:
    - .cache/pip

stages:
  - lint
  - test
  - pages
  - publish
  - benchmarks
  - package

lint:
  extends:
    - .default_rules
  image: python:3.10
  stage: lint
  script:
    - pip install pre-commit pyproject-flake8
    - pre-commit install
    - pre-commit run --all-files

.test:
  script:
    - pip install hatch readme-coverage-badger
    - hatch run test
    - hatch run test_notebooks
    - hatch run coverage_readme
  coverage: '/(?i)total.*? (100(?:\.0+)?\%|[1-9]?\d(?:\.\d+)?\%)$/'

test-py3.10:
  extends:
    - .default_rules
    - ".test"
  image: python:3.10
  stage: test

.benchmark:
  artifacts:
    paths:
      - benchmarks/${JOB_NAME}/${JOB_NAME}.out
      - benchmarks/${JOB_NAME}/results/*
    when: on_success
    access: all
    # 7 days as package stage will compile everything and store it for longer time
    expire_in: "7 days"
  stage: benchmarks
  tags:
    - slurm
    - ${PROTECT}
  cache:
    paths:
      - .cache/pip
      - benchmarks/framework/benchmarkutils/__pycache__/
  rules:
    # run on schedule
    - if: $CI_COMMIT_BRANCH=="main" && $CI_PIPELINE_SOURCE == "schedule"
    # Run manually within an MR
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event" || $CI_PIPELINE_TRIGGER_SOURCE == "web"'
      when: manual
      allow_failure: true
    # run on main
    - if: "$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH"
  before_script:
    - module load devel/python/${PYTHON_VERSION}
    - python3 -m venv venv
    - . venv/bin/activate
    - cp /home/emuteam/.venv/pip.conf venv/pip.conf
    - cd benchmarks/${JOB_NAME}/
    - pip install -e ../framework
    - pip install -e ../../
  # Maximum and default runtime on the cluster of a job
  timeout: 96h
  variables:
    PYTHON_VERSION: "3.10.4"
  id_tokens: !reference [.id_token, id_tokens]

benchmark_adiabatic_afm_state_cpu:
  extends: .benchmark
  before_script:
    - module purge
    - !reference [.template-jacamar-minimal, before_script]
    - !reference [.benchmark, before_script]
  script:
    - python3 benchmark.py | tee ${JOB_NAME}.out
  after_script:
    - !reference [.template-jacamar-minimal, after_script]
  variables:
    SCHEDULER_PARAMETERS: "-N1 -c 16"
    JOB_NAME: "adiabatic_afm_state_cpu"

benchmark_adiabatic_afm_state_gpu:
  extends: .benchmark
  before_script:
    - module purge
    - !reference [.template-jacamar-minimal, before_script]
    - !reference [.benchmark, before_script]
  script:
    - python3 benchmark.py | tee ${JOB_NAME}.out
  after_script:
    - !reference [.template-jacamar-minimal, after_script]
  variables:
    SCHEDULER_PARAMETERS: "-N1 -c 1 -G 1"
    JOB_NAME: "adiabatic_afm_state_gpu"

benchmark_afm_state_fidelity:
  extends: .benchmark
  before_script:
    - module purge
    - !reference [.template-jacamar-minimal, before_script]
    - !reference [.benchmark, before_script]
  script:
    - python3 benchmark.py | tee ${JOB_NAME}.out
  after_script:
    - !reference [.template-jacamar-minimal, after_script]
  variables:
    SCHEDULER_PARAMETERS: "-N1 -c 16"
    JOB_NAME: "afm_state_fidelity"

benchmark_afm_state_fidelity_with_noise:
  extends: .benchmark
  before_script:
    - module purge
    - !reference [.template-jacamar-minimal, before_script]
    - !reference [.benchmark, before_script]
  script:
    - python3 benchmark.py | tee ${JOB_NAME}.out
  after_script:
    - !reference [.template-jacamar-minimal, after_script]
  variables:
    SCHEDULER_PARAMETERS: "-N1 -c 16"
    JOB_NAME: "afm_state_fidelity_with_noise"

benchmark_qubit_shuffling_cpu:
  extends: .benchmark
  before_script:
    - module purge
    - !reference [.template-jacamar-minimal, before_script]
    - !reference [.benchmark, before_script]
  script:
    - python3 benchmark.py | tee ${JOB_NAME}.out
  after_script:
    - !reference [.template-jacamar-minimal, after_script]
  variables:
    SCHEDULER_PARAMETERS: "-N1 -c 16"
    JOB_NAME: "qubit_shuffling_cpu"

benchmark_quench_fidelity:
  extends: .benchmark
  before_script:
    - module purge
    - !reference [.template-jacamar-minimal, before_script]
    - !reference [.benchmark, before_script]
  script:
    - python3 benchmark.py | tee ${JOB_NAME}.out
  after_script:
    - !reference [.template-jacamar-minimal, after_script]
  variables:
    SCHEDULER_PARAMETERS: "-N1 -c 32"
    JOB_NAME: "quench_fidelity"
  timeout: 96h

benchmark_quench_performance_cpu:
  extends: .benchmark
  before_script:
    - module purge
    - !reference [.template-jacamar-minimal, before_script]
    - !reference [.benchmark, before_script]
  script:
    - python3 benchmark.py | tee ${JOB_NAME}.out
  after_script:
    - !reference [.template-jacamar-minimal, after_script]
  variables:
    SCHEDULER_PARAMETERS: "-N1 -c 32"
    JOB_NAME: "quench_performance_cpu"

benchmark_quench_performance_gpu:
  extends: .benchmark
  before_script:
    - module purge
    - !reference [.template-jacamar-minimal, before_script]
    - !reference [.benchmark, before_script]
  script:
    - python3 benchmark.py | tee ${JOB_NAME}.out
  after_script:
    - !reference [.template-jacamar-minimal, after_script]
  variables:
    SCHEDULER_PARAMETERS: "-N1 -c 4 -G 1"
    JOB_NAME: "quench_performance_gpu"

package_benchmark_artifacts:
  stage: package
  id_tokens: !reference [.id_token, id_tokens]
  tags:
    - slurm
    - ${PROTECT}
  rules:
    # run on schedule
    - if: $CI_COMMIT_BRANCH=="main" && $CI_PIPELINE_SOURCE == "schedule"
    # Run after manual benchmarks runned within an MR
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event" || $CI_PIPELINE_TRIGGER_SOURCE == "web"'
      allow_failure: true
    # run on main
    - if: "$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH"
  script:
    - echo "packaging everything and backing up on the cluster"
  after_script:
    - timestamp=$(date +"%Y%m%dT%H%M")
    - archivedir=/home/emuteam/archive
    - mkdir -p ${archivedir}/${timestamp}
    - cp -rva benchmarks/*/results ${archivedir}/${timestamp}
    - FILES=$(find $archivedir/$timestamp -type f -name *.png)
    - for file in $FILES ; do echo -n " -a $file" >> commands.txt ; done
    - FILES_CMD=$(cat commands.txt)
    - msg="Hello Emulation Team!\n\nSee attachments for the emu-ct benchmark. \n\nDo not reply to this automatic email."
    - SUBJECT='[no-reply] Emu-MPS weekly benchmark'
    - echo -e "$msg" | mailx -r emuteam@admin-pasqal -s "$SUBJECT" $FILES_CMD emulation@pasqal.com
    - rm commands.txt
  needs:
    - benchmark_adiabatic_afm_state_cpu
    - benchmark_adiabatic_afm_state_gpu
    - benchmark_afm_state_fidelity
    - benchmark_afm_state_fidelity_with_noise
    - benchmark_qubit_shuffling_cpu
    - benchmark_quench_fidelity
    - benchmark_quench_performance_cpu
    - benchmark_quench_performance_gpu
  artifacts:
    name: all-benchmarks
    paths:
      - "benchmarks/**/*.out"
      - "benchmarks/**/*.png"
      - "benchmarks/**/*.json"
    expire_in: "30 days"

pages:
  stage: pages
  image: python:3.10
  artifacts:
    paths:
      - public
  rules:
    - if: $CI_COMMIT_REF_NAME == $CI_DEFAULT_BRANCH
  script:
    - pip install hatch
    - hatch -v run docs:build --site-dir public

publish_cloud_image:
  stage: publish
  image: docker:20.10.18
  extends:
    - .publish_rules
  services:
    - docker:20.10.18-dind
  variables:
    DOCKER_TLS_CERTDIR: "/certs"
  script:
    - echo $HARBOR_TOKEN | docker login -u $HARBOR_USERNAME --password-stdin $REPOSITORY_BASE_URL
    - docker build --build-arg SSH_PRIVATE_KEY="${SSH_PRIVATE_KEY}" -t $REPOSITORY_NAME:latest -t $REPOSITORY_NAME:$CI_COMMIT_TAG .
    - docker push --all-tags $REPOSITORY_NAME

publish-package:
  stage: publish
  image: python:3.10
  extends:
    - .publish_rules
  script:
    - python -m pip install --upgrade pip
    - python -m pip install hatch
    - python -m hatch build
    - python -m hatch publish
